{"meta":{"title":"萌面喵喵侠","subtitle":"","description":"萌面喵喵侠的个人博客","author":"萌面喵喵侠","url":"https://lolico.me","root":"/"},"pages":[{"title":"404 | 萌面喵喵侠","date":"2022-05-02T03:45:10.806Z","updated":"2022-05-02T03:45:10.806Z","comments":true,"path":"404.html","permalink":"https://lolico.me/404.html","excerpt":"","text":"404 | 萌面喵喵侠*{margin:0;padding:0}body{background:#f2f2f2}canvas{display:block;margin:50px auto 200px;margin-left:300px;border:1px solid #333;box-shadow:0 0 16px 2px rgba(0,0,0,.8)}a,p{font-family:Helvetica,Arial,sans-serif;font-size:20px;color:#777;display:block;width:400px;margin:0 auto;text-align:center;text-decoration:none}.info{margin:50px auto;text-align:center;font-size:20px;color:#999}a{color:#37e}#info{position:absolute;z-index:55;width:400px;right:200px;top:200px}#tenth>button{letter-spacing:0}#tenth span{letter-spacing:0;display:inline-block;position:relative;width:8px;transition:all .5s ease-in-out}#tenth span:nth-of-type(4){width:5px}#tenth span:nth-of-type(6){width:1px}#tenth span:nth-of-type(8){width:4px}#tenth:hover span:nth-of-type(1){animation:h .5s}#tenth:hover span:nth-of-type(2){animation:o .5s}#tenth:hover span:nth-of-type(3){animation:v .5s}#tenth:hover span:nth-of-type(4){animation:e .5s}#tenth:hover span:nth-of-type(5){animation:r .5s}#tenth:hover span:nth-of-type(7){animation:t .5s}#tenth:hover span:nth-of-type(8){animation:e .5s}#tenth:hover span:nth-of-type(9){animation:n .5s}@keyframes h{0%{transform:translate(0,0)}50%{transform:translate(50px,5px)}75%{transform:translate(5px,5px)}80%{transform:translate(0,0)}100%{transform:translate(0,0)}}@keyframes o{0%{transform:translate(0,0)}25%{transform:translate(-4px,0)}50%{transform:translate(3px,4px)}80%{transform:translate(0,0)}100%{transform:translate(0,0)}}@keyframes v{0%{transform:translate(0,0)}20%{transform:rotate(360deg)}50%{transform:scale(2)}80%{transform:translate(0,0)}100%{transform:translate(0,0)}}@keyframes e{0%{transform:translate(0,0)}20%{transform:translate(-10px,-2px)}80%{transform:translate(0,0)}100%{transform:translate(0,0)}}@keyframes r{0%{transform:translate(0,0)}20%{transform:translate(0,10px)}80%{transform:translate(0,32px)}100%{transform:translate(0,0)}}@keyframes t{0%{transform:translate(0,0)}20%{transform:translate(0,-10px)}40%{transform:translate(0,0)}60%{transform:translate(0,-10px)}80%{transform:translate(0,0)}100%{transform:translate(0,0)}}@keyframes n{0%{transform:translate(0,0)}50%{transform:skewY(50deg)}80%{transform:translate(0,0)}100%{transform:translate(0,0)}}button{position:absolute;right:420px;top:500px;z-index:99;width:180px;height:60px;background:0 0;color:#000;font-weight:700;letter-spacing:1px;border:none;font-size:18px;outline:0;cursor:pointer}404文章不见了，送你一个游戏叭使用👆、👇、👈、👉移动返 回 首 页var map={tile_size:16,keys:[{id:0,colour:\"#333\",solid:0},{id:1,colour:\"#888\",solid:0},{id:2,colour:\"#555\",solid:1,bounce:.35},{id:3,colour:\"rgba(121, 220, 242, 0.4)\",friction:{x:.9,y:.9},gravity:{x:0,y:.1},jump:1,fore:1},{id:4,colour:\"#777\",jump:1},{id:5,colour:\"#E373FA\",solid:1,bounce:1.1},{id:6,colour:\"#666\",solid:1,bounce:0},{id:7,colour:\"#73C6FA\",solid:0,script:\"change_colour\"},{id:8,colour:\"#FADF73\",solid:0,script:\"next_level\"},{id:9,colour:\"#C93232\",solid:0,script:\"death\"},{id:10,colour:\"#555\",solid:1},{id:11,colour:\"#0FF\",solid:0,script:\"unlock\"}],data:[[2,2,2,2,2,2,2,2,2,2,2,2,2],[2,1,1,1,1,1,1,1,1,1,1,1,2],[2,1,1,1,1,1,1,1,1,1,1,1,2],[2,1,1,1,1,1,1,1,1,1,1,1,2],[2,1,1,1,1,1,1,1,1,1,1,1,2],[2,1,1,1,1,1,1,1,1,1,1,1,2],[2,1,1,1,1,1,1,1,1,1,1,1,2],[2,1,1,1,1,1,1,1,1,1,1,1,2],[2,1,1,1,1,1,1,1,1,1,1,1,2],[2,1,1,1,1,1,1,1,1,1,1,1,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,6,6,6,6,6,2],[2,1,1,1,1,1,1,1,1,1,1,1,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,1,1,1,1,1,2],[2,1,1,1,1,1,1,1,1,1,1,1,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,1,1,1,1,1,2],[2,1,1,1,1,1,1,1,1,1,1,1,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,1,1,1,1,1,2],[2,1,1,1,1,1,1,1,1,1,1,1,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,1,1,1,1,1,2,2,2],[2,1,1,1,1,1,1,1,1,1,1,1,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,7,1,1,1,1,1,1,1,2],[2,1,1,1,1,1,1,1,1,1,1,1,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,4,2,2,2,1,2],[2,1,1,1,1,1,1,1,1,1,1,1,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,4,2,1,1,1,2],[2,1,1,1,1,1,1,1,1,1,1,1,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,4,2,1,2,2,2],[2,1,1,1,1,1,1,1,1,1,1,1,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,4,2,1,2],[2,1,1,1,1,1,1,1,1,1,1,1,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,4,2,1,2],[2,1,1,1,1,1,1,1,1,1,1,1,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,4,2,1,2],[2,1,1,1,1,1,1,1,1,1,1,1,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,4,2,1,2],[2,1,1,1,1,1,1,1,1,1,1,1,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,4,2,1,2],[2,1,1,1,1,1,1,1,1,1,1,1,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,4,2,1,2],[2,1,1,1,1,1,1,1,1,1,1,1,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,4,2,1,2],[2,1,1,1,1,1,1,1,1,1,1,1,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,4,2,1,2],[2,1,1,1,1,1,1,1,1,1,1,1,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,4,2,1,2],[2,2,2,2,2,2,2,2,2,2,2,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,4,2,1,2],[2,1,1,1,1,1,1,1,1,1,2,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,4,2,1,2],[2,1,1,1,1,1,1,1,1,1,2,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,4,2,1,2,2,2,2,2,2,2,2,2,2,2,2,2],[2,1,2,1,1,1,1,1,1,1,2,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,4,2,1,2,2,2,2,2,2,2,2,1,1,1,1,2],[2,1,2,2,1,1,1,1,1,1,2,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,4,2,1,2,2,2,2,2,2,2,2,1,1,1,1,2],[2,1,2,2,2,1,1,1,1,1,2,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,4,2,1,2,2,2,2,2,2,2,2,1,1,1,1,2],[2,1,2,2,2,2,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,4,2,1,2,2,2,2,2,2,2,2,8,1,1,1,2],[2,1,2,2,2,2,2,2,2,2,2,6,2,1,1,1,1,1,1,1,1,1,1,2,2,1,1,1,2,2,2,2,2,2,2,1,2,2,2,2,2,2,2,2,2,2,2,4,2],[2,1,2,2,2,2,2,2,2,2,2,2,2,1,1,1,1,1,1,1,1,1,2,2,2,9,9,9,2,10,10,10,10,10,10,1,1,1,1,1,1,1,11,2,2,2,2,4,2],[2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,10,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,4,2],[2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,4,2],[2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,4,2,2,2,2,2,2,2,2],[2,6,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,4,2,1,1,1,1,1,1,2],[2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,4,1,1,1,1,1,1,1,2],[2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,2],[2,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,6,6,6,2,2,2,2,2,2,6,2,2,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2],[2,1,1,2,2,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2],[2,1,1,2,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2],[2,1,1,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2],[2,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2],[2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2],[2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,1,1,1,1,2,5,5,2,1,1,1,1,1,1,1,1,1,1,1,2],[2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,1,1,1,1,2,2,2,2,2,1,1,1,1,1,1,1,1,1,1,2],[2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,2,2,2,2,2,2,1,1,1,1,1,1,1,1,1,2],[2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,2,2,2,2,2,2,2,1,1,1,1,1,1,1,1,2],[2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,2,2,2,2,2,2,2,2,1,1,1,1,1,1,1,2],[2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,3,3,3,3,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,2],[2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,3,3,3,3,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,2],[2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,3,3,3,3,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,2],[2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,3,3,3,3,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,2],[2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,2],[2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,2],[2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,5,5,5,1,1,1,1,1,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,2],[2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2]],gravity:{x:0,y:.3},vel_limit:{x:2,y:16},movement_speed:{jump:6,left:.3,right:.3},player:{x:2,y:2,colour:\"#FF9900\"},scripts:{change_colour:'game.player.colour = \"#\"+(Math.random()*0xFFFFFF"},{"title":"About","date":"2022-05-02T03:45:10.810Z","updated":"2022-05-02T03:45:10.810Z","comments":false,"path":"about/index.html","permalink":"https://lolico.me/about/index.html","excerpt":"","text":"关于我（雾啵啵birdyヾ(≧▽≦*)o时间轴@timeline{2020@item{3月3日博客迁移到Hexo，Github托管}2019@item{10月1日学习SpringBoot，Spring全家桶等Web后端技术}@item{7月1日学习SpringMVC框架}@item{3月1日学习前端基础（HTML，CSS，JS）}2018@item{9月折腾服务器，搭建各种小站点}@item{8月6日基于typecho搭建个人博客}@item{8月4日购买人生中的第一台服务器（阿里云学生ECS）}}"},{"title":"","date":"2022-05-02T03:45:10.810Z","updated":"2022-05-02T03:45:10.810Z","comments":false,"path":"categories/index.html","permalink":"https://lolico.me/categories/index.html","excerpt":"","text":""},{"title":"","date":"2022-05-02T03:45:10.810Z","updated":"2022-05-02T03:45:10.810Z","comments":false,"path":"tags/index.html","permalink":"https://lolico.me/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"学点RocketMQ","slug":"学点RocketMQ","date":"2022-05-02T03:42:17.000Z","updated":"2022-05-02T03:45:10.810Z","comments":true,"path":"2022/05/02/学点RocketMQ/","link":"","permalink":"https://lolico.me/2022/05/02/%E5%AD%A6%E7%82%B9RocketMQ/","excerpt":"","text":"对于 MQ 来说，其实不管是 RocketMQ、Kafka 还是其他消息队列，它们的本质都是：一发一存一消费。下面我们先以这个本质作为根，一起由浅入深地聊聊 MQ。从MQ的本质说起原始模型将 MQ 掰开了揉碎了来看，都是一发一存一消费，再通俗点就是一个转发器。生产者先将消息投递到一个叫做队列的容器中，消费者不断从这个容器中取出消息^1进行消费，仅此而已。image-20220108204854445上图便是消息队列最原始的模型，它包含了两个关键词：消息和队列。1、消息：就是要传输的数据，可以是最简单的字符串，也可以是任何自定义的复杂格式（只要能按预定格式解析（序列化/反序列化^2）出来即可）。2、队列：一种先进先出数据结构。它是存放消息的容器，消息从队尾入队，从队头出队，入队即发消息的过程，出队即收消息的过程。原始模型的演进再看今天我们最常用的消息队列产品（RocketMQ、Kafka 等等），你会发现：它们都在最原始的消息模型上做了扩展，同时提出了一些新名词，比如：主题（topic）、分区^3（partition）、生产/消费组（producer/consumer group）等等。要彻底理解这些新概念，先从消息模型的演进说起（道理好比：架构从来不是设计出来的，而是演进来的）。队列模型最初的消息队列就是上一节讲的原始模型，它是一个严格意义上的队列（Queue）。消息按照什么顺序写进去，就按照什么顺序读出来。不过，队列没有 “读” 这个操作，读就是出队，从队头中 “删除” 这个消息。image-20220108205116346这便是队列模型：它允许多个生产者往同一个队列发送消息。但是，如果有多个消费者，实际上是竞争的关系，也就是一条消息只能被其中一个消费者接收到，消费完就不能再次被消费。发布-订阅模型如果需要将一份消息数据分发给多个消费者，并且每个消费者都要求收到全量的消息。很显然，队列模型无法满足这个需求。一个可行的方案是：为每个消费者创建一个单独的队列，让生产者发送多份。这种做法比较笨，而且同一份数据会被复制多份，也很浪费空间。为了解决这个问题，就演化出了另外一种消息模型：发布-订阅模型。image-20220108205149218在发布-订阅模型中，存放消息的容器变成了 “主题”，消费者在接收消息之前需要先 “订阅主题”。最终，每个消费者都可以收到同一个主题的全量消息。仔细对比下它和 ”队列模型” 的异同：发布消息的是生产者，主题即消息的容器，消费者即订阅者，无本质区别。唯一的不同点在于：一份消息数据是否可以被多次消费。小结上面两种模型说白了就是：单播和广播^4。并且当 发布-订阅模型 中只有一个订阅者时，它和队列模型就一样了。这也解释了为什么现在主流的 RocketMQ、Kafka 都是基于发布-订阅模型实现的？至于各类产品中的生产/消费组^5、分区、消费模式、消息回溯、延迟消费等等衍生概念都是在上述原始模型的基础上，为了解决某些问题而产生的。通过MQ本质看应用场景回顾一下上面消息队列的原始模型，不难发现消息队列的这两个特性：在没有消息队列时，通常生产者作为调用方、消费者作为被调方，消息通过一次RPC[^6]直接进行传达并被“消费”。引入消息队列后，一次RPC变成了两次RPC，生产者和消费者之间无需知道对方的存在。多了一个中间节点（消息队列）转储消息，原本的同步操作变成了异步。再回想起倒背如流的消息队列应用场景：系统解耦、异步通信、流量削峰、内容分发等等，无非是利用了上面两个特性。那么引入消息队列后就没有坏处吗？当然不。鱼和熊掌不可兼得，在某些方面获得便利的同时也引入了一些问题：1、消息的及时性问题，通常而言业务对消息的及时性要求不高。2、引入额外的组件，系统复杂度上升，稳定性下降。3、因为网络波动和异步，会存在消息的顺序和重复问题。4、生产者发送失败和消费者消费失败的处理带来的一致性的问题。纵观目前主流的消息队列，也并没有完全解决这些问题，根据侧重不同平衡利弊，所以才有了现在诸多的消息队列。那目前主流的消息队列是如何平衡和解决这些问题，内部实现又是如何呢？下面我们就以RocketMQ为例，探究一下内部设计和实现细节。RocketMQ原始队列模型毕竟简单，无法满足真实的应用场景，所以目前主流的消息队列都引入了一些额外的概念来解决这些泛问题，描述的名词可能不同但作用总体上相差无几。所以先来了解一下RocketMQ中的概念[^7]，以便更好的理解后文内容。RocketMQ中的概念imgRocketMQ核心由四部分组成，分别是NameServer、Broker、Producer以及Consumer。通过上图可以看到，这四部分都可集群部署，这是RocketMQ吞吐量大、可用性高的原因之一。Broker的集群部署模式也有很多种：支持多Master模式、多Master多Slave异步复制模式、多Master多Slave同步复制模式。NameServerNameServer是一个功能齐全的服务，其角色类似Dubbo中的Zookeeper，但NameServer与Zookeeper相比更轻量。主要是因为NameServer被设计成几乎无状态的，节点之间相互无通信，通过部署多个NameServer并在客户端做可用性轮训，实现了一个伪集群的高可用。NameServer压力不会太大，平时主要开销是在维持心跳和提供Topic-Broker的关系数据。BrokerBroker是具体提供业务的服务，负责存储消息，转发消息。每个Broker启动时都会向NameServer注册自己的信息，并与NameServer保持长链接及心跳，定时将Topic信息更新到NameServer。有一点需要注意，Broker向NameServer发送心跳时， 会带上当前自己所负责的所有Topic信息，如果Topic个数太多（万级别），会导致一次心跳中Topic的数据就几十M，网络情况差的话， 网络传输失败，心跳失败，导致NameServer误认为Broker心跳失败。ProducerProducer是指具体生产消息的服务，即生产者。生产者在启动时会。从支持三种消息发送方式：单向发送：消息发出去后，可以继续发送下一条消息或执行业务代码，不需要等待服务器回应，且没有回调函数[^8]。异步发送：消息发出去后，可以继续发送下一条消息或执行业务代码，不等待服务器回应，有回调函数。同步发送：消息发出去后，等待服务器响应成功或失败，才能继续后面的操作。ConsumerConsumer是指具体消费消息的服务，即消费者。消费者在启动时会从NameServer拉取Topic及Queue信息，根据负载均衡策略选择消费的Queue，支持集群消费和广播消费，可提供近实时的消息订阅机制。RocketMQ中提供了两张消费API，即Pull和Push两种：Pull，拉取型消费。消费者主动从Broker中拉去消息进行消费，只要拉取到消息，用户应用就会启动消费过程，所以 Pull 也称主动消费类型。Push，推送式消费。RocketMQ Client封装了消息的拉取、消费进度和其他的内部维护工作，将消息到达后执行的回调接口留给用户应用程序来实现。所以 Push 称为被动消费类型，但从实现上看还是基于 Pull 模式，不同于 Pull 的是 Push 首先要注册回调函数，当拉取到消息后触发回调函数开始消费消息。RocketMQ关键特性及实现原理分布式消息系统作为实现分布式系统可扩展、可伸缩性的关键组件，需要具有高吞吐量、高可用等特点。而谈到消息系统的设计，就回避不了两个问题：消息的顺序问题消息的重复问题RocketMQ作为阿里开源的一款高性能、高吞吐量的消息中间件，它是怎样来解决这两个问题的？顺序消息消息有序指的是一类消息消费时，能按照发送的顺序来消费。例如：一个订单产生了 3 条消息，分别是订单创建、订单付款、订单完成。消费时，要按照这个顺序消费才有意义。但同时多个订单之间同类的消息又是可以并行消费的。假如生产者产生了2条消息：M1、M2，要保证这两条消息的顺序，应该怎样做？你脑中想到的可能是这样：image-20220108235348191M1发送到S1后，M2发送到S2，如果要保证M1先于M2被消费，那么需要M1到达消费端后，通知S2，然后S2再将M2发送到消费端。这个模型存在的问题是，如果M1和M2分别发送到两台Broker上，就不能保证M1一定先达到，也就不能保证M1被先消费，那么就需要在MQ Broker集群维护消息的顺序。那么如何解决？一种简单的方式就是将M1、M2发送到同一个Broker上：image-20220109012300101这样可以保证M1先于M2到达MQ Broker（客户端等待M1成功后再发送M2），根据队列先进先出的原则，M1会先于M2被消费，这样就保证了消息的顺序。这个模型，理论上可以保证消息的顺序，但在实际运用中你应该会遇到下面的问题：image-20220109014152500网络延迟问题。只要将消息从一台服务器发往另一台服务器，就会存在网络延迟问题。如上图所示，如果发送M1耗时大于发送M2的耗时，那么M2就先被消费，仍然不能保证消息的顺序。即使M1和M2同时到达消费端，由于不清楚消费端1和消费端2的负载情况，仍然有可能出现M2先于M1被消费。如何解决这个问题？将M1和M2发往同一个消费者即可，且发送M1后，需要消费端响应成功后才能发送M2。但又会引入另外一个问题，如果发送M1后，消费端1没有响应，那是继续发送M2呢，还是重新发送M1？一般为了保证消息至少被消费一次[^9]，肯定会选择重发M1到另外一个消费端2，就如下图所示。image-20220109013847952这样的模型就严格保证消息的顺序，细心的你仍然会发现问题，消费端1没有响应Server时有两种情况，一种是M1确实没有到达，另外一种情况是消费端1已经响应，但是Server端没有收到。如果是第二种情况，重发M1，就会造成M1被重复消费。也就是我们后面要说的第二个问题，消息重复问题。回过头来看消息顺序问题，严格的顺序消息非常容易理解，而且处理问题也比较容易，要实现严格的顺序消息，简单且可行的办法就是：保证 生产者 - MQBroker - 消费者 是一对一对一的关系。但是这样设计，消息系统的吞吐量就大打折扣，也会导致更多的异常处理，比如：只要消费端出现问题，就会导致当前流程阻塞，又不得不花费更多的精力来解决阻塞问题。但消息队列需要做到高吞吐量、高容错性。这似乎是一对不可调和的矛盾，那么RocketMQ是如何解决这个问题的呢？首先可以明确的是RocketMQ并没有实现严格意义上的顺序消息。有些问题，看起来很重要，但实际上我们可以通过合理的设计或者将问题分解来规避。如果硬要把时间花在解决它们身上，实际上是浪费的，效率低下的。从这个角度来看消息的顺序问题，我们可以得出两个结论：1、不关注乱序的应用实际大量存在2、队列无序并不意味着消息无序最后我们从源码角度分析RocketMQ怎么实现发送顺序消息。123456789// RocketMQ默认提供了两种MessageQueueSelector实现：随机/HashSendResult sendResult = producer.send(msg, new MessageQueueSelector() &#123; @Override public MessageQueue select(List&lt;MessageQueue&gt; mqs, Message msg, Object arg) &#123; Integer id = (Integer) arg; int index = id % mqs.size(); return mqs.get(index); &#125;&#125;, orderId);在获取到路由信息以后，会根据MessageQueueSelector实现的算法来选择一个队列，同一个OrderId获取到的队列是同一个队列。12345678910111213private SendResult send() &#123; // 获取topic路由信息 TopicPublishInfo topicPublishInfo = this.tryToFindTopicPublishInfo(msg.getTopic()); if (topicPublishInfo != null &amp;&amp; topicPublishInfo.ok()) &#123; MessageQueue mq = null; // 根据我们的算法，选择一个发送队列 // 这里的arg = orderId mq = selector.select(topicPublishInfo.getMessageQueueList(), msg, arg); if (mq != null) &#123; return this.sendKernelImpl(msg, mq, communicationMode, sendCallback, timeout); &#125; &#125;&#125;消息重复上面在解决消息顺序问题时，引入了一个新的问题，就是消息重复。那么RocketMQ是怎样解决消息重复的问题呢？还是“恰好”不解决。造成消息的重复的根本原因是：网络不可达。只要通过网络交换数据，就无法避免这个问题。所以解决这个问题的办法就是不解决，转而绕过这个问题。那么问题就变成了：如果消费端收到两条一样的消息，应该怎样处理？1、消费端处理消息的业务逻辑保持幂等性2、保证每条消息都有唯一编号且保证消息处理成功与去重表的日志同时出现第1条很好理解，只要保持幂等性，不管来多少条重复消息，最后处理的结果都一样。第2条原理就是利用一张日志表来记录已经处理成功的消息的ID，如果新到的消息ID已经在日志表中，那么就不再处理这条消息。我们可以看到第1条的解决方式，很明显应该在消费端实现，不属于消息系统要实现的功能。第2条可以消息系统实现，也可以业务端实现。正常情况下出现重复消息的概率不一定大，且由消息系统实现的话，肯定会对消息系统的吞吐量和高可用有影响，所以最好还是由业务端自己处理消息重复的问题，这也是RocketMQ不解决消息重复的问题的原因。RocketMQ不保证消息不重复，如果你的业务需要保证严格的不重复消息，需要你自己在业务端去重。发送消息Producer轮询某topic下的所有队列的方式来实现发送方的负载均衡，如下图所示：img首先分析一下RocketMQ的客户端发送消息的源码：12345678910111213// 构造ProducerDefaultMQProducer producer = new DefaultMQProducer(\"ProducerGroupName\");// 初始化Producer，整个应用生命周期内，只需要初始化1次producer.start();// 构造MessageMessage msg = new Message(\"TopicTest1\",// topic \"TagA\",// tag：给消息打标签,用于区分一类消息，可为null \"OrderID188\",// key：自定义Key，可以用于去重，可为null (\"Hello MetaQ\").getBytes());// body：消息内容// 发送消息并返回结果SendResult sendResult = producer.send(msg);// 清理资源，关闭网络连接，注销自己producer.shutdown();在整个应用生命周期内，生产者需要调用一次start方法来初始化，初始化主要完成的任务有：如果没有指定namesrv地址，将会自动寻址启动定时任务：更新namesrv地址、从namsrv更新topic路由信息、清理已经挂掉的broker、向所有broker发送心跳…启动负载均衡的服务初始化完成后，开始发送消息，发送消息的主要代码如下：123456789101112private SendResult sendDefaultImpl(Message msg,......) &#123; // 检查Producer的状态是否是RUNNING this.makeSureStateOK(); // 检查msg是否合法：是否为null、topic,body是否为空、body是否超长 Validators.checkMessage(msg, this.defaultMQProducer); // 获取topic路由信息 TopicPublishInfo topicPublishInfo = this.tryToFindTopicPublishInfo(msg.getTopic()); // 从路由信息中选择一个消息队列 MessageQueue mq = topicPublishInfo.selectOneMessageQueue(lastBrokerName); // 将消息发送到该队列上去 sendResult = this.sendKernelImpl(msg, mq, communicationMode, sendCallback, timeout);&#125;代码中需要关注的两个方法tryToFindTopicPublishInfo和selectOneMessageQueue。前面说过在producer初始化时，会启动定时任务获取路由信息并更新到本地缓存，所以tryToFindTopicPublishInfo会首先从缓存中获取topic路由信息，如果没有获取到，则会自己去namesrv获取路由信息。selectOneMessageQueue方法通过轮询的方式，返回一个队列，以达到负载均衡的目的。如果Producer发送消息失败，会自动重试，重试的策略：重试次数 &lt; retryTimesWhenSendFailed（可配置）总的耗时（包含重试n次的耗时） &lt; sendMsgTimeout（发送消息时传入的参数）同时满足上面两个条件后，Producer会选择另外一个队列发送消息消息存储RocketMQ的消息存储是由consume queue和commit log配合完成的。Consume Queueconsume queue是消息的逻辑队列，相当于字典的目录，用来指定消息在物理文件commit log上的位置。我们可以在配置中指定consume queue与commitlog存储的目录每个topic下的每个queue都有一个对应的consumequeue文件，比如：1$&#123;rocketmq.home&#125;&#x2F;store&#x2F;consumequeue&#x2F;$&#123;topicName&#125;&#x2F;$&#123;queueId&#125;&#x2F;$&#123;fileName&#125;Consume Queue文件组织，如图所示：img根据topic和queueId来组织文件，图中TopicA有两个队列0,1，那么TopicA和QueueId=0组成一个ConsumeQueue，TopicA和QueueId=1组成另一个ConsumeQueue。按照消费端的GroupName来分组重试队列，如果消费端消费失败，消息将被发往重试队列中，比如图中的%RETRY%ConsumerGroupA。按照消费端的GroupName来分组死信队列，如果消费端消费失败，并重试指定次数后，仍然失败，则发往死信队列，比如图中的%DLQ%ConsumerGroupA。死信队列（Dead Letter Queue）一般用于存放由于某种原因无法传递的消息，比如处理失败或者已经过期的消息。Consume Queue中存储单元是一个20字节定长的二进制数据，顺序写顺序读，如下图所示：imgCommitLog Offset是指这条消息在Commit Log文件中的实际偏移量Size存储中消息的大小Message Tag HashCode存储消息的Tag的哈希值：主要用于订阅时消息过滤（订阅时如果指定了Tag，会根据HashCode来快速查找到订阅的消息）Commit LogCommitLog：消息存放的物理文件，每台broker上的commitlog被本机所有的queue共享，不做任何区分。文件的默认位置如下，仍然可通过配置文件修改：1$&#123;user.home&#125;\\store\\$&#123;commitlog&#125;\\$&#123;fileName&#125;CommitLog的消息存储单元长度不固定，文件顺序写，随机读。消息的存储结构如下表所示，按照编号顺序以及编号对应的内容依次存储。img消息存储实现消息存储实现，比较复杂，也值得大家深入了解，这小节只以代码说明一下具体的流程。1234567891011121314151617181920212223242526272829303132333435363738// Set the storage timemsg.setStoreTimestamp(System.currentTimeMillis());// Set the message body BODY CRC (consider the most appropriate settingmsg.setBodyCRC(UtilAll.crc32(msg.getBody()));StoreStatsService storeStatsService = this.defaultMessageStore.getStoreStatsService();synchronized (this) &#123; long beginLockTimestamp = this.defaultMessageStore.getSystemClock().now(); // Here settings are stored timestamp, in order to ensure an orderly global msg.setStoreTimestamp(beginLockTimestamp); // MapedFile：操作物理文件在内存中的映射以及将内存数据持久化到物理文件中 MapedFile mapedFile = this.mapedFileQueue.getLastMapedFile(); // 将Message追加到文件commitlog result = mapedFile.appendMessage(msg, this.appendMessageCallback); switch (result.getStatus()) &#123; case PUT_OK:break; case END_OF_FILE: // Create a new file, re-write the message mapedFile = this.mapedFileQueue.getLastMapedFile(); result = mapedFile.appendMessage(msg, this.appendMessageCallback); break; DispatchRequest dispatchRequest = new DispatchRequest( topic,// 1 queueId,// 2 result.getWroteOffset(),// 3 result.getWroteBytes(),// 4 tagsCode,// 5 msg.getStoreTimestamp(),// 6 result.getLogicsOffset(),// 7 msg.getKeys(),// 8 /** * Transaction */ msg.getSysFlag(),// 9 msg.getPreparedTransactionOffset());// 10 // 1.分发消息位置到ConsumeQueue // 2.分发到IndexService建立索引 this.defaultMessageStore.putDispatchRequest(dispatchRequest);&#125;消息的索引文件如果一个消息包含key值的话，会使用IndexFile存储消息索引，文件的内容结构如图：img索引文件主要用于根据key来查询消息的，流程主要是：根据查询的 key 的 hashcode%slotNum 得到具体的槽的位置(slotNum 是一个索引文件里面包含的最大槽的数目，例如图中所示 slotNum=5000000)根据 slotValue(slot 位置对应的值)查找到索引项列表的最后一项(倒序排列,slotValue 总是指向最新的一个索引项)遍历索引项列表返回查询时间范围内的结果集(默认一次最大返回的 32 条记录)消息订阅RocketMQ消息订阅有两种模式，一种是Push模式，即MQServer主动向消费端推送；另外一种是Pull模式，即消费端在需要时，主动到MQServer拉取。但在具体实现时，Push和Pull模式都是采用消费端主动拉取的方式。首先看下消费端的负载均衡：img消费端会通过RebalanceService线程，10秒钟做一次基于topic下的所有队列负载：遍历Consumer下的所有topic，然后根据topic订阅所有的消息获取同一topic和Consumer Group下的所有Consumer然后根据具体的分配策略来分配消费队列，分配的策略包含：平均分配、消费端配置等如同上图所示：如果有 5 个队列，2 个 consumer，那么第一个 Consumer 消费 3 个队列，第二 consumer 消费 2 个队列。这里采用的就是平均分配策略，它类似于我们的分页，TOPIC下面的所有queue就是记录，Consumer的个数就相当于总的页数，那么每页有多少条记录，就类似于某个Consumer会消费哪些队列。通过这样的策略来达到大体上的平均消费，这样的设计也可以很方面的水平扩展Consumer来提高消费能力。消费端的Push模式是通过长轮询的模式来实现的，就如同下图：imgConsumer端每隔一段时间主动向broker发送拉消息请求，broker在收到Pull请求后，如果有消息就立即返回数据，Consumer端收到返回的消息后，再回调消费者设置的Listener方法。如果broker在收到Pull请求时，消息队列里没有数据，broker端会阻塞请求直到有数据传递或超时才返回。当然，Consumer端是通过一个线程将阻塞队列LinkedBlockingQueue&lt;PullRequest&gt;中的PullRequest发送到broker拉取消息，以防止Consumer一致被阻塞。而Broker端，在接收到Consumer的PullRequest时，如果发现没有消息，就会把PullRequest扔到ConcurrentHashMap中缓存起来。broker在启动时，会启动一个线程不停的从ConcurrentHashMap取出PullRequest检查，直到有数据返回。未完待续…[^6]: RPC(Remote Procedure Call)，远程过程调用。可以通俗的理解为不同系统间的接口调用。[^7]: 此处的概念并不是指RocketMQ独有，部分名词属于消息领域模型中通用的概念。[^8]: 回调函数多用于异步操作完成后的通知或处理，在这里用于确认消息是否发送成功。[^9]: 几乎所有的MQ都做到了至少一次（At least once），三种消息交付方式之间的区别详见此处。","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"MessageQueue","slug":"MessageQueue","permalink":"https://lolico.me/tags/MessageQueue/"}]},{"title":"概念工程学","slug":"概念工程学","date":"2022-05-01T07:43:42.000Z","updated":"2022-05-02T03:45:10.810Z","comments":true,"path":"2022/05/01/概念工程学/","link":"","permalink":"https://lolico.me/2022/05/01/%E6%A6%82%E5%BF%B5%E5%B7%A5%E7%A8%8B%E5%AD%A6/","excerpt":"","text":"一天晚上，一位朋友发了个统计学领域一些定理及定义的截图给我，逐字逐句看了很久，完全没看懂在说啥，不由得想：为什么数学领域要把一些「能用通俗语言描述」的东西描述的晦涩难懂？因为自己平时在给人解答一些技术问题时，都会尽量用通俗的话来描述，就算与实际含义有点偏差，也至少能让人家觉得：「噢，大概知道了」，而不是讲些大而美的名词在外行面前显得「专业」。直到一次偶然机会，了解到了一个名词：「概念工程学」。搭建一个概念体系和盖楼造汽车是一样的，这是一种工程，只要每个部件有统一标准，不管谁造出来都能拼成一个整体。数学工作者努力的把「能通俗」的事情翻译成严谨的数学语言，就是让这些概念标准化，标准化就有利于分工合作和深入研究。首先能确定的一点是：任何领域的研究到达一定深度时就一定只是为少数人准备的。客观世界的复杂性使我们需要更精确的工具去描述，才能更好发展我们的理论而不至于混乱、不自洽。对于类似数学领域这种严谨的「基础理论科学」来说更是如此。总之，通俗的语言有助于科普，严谨的数学语言有助于深入，两者都很重要。听众不同，是选择用通俗语言去领进门还是用严谨的符号深入研究是我们需要注意的。世界必不被轻看。","categories":[{"name":"碎碎念","slug":"碎碎念","permalink":"https://lolico.me/categories/%E7%A2%8E%E7%A2%8E%E5%BF%B5/"}],"tags":[]},{"title":"最优解","slug":"最优解","date":"2022-04-05T14:53:05.000Z","updated":"2022-05-02T03:45:10.810Z","comments":true,"path":"2022/04/05/最优解/","link":"","permalink":"https://lolico.me/2022/04/05/%E6%9C%80%E4%BC%98%E8%A7%A3/","excerpt":"","text":"如果将交往看成一个找最优解问题，普通朋友能做到局部最优，但男女朋友可以做到全局最优，因为从局部最优搜索到全局最优需要不断考验对方的边界，而普通朋友看起来关系和谐，却是没法打破这一点的。越陌生的朋友，越容易「在每一件事上都让彼此都舒服」。而恋人之间应该追求的是「总体上来看，我们在一起比不在一起，让彼此更舒服了」比如你有个同学，这同学和你不算熟，你俩只有一个共同爱好，就是打dota。你们的生活除了游戏没有交集，只有晚上打dota的时候一起开黑，你们共度的每一段时光，都是彼此都开心的。你会发现，和这个同学一起玩的时候，「彼此都舒服」。至于他其他时候做什么，你一点都不关心。他爱干啥干啥，都不会令你感到不适。男女朋友就是完全另一个系统了。你认为，是否让彼此都舒服，是以「时间」来计算的。会有一个合理的「时间」，让男女双方都感到满意。这显然是一个过于简化的模型。同样是两个小时，让女生陪男生看球，和让男生陪女生逛街，显然给双方带来的是截然不同的感受。因此时间并不是最本质的，做的事情才比较重要。在成为恋人之后，你会发现，由于你们的生活被多多少少捆绑在一起，你们很多时候根本没有所谓「共赢」的选择。在某一件事情上，根本不可能让彼此「都舒服」。就比如说看五月天演唱会。可能你女朋友是个五月天狂热粉，你对五月天毫无兴趣。这时候如果你陪你女朋友去看，你女朋友高兴，你不高兴。但是你不陪你女朋友去看，她觉得你作为男朋友竟然不喜欢她的爱豆，变成了你高兴她不高兴。也有可能，你不陪她，她就要和别的男生看，这时候你就更不高兴。或者说没有女生陪她看，你又担心她在这个比较复杂场合的安全，你又不高兴。再或者你说那咱们别去看五月天了，这时候变成了她不高兴。你看，因为你们现在是男女朋友关系，而不是普通朋友了，就会出现很多别的想法，责任、义务、占有欲。这些想法就会让「彼此都舒服」成为一件不可能的事情。而这些问题，根本不是所谓增加或者减少两个人「黏」在一起的时间可以解决的。这段时间在不在一起，都会引起其中一个人的不舒适。男女朋友之间应该做的，是追求所谓「两个人加起来更开心」。比如一件事，如果压根没这件事，你们俩心情不变，都是（0，0）。但是如果这件事女孩子做了，她很开心，你小不开心，变成了（10，-3）。这件事就是件可以做的事情。可这件事要是女孩子小开心，你大不开心，变成了（2，-20），那这件事就不应该做。我之前说，喜欢一个人，是愿意和她做让彼此都开心的事情，但爱一个人，应该是愿意和她做让她开心可不让自己开心的事情。大概意思就是这样。如果两个人都有这样的心态，那日积月累，你们每个人的开心值期望都应该是上升的，在一个地方让对方一下下，对方在未来就会用更好的方式弥补你。你陪我去看五月天，我就陪你去看邓紫棋。这就是所谓比较健康的恋情。当然，并不是每一段恋情都是健康的。如果有一个人的心态是「你应该事事站在我的立场考虑，只要我开心的事情就让我去做，我不开心的事情就不能做」，那另一个人的开心值很可能就会一直下降，直到他无法继续容忍。这个很好理解。但是还有一种情况，即便有一个人的心态是「我应该事事站在你的立场考虑，只要你开心的事情我就愿意做，你不开心我就不做」，也会导致同样的结果。在模型上，他们是等价的。你什么时候看到过一段感情，只有一方玩命付出，努力牺牲，不断退让，最后还能修成正果的？所以说，无论是男孩子还是女孩子，当你们感觉到另一半一直在让着自己，每件事都以自己开心为第一使命的时候，不要开心，这可能是分手的前奏。然而，量化开心度并不是一件容易的事情。人们往往更容易感知到自己「是否开心」，而非「多开心」或者「多不开心」。更重要的是，人和人的价值观是有很大差异的。如果两个差别很大的人在一起，就会经常遇到这种取舍。动不动就是我很开心你很不开心。这样的感情就会导致两个人情绪波动太大，矛盾太多。而两个价值观很相似的人在一起，或许生活中大部分事情都是两个人都开心或者都不开心，他们几乎不太用做这种取舍。理论固然有其可取之处，不过找到了对的人，这些就都不算是太大的问题了。","categories":[{"name":"碎碎念","slug":"碎碎念","permalink":"https://lolico.me/categories/%E7%A2%8E%E7%A2%8E%E5%BF%B5/"}],"tags":[]},{"title":"Java知识小记","slug":"Java知识小记","date":"2022-03-22T14:57:05.000Z","updated":"2022-05-02T03:45:10.806Z","comments":true,"path":"2022/03/22/Java知识小记/","link":"","permalink":"https://lolico.me/2022/03/22/Java%E7%9F%A5%E8%AF%86%E5%B0%8F%E8%AE%B0/","excerpt":"","text":"1、一个字符的String.length()是多少？Java中字符采用Unicode（UTF16）编码，即16位（2字节）一个单元，UTF16可以包含一个单元或两个单元，对于U+0000-U+FFFF范围内的字符采用2字节编码，大于U+FFFF的采用四字节编码。例如一些emoji或者生僻字，采用四字节编码及两单元，String#length()将返回2，如需返回字符数可使用String#codePointCount(0,length)。2、SpringSecurity使用了什么模式？构建者模式、责任链模式。3、SpringSecurity使用构建者模式最后构建的是一个什么？是一个Filter、而且是FilterChainProxy，其内部包含多个SecurityFilterChain，根据请求匹配一个SecurityFilterChain并应用其中的Filter。4、简单说一下Synchronized和AQS有什么不同？前者是JVM层面实现、后者是语言层面实现。前者根据不同锁实现方式不一样、后者是基于队列+CAS实现。后者相比前者提供了更灵活的API、比如是否响应中断、超时时间设置、可绑定多个条件队列等等前者只能是非公平锁、后者可实现公平锁，即先等待的线程先获取到锁。5、偏向锁、轻量级锁、重量级锁的升级过程简单说一下？在不存在锁竞争时是偏向锁、此时只使用了一次CAS设置对象头中的偏向线程ID；存在资源竞争时、在全局安全点撤销偏向锁升级为轻量级锁，轻量级锁使用CAS来修改对象头中持有锁的线程ID；在轻量级锁CAS竞争锁失败一定次数（默认10）后升级为重量级锁；重量级锁基于操作系统的Mutex Lock实现。6、三种锁是怎样确保线程安全的？使用Synchronized关键字时，会在字节码中插入monitorenter和monitorexit指令，当执行 monitorenter 指令时，线程试图获取锁也就是获取 对象监视器 monitor 的持有权，如果获取失败则根据锁类型自旋或者阻塞，从而确保线程安全。7、AQS的原理简单说一下？内部使用了什么数据结构与设计模式？AQS内部使用双向循环队列+CAS实现，使用了模版方法模式。8、ThreadLocal存不存在内存泄漏问题?ThreadLocalMap 中使用的 key 为 ThreadLocal 的弱引用,而 value 是强引用。所以，如果 ThreadLocal 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。这样一来，ThreadLocalMap 中就会出现 key 为 null 的 Entry。假如我们不做任何措施的话，value 永远无法被 GC 回收，这个时候就可能会产生内存泄露。ThreadLocalMap 实现中已经考虑了这种情况，在调用 set()、get()、remove() 方法的时候，会清理掉 key 为 null 的记录。但在使用完 ThreadLocal方法后 最好手动调用remove()方法以便及时回收资源。","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[]},{"title":"Netty中Channel的生命周期","slug":"Netty中Channel的生命周期","date":"2022-03-06T14:57:33.000Z","updated":"2022-05-02T03:45:10.806Z","comments":true,"path":"2022/03/06/Netty中Channel的生命周期/","link":"","permalink":"https://lolico.me/2022/03/06/Netty%E4%B8%ADChannel%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/","excerpt":"","text":"服务端父EventLoopGroup中的ChannelRegistered -&gt; Bind -&gt; Active -&gt; [Read -&gt; Read Complete] -&gt; Close -&gt; Inactive -&gt; Unregistered子EventLoopGroup中的ChannelRegistered -&gt; Active -&gt; [(Read/Write -&gt; Read Complete/Flush)、Event Triggered、Exception Caught] -&gt; Inactive -&gt;Unregistered客户端Registered -&gt; Connect -&gt; Active(Lazy Active) -&gt; [(Read/Write -&gt; Read Complete/Flush)、Event Triggered、Exception Caught、Disconnect] -&gt; Close -&gt; Inactive -&gt; Unregistered","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Netty","slug":"Netty","permalink":"https://lolico.me/tags/Netty/"}]},{"title":"AOP详解","slug":"AOP详解","date":"2020-07-22T15:01:12.000Z","updated":"2022-05-02T03:45:10.806Z","comments":true,"path":"2020/07/22/AOP详解/","link":"","permalink":"https://lolico.me/2020/07/22/AOP%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"什么是AOP？AOP（Aspect-oriented Programming），称为面向切面编程，作为面向对象的一种补充，用于处理系统中分布于各个模块的横切关注点，比如权限控制、事务管理、日志、缓存等等。AOP代理主要分为静态代理和动态代理，静态代理的代表为AspectJ；而动态代理则以Spring AOP为代表。静态代理一般在编译期或者加载期实现，动态代理是运行期实现。静态代理AspectJ的静态代理，不是基于代理的。它使用修改字节码的技术将通知织入到目标类，所以，在运行时的类已经不是原本的那个类，是经过修改的了。通常来说，你写的AOP相关的代码，和对象的结合过程叫做织入(weave)。AspectJ的织入过程，有可能发生在三个阶段：编译时织入(Compile-time weaving) 使用AspectJ的编译器ajc，在项目编译的阶段就将代码织入目标类编译后织入(Post-compile weaving) 使用AspectJ的编译器ajc，向javac编译出来的的class织入代码加载时织入(Load-time weaving) 使用特定的类加载器在类加载时期修改类字节码后加载进JVM从上面可以看出，在程序的运行阶段，我们使用的类都是已经织入了通知代码的（并不会创建出多余的对象），而不像Spring AOP，需要在运行的时候去生成动态代理或者生成类。所以说，AspectJ的运行效率相比动态代理生成的类要高一点。动态代理动态代理则不会修改字节码，而是在内存中生成一个代理对象，这个AOP对象包含了目标对象的全部方法，并且在特定的切点做了增强处理，并回调原对象的方法。所以动态代理是在方法层级上进行代理，代理细度上不如静态代理。生成AOP代理的入口Spring所有的代理AopProxy的创建最后都是ProxyCreatorSupport#createAopProxy这个方法，而这个方法如下：123456protected final synchronized AopProxy createAopProxy() &#123; if (!this.active) &#123; activate(); &#125; return getAopProxyFactory().createAopProxy(this);&#125;显然它又是调用了AopProxyFactory#createAopProxy方法，它的唯一实现为DefaultAopProxyFactory。它做了一个简单的逻辑判断：若实现类接口，使用JdkDynamicAopProxy去创建，否则使用ObjenesisCglibAopProxy。最终拿到AopProxy后，调用AopProxy#getProxy()就可以拿到代理对象，从而进行相应的工作了。我们基本有一共共识就是：默认情况下，若我们实现了接口，就实用JDK动态代理，若没有就实用CGLIB。那么接下来，就来看看代理对象的创建、执行的具体过程是如何的。AopProxy它是一个AOP代理的抽象接口。提供了两个方法，让我们可以获取对应 配置的AOP对象的代理：1234public interface AopProxy &#123; Object getProxy(); Object getProxy(@Nullable ClassLoader classLoader);&#125;它的实现类只有三个：JdkDynamicAopProxy 基于jdk动态代理生成代理对象CglibAopProxy 基于cglib生成一个代理子类ObjenesisCglibAopProxy 基于Objenesis扩展CglibAopProxy，提供不调用类的构造函数来创建代理对象。JdkDynamicAopProxy123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187final class JdkDynamicAopProxy implements AopProxy, InvocationHandler, Serializable &#123; private static final long serialVersionUID = 5531744639992436476L; private static final Log logger = LogFactory.getLog(JdkDynamicAopProxy.class); // 这里就保存这个AOP代理所有的配置信息，包括所有的增强器等等 private final AdvisedSupport advised; // 用于记录代理接口中是否定义了equals和hashCode方法 private boolean equalsDefined; private boolean hashCodeDefined; public JdkDynamicAopProxy(AdvisedSupport config) throws AopConfigException &#123; Assert.notNull(config, \"AdvisedSupport must not be null\"); // 至少需要一个增强器和目标实例才行 if (config.getAdvisors().length == 0 &amp;&amp; config.getTargetSource() == AdvisedSupport.EMPTY_TARGET_SOURCE) &#123; throw new AopConfigException(\"No advisors and no TargetSource specified\"); &#125; this.advised = config; &#125; @Override public Object getProxy() &#123; return getProxy(ClassUtils.getDefaultClassLoader()); &#125; // 创建代理对象 @Override public Object getProxy(@Nullable ClassLoader classLoader) &#123; if (logger.isTraceEnabled()) &#123; logger.trace(\"Creating JDK dynamic proxy: \" + this.advised.getTargetSource()); &#125; // 这部很重要，就是去找接口 我们看到最终代理的接口就是这里返回的所有接口们（除了我们自己的接口，还有Spring默认的一些接口） 大致过程如下： //1、获取目标对象自己实现的接口(最终肯定都会被代理的) //2、是否添加`SpringProxy`这个接口：目标对象实现对就不添加了，没实现过就添加 //3、是否新增`Adviced`接口，注意不是Advice通知接口。 实现过就不实现了，没实现过并且advised.isOpaque()为false就添加（默认会添加的） //4、是否新增DecoratingProxy接口。传入的第二个参数decoratingProxy为true，并且没实现过就添加（显然这里，首次进来是会添加的） //5、代理类的接口一共是目标对象的接口+上面三个接口SpringProxy、Advised、DecoratingProxy（SpringProxy是个标记接口而已，其余的接口都有对应的方法的） //DecoratingProxy 这个接口Spring4.3后才提供 Class&lt;?&gt;[] proxiedInterfaces = AopProxyUtils.completeProxiedInterfaces(this.advised, true); findDefinedEqualsAndHashCodeMethods(proxiedInterfaces); // 创建jdk动态代理对象，InvocationHandler传的this return Proxy.newProxyInstance(classLoader, proxiedInterfaces, this); &#125; // 找找看接口里有没有自己定义equals方法和hashCode方法，然后标记一下 // 注意此处用的是getDeclaredMethods，只会找当前类中的 private void findDefinedEqualsAndHashCodeMethods(Class&lt;?&gt;[] proxiedInterfaces) &#123; for (Class&lt;?&gt; proxiedInterface : proxiedInterfaces) &#123; Method[] methods = proxiedInterface.getDeclaredMethods(); for (Method method : methods) &#123; if (AopUtils.isEqualsMethod(method)) &#123; this.equalsDefined = true; &#125; if (AopUtils.isHashCodeMethod(method)) &#123; this.hashCodeDefined = true; &#125; if (this.equalsDefined &amp;&amp; this.hashCodeDefined) &#123; return; &#125; &#125; &#125; &#125; @Override @Nullable public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; Object oldProxy = null; boolean setProxyContext = false; TargetSource targetSource = this.advised.targetSource; Object target = null; try &#123; if (!this.equalsDefined &amp;&amp; AopUtils.isEqualsMethod(method)) &#123; // The target does not implement the equals(Object) method itself. return equals(args[0]); &#125; else if (!this.hashCodeDefined &amp;&amp; AopUtils.isHashCodeMethod(method)) &#123; // The target does not implement the hashCode() method itself. return hashCode(); &#125; else if (method.getDeclaringClass() == DecoratingProxy.class) &#123; // There is only getDecoratedClass() declared -&gt; dispatch to proxy config. return AopProxyUtils.ultimateTargetClass(this.advised); &#125; else if (!this.advised.opaque &amp;&amp; method.getDeclaringClass().isInterface() &amp;&amp; method.getDeclaringClass().isAssignableFrom(Advised.class)) &#123; // Service invocations on ProxyConfig with the proxy config... return AopUtils.invokeJoinpointUsingReflection(this.advised, method, args); &#125; Object retVal; if (this.advised.exposeProxy) &#123; // Make invocation available if necessary. oldProxy = AopContext.setCurrentProxy(proxy); setProxyContext = true; &#125; // Get as late as possible to minimize the time we \"own\" the target, // in case it comes from a pool. target = targetSource.getTarget(); Class&lt;?&gt; targetClass = (target != null ? target.getClass() : null); // Get the interception chain for this method. List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); // Check whether we have any advice. If we don't, we can fallback on direct // reflective invocation of the target, and avoid creating a MethodInvocation. if (chain.isEmpty()) &#123; // We can skip creating a MethodInvocation: just invoke the target directly // Note that the final invoker must be an InvokerInterceptor so we know it does // nothing but a reflective operation on the target, and no hot swapping or fancy proxying. Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args); retVal = AopUtils.invokeJoinpointUsingReflection(target, method, argsToUse); &#125; else &#123; // We need to create a method invocation... MethodInvocation invocation = new ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain); // Proceed to the joinpoint through the interceptor chain. retVal = invocation.proceed(); &#125; // Massage return value if necessary. Class&lt;?&gt; returnType = method.getReturnType(); if (retVal != null &amp;&amp; retVal == target &amp;&amp; returnType != Object.class &amp;&amp; returnType.isInstance(proxy) &amp;&amp; !RawTargetAccess.class.isAssignableFrom(method.getDeclaringClass())) &#123; // Special case: it returned \"this\" and the return type of the method // is type-compatible. Note that we can't help if the target sets // a reference to itself in another returned object. retVal = proxy; &#125; else if (retVal == null &amp;&amp; returnType != Void.TYPE &amp;&amp; returnType.isPrimitive()) &#123; throw new AopInvocationException( \"Null return value from advice does not match primitive return type for: \" + method); &#125; return retVal; &#125; finally &#123; if (target != null &amp;&amp; !targetSource.isStatic()) &#123; // Must have come from TargetSource. targetSource.releaseTarget(target); &#125; if (setProxyContext) &#123; // Restore old proxy. AopContext.setCurrentProxy(oldProxy); &#125; &#125; &#125; @Override public boolean equals(@Nullable Object other) &#123; if (other == this) &#123; return true; &#125; if (other == null) &#123; return false; &#125; JdkDynamicAopProxy otherProxy; if (other instanceof JdkDynamicAopProxy) &#123; otherProxy = (JdkDynamicAopProxy) other; &#125; else if (Proxy.isProxyClass(other.getClass())) &#123; InvocationHandler ih = Proxy.getInvocationHandler(other); if (!(ih instanceof JdkDynamicAopProxy)) &#123; return false; &#125; otherProxy = (JdkDynamicAopProxy) ih; &#125; else &#123; // Not a valid comparison... return false; &#125; // If we get here, otherProxy is the other AopProxy. return AopProxyUtils.equalsInProxy(this.advised, otherProxy.advised); &#125; @Override public int hashCode() &#123; return JdkDynamicAopProxy.class.hashCode() * 13 + this.advised.getTargetSource().hashCode(); &#125;&#125;CglibAopProxy","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://lolico.me/tags/Spring/"},{"name":"AOP","slug":"AOP","permalink":"https://lolico.me/tags/AOP/"}]},{"title":"Spring中ControllerAdvice失效的几种场景","slug":"Spring中ControllerAdvice失效的几种场景","date":"2020-07-07T15:01:12.000Z","updated":"2022-05-02T03:45:10.806Z","comments":true,"path":"2020/07/07/Spring中ControllerAdvice失效的几种场景/","link":"","permalink":"https://lolico.me/2020/07/07/Spring%E4%B8%ADControllerAdvice%E5%A4%B1%E6%95%88%E7%9A%84%E5%87%A0%E7%A7%8D%E5%9C%BA%E6%99%AF/","excerpt":"","text":"异步调用的方法中抛出异常Around切面在调用ProceedingJoinPoint#proceed时catch并且处理了异常","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://lolico.me/tags/Spring/"},{"name":"Web","slug":"Web","permalink":"https://lolico.me/tags/Web/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://lolico.me/tags/SpringBoot/"}]},{"title":"Stream消息队列在SpringBoot中的实践与踩坑","slug":"Stream消息队列在SpringBoot中的实践与踩坑","date":"2020-06-28T13:54:57.000Z","updated":"2022-05-02T03:45:10.806Z","comments":true,"path":"2020/06/28/Stream消息队列在SpringBoot中的实践与踩坑/","link":"","permalink":"https://lolico.me/2020/06/28/Stream%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%9C%A8SpringBoot%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5%E4%B8%8E%E8%B8%A9%E5%9D%91/","excerpt":"","text":"前言Redis5新增了一个Stream的数据类型，这个类型作为消息队列来使用时弥补了List和Pub/Sub的不足并且提供了更强大的功能，比如ack机制以及消费者组等概念，在有轻量消息队列使用需求时，使用这个新类型那是再好不过了。对于这个类型，在这里就不赘述了，想了解的话可以看一下这篇文章，在这里，我们就具体来讲一下在SpringBoot中的实践与踩坑。注意，SpringBoot版本需要大于2.2（即spring-data-redis需要大于2.2）。新API和类在开始正文之前，我们先简单了解一下在2.2引入的和Stream操作相关的方法和类。消息和消息ID的对象消息（或者称为记录）和消息ID在Spring-Data-Redis中使用Record和RecordId来表示。一个Record包含三部分内容：stream表示这个消息要发往那个Stream，也就是Stream的keyrecordId表示这个消息的ID，一般Redis服务器自动生成，也可以指定value表示消息内容SpringBoot为我们提供了五种消息类型的抽象：MapRecord、ObjectRecord、ByteRecord、ByteBufferRecord、StringRecord，以及一个消息ID类型：RecordId。这里另外说一下：其实除开ObjectRecord，其他几个Record都是通过继承MapRecord扩展而来的。StringRecord中的消息内容也并非仅仅是一个字符串，而是一个键值都为字符串类型的Map（ByteRecord、ByteBufferRecord同理）。而ObjectRecord最后也会使用HashMapper转换成MapRecord。为什么最后都是操作Map类型？这是因为Stream中的内容是以多个key-value这种键值对的形式存储的。那么我们怎样去创建一个消息对象呢？一般来说我们使用前两个消息类型比较多，所以Spring-Data-Redis很贴心的在Record这个顶级接口中提供了两个静态方法用于直接构造MapRecord和ObjectRecord：12345678static &lt;S, K, V&gt; MapRecord&lt;S, K, V&gt; of(Map&lt;K, V&gt; map) Assert.notNull(map, \"Map must not be null!\"); return StreamRecords.mapBacked(map);&#125;static &lt;S, V&gt; ObjectRecord&lt;S, V&gt; of(V value) &#123; Assert.notNull(value, \"Value must not be null!\"); return StreamRecords.objectBacked(value);&#125;我们可以看到，这两个方法实际上是调用了StreamRecords中提供的静态方法来创建，StreamRecords这个类提供了下面这些方法用于创建五种Record：123456ByteRecord rawBytes(Map&lt;byte[], byte[]&gt; raw) ByteBufferRecord rawBuffer(Map&lt;ByteBuffer, ByteBuffer&gt; raw) StringRecord string(Map&lt;String, String&gt; raw)&lt;S, K, V&gt; MapRecord&lt;S, K, V&gt; mapBacked(Map&lt;K, V&gt; map)&lt;S, V&gt; ObjectRecord&lt;S, V&gt; objectBacked(V value)RecordBuilder&lt;?&gt; newRecord() // 通过builder方式创建当然，我们还可以通过使用某个具体的Record类型的create静态方法来创建，下面是几个示例：12345678910String streamKey = \"channel:stream:key1\";//stream keyMailInfo mailInfo = new MailInfo(\"554205726@qq.com\", \"sendmail\");//定义一个Object类型的消息内容Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;() &#123;&#123; put(\"receiver\", \"534619360@qq.com\");&#125;&#125;; //定义一个Map类型的消息内容Record.of(mailInfo).withStreamKey(streamKey);Record.of(map).withStreamKey(streamKey).withId(RecordId.of(\"123\"));//指定idStreamRecords.objectBacked(mailInfo).withStreamKey(streamKey);StreamRecords.mapBacked(map).withStreamKey(streamKey).withId(RecordId.autoGenerate());//指定idObjectRecord.create(streamKey, mailInfo); //使用ObjectRecord的create静态方法创建如果我们不通过withId方法显示调用去指定id，那么默认的情况下就是使用RecordId.autoGenerate()自动生成。还有一个需要注意的地方就是在使用StreamRecords的方法来构建Record时一定要记住用withStreamKey方法来指定Stream Key。不管是消息或是消息ID，这些类基本都提供了扁平化的api来构造，使用起来还是很简单的。那么在构造了一个Record后怎么将其持久化到Redis的Stream类型中呢？向Stream添加消息（Record)使用RedisTemplate操作Stream：123456789101112131415String streamKey = \"channel:stream:key1\";//stream keyMailInfo mailInfo = new MailInfo(\"554205726@qq.com\", \"sendmail\");ObjectRecord&lt;String, MailInfo&gt; record = ObjectRecord.create(streamKey, mailInfo);RecordId id = record.getId(); //构造Record时使用的RecordIdRecordId recordId = redisTemplate.opsForStream().add(record); //返回的RecordIdid.getTimestamp(); //nullid.getSequence(); //nullid.shouldBeAutoGenerated(); //truerecordId.getTimestamp(); //not nullrecordId.getSequence(); //not nullrecordId.shouldBeAutoGenerated(); //false使用add方法来添加记录，该方法执行成功后返回添加的记录的id信息。注意下面的结果，这里有两个问题需要注意：为什么我们构造Record时使用的RecordId和添加记录返回的RecordId不同？这个问题很好理解，因为构造Record时不指定id时虽然是自动生成，但是这个自动生成并不是在构造时就自动生成好了的，而是在执行Redis命令持久化时Redis服务器来自动生成的，所以前者在获取时间戳和序号的时返回null。为什么添加记录返回的RecordId调用shouldBeAutoGenerated方法返回false呢，不是自动生成了吗？其实也很好理解，因为在持久化一条Stream的记录时，我们可以指定id，也可以选择让Redis来自动生成，那么这也就导致add方法执行成功获取到Redis返回的id信息后在构造RecordId时并不知道返回的这个id是我们之前指定的还是Redis自动生成的，所以说前者返回true，后者返回false并不难理解。说到这里，其实你去看一下Record构造时默认自动生成id是如何做到的就很好理解了。在这里稍微提一下：在构造Record时默认使用RecordId.autoGenerate()作为RecordId，而这个方法返回了一个匿名对象，这个匿名对象重写了上面那三个方法，前两个方法重写直接返回null，后者也就是shouldBeAutoGenerated方法返回true。实现消息队列在基本了解了SpringBoot2.2新增的几个Stream操作api和相关类之后，也就到了我们Stream实现消息队列的实践部分了。为了方便，下面我会以发送邮件为例来讲一下如何使用Strean来实现消息队列。为了方便后续的讲解，先构造一个简单的邮件信息类作为我们的消息内容：MailInfo.java123456789@Data@AllArgsConstructor@NoArgsConstructorpublic class MailInfo &#123; private String receiver; private String description;&#125;构造StreamMessageListenerContainer在使用Pub/Sub模式时，我们都是先创建一个RedisMessageListenerContainer容器，向这个容器注册监听器然后在onMessage方法中处理业务逻辑即可。那么使用Stream类型的话有没有提供一个类似的容器呢？答案是肯定的。在SpringBoot2.2提供了StreamMessageListenerContainer这个Stream类型专有的消息监听容器，而唯一的实现也就是DefaultStreamMessageListenerContainer。StreamMessageListenerContainer的构造函数相比RedisMessageListenerContainer多了一个StreamMessageListenerContainerOptions，这个对象是使用builder方式来创建的：123456789StreamMessageListenerContainerOptions&lt;String, ObjectRecord&lt;String, MailInfo&gt;&gt; options = StreamMessageListenerContainerOptions.builder() .batchSize(100) //一批次拉取的最大count数 .executor(executor) //线程池 .pollTimeout(Duration.ZERO) //阻塞式轮询 .targetType(MailInfo.class) //目标类型（消息内容的类型） .build();StreamMessageListenerContainer&lt;String, ObjectRecord&lt;String, MailInfo&gt;&gt; container = StreamMessageListenerContainer.create(redisConnectionFactory, options);在构造StreamMessageListenerContainerOptions时最关键的就是targetType、objectMapper以及设置序列化器这几个方法，这些参数的设置会直接影响到后续接收到消息后能否反序列化为java对象！由于这部分内容涉及源码过多，在后面一部分我们再针对这几个方法进行详细的探查。在构造完StreamMessageListenerContainer之后，现在该怎么注册消息监听器呢？我们接着往下看。注册StreamListener在Pub/Sub模式中我们使用addMessageListener(MessageListener, Topic)方法添加一个MessageListener到指定的Topic，那么在使用Stream消息的监听容器时，我们是使用receive方法。Spring-data-redis提供了三个方法用于注册StreamListener：123456789default Subscription receive(StreamOffset&lt;K&gt; streamOffset, StreamListener&lt;K, V&gt; listener) &#123; return register(StreamReadRequest.builder(streamOffset).build(), listener);&#125;default Subscription receive(Consumer consumer, StreamOffset&lt;K&gt; streamOffset, StreamListener&lt;K, V&gt; listener) &#123; return register(StreamReadRequest.builder(streamOffset).consumer(consumer).autoAcknowledge(false).build(), listener);&#125;default Subscription receiveAutoAck(Consumer consumer, StreamOffset&lt;K&gt; streamOffset, StreamListener&lt;K, V&gt; listener) &#123; return register(StreamReadRequest.builder(streamOffset).consumer(consumer).autoAcknowledge(true).build(), listener);&#125;如果你发现你哪里receive方法和我的不太一样？那么你使用的版本应该是2.2，这个版本的问题比较多，比如上面这个地方，使用第二个方法注册StreamListener，在消息被消费之后会自动ack，因为ConsumerStreamReadRequestBuilder的autoAck属性默认就是true（除非使用第一个方法指定StreamReadRequest），这个问题在2.3修复了，感兴趣可以去看看这部分源码，修补提交在这里。我个人最初就是使用的SpringBoot2.2.2，使用过程中发现问题真的有点很多。比如还有一处序列化器泛型类型错误导致StreamMessageListenerContainerOptions构造混乱的问题【修补提交】，所以说如果你想尝鲜，那么强烈建议使用SpringBoot最新发布的版本。Consumer和StreamOffset可以看到receive方法另外还需要Consumer和StreamOffset两个参数，Consumer1Consumer.from(\"group name\", \"consumer name\")Consumer表示消费者组中的某个消费者，这个东西只会在消费者组模式中用到。我们一般通过上面这种方式来创建，第一个参数表示消费者组，第二个参数表示消费者。StreamOffsetStreamOffset用于表示在某个Stream上的偏移量，它包含两部分内容，一个是stream的key，另一个是ReadOffset用于表示读取偏移量。前者应该不需要过多的解释，那么ReadOffset这个读取偏移量是干嘛用的呢？要搞清楚ReadOffset，我们首先要知道Stream中偏移量的含义，在Stream中偏移量既可以表示消费记录时的偏移量，又可以表示消费者组在Stream上的偏移量。还记得Redis中我们怎么读取Stream中的记录吗？通过xread命令也就是非消费者组模式直接读取，或者使用xreadgroup命令在消费者组中命令一个消费者去消费一条记录，这个时候，我们可以通过0、&gt;、$分别表示第一条记录、最后一次未被消费的记录和最新一条记录，这也就是ReadOffset的用途之一：用于表示直接读取或消费者组中消费者读取记录时的偏移量。那么还有另外的用途吗？当然了，还记得怎样创建消费者组吗？一般我们使用xgroup create命令创建一个消费者组时可以选择从Stream的第一条消息开始，或者Stream的中间某个记录开始，又或者从Stream的最新一条记录开始。也就分别代表了0、$。这也就是ReadOffset的用途之二：用于表示创建消费者组时该消费者组在Stream上的偏移量。理解ReadOffset最快最简单的方法就是在Redis-cli中用Redis命令操作一番。这其中还有一些值得注意的问题，比如创建消费者组时不能使用&gt;表示最后一次未被消费的记录；比如0表示从第一条开始并且包括第一条；$表示从最新一条开始但并不是指当前Stream的最后一条记录，所以使用$时最新一条也就是表示下一个xadd添加的那一条记录，所以说$在非消费者组模式的阻塞读取下才有意义！实现StreamListener同样的用Pub/Sub来类比，在Pub/Sub模式下我们实现的消息监听器是一般是MessageListener或者使用MessageListenerAdapter反射调用处理方法，在Strean消息队列的实现中必然也需要一个监听器用于处理真正的业务逻辑，这个类目前只有一个，也就是StreamListener：123456789101112131415161718public class StreamMessageListener implements StreamListener&lt;String, ObjectRecord&lt;String, MailInfo&gt;&gt; &#123; private final Logger logger = LoggerFactory.getLogger(StreamMessageListener.class); private final StringRedisTemplate stringRedisTemplate; public StreamMessageListener(StringRedisTemplate stringRedisTemplate) &#123; this.stringRedisTemplate = stringRedisTemplate; &#125; @Override public void onMessage(ObjectRecord&lt;String, MailInfo&gt; message) &#123; RecordId id = message.getId(); MailInfo messageValue = message.getValue(); logger.info(\"消费stream:&#123;&#125;中的信息:&#123;&#125;, 消息id:&#123;&#125;\", message.getStream(), messageValue, id); // 发邮件... stringRedisTemplate.opsForStream().acknowledge(MAIL_GROUP, message); //手动ack &#125;&#125;StreamListener和MessageListener差不多，只需要实现onMessage方法，只不过多了个泛型参数罢了。在实现消息监听器后也就可以使用receive方法进行注册了：123container.receive(Consumer.from(MAIL_GROUP, \"consumer-1\"), StreamOffset.create(MAIL_CHANNEL, ReadOffset.lastConsumed()), new StreamMessageListener(stringRedisTemplate));注册完成之后启动StreamMessageListenerContainer容器：1container.start();完整代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283@Componentpublic class StreamConsumerRunner implements ApplicationRunner, DisposableBean &#123; public static final String MAIL_CHANNEL = \"channel:stream:mail\"; public static final String MAIL_GROUP = \"group:mail\"; private final ThreadPoolTaskExecutor executor; private final RedisConnectionFactory redisConnectionFactory; private final StringRedisTemplate stringRedisTemplate; private StreamMessageListenerContainer&lt;String, ObjectRecord&lt;String, MailInfo&gt;&gt; container; public StreamConsumerRunner(ThreadPoolTaskExecutor executor, RedisConnectionFactory redisConnectionFactory, StringRedisTemplate stringRedisTemplate) &#123; this.executor = executor; this.redisConnectionFactory = redisConnectionFactory; this.stringRedisTemplate = stringRedisTemplate; &#125; @Override public void run(ApplicationArguments args) &#123; StreamMessageListenerContainerOptions&lt;String, ObjectRecord&lt;String, MailInfo&gt;&gt; options = StreamMessageListenerContainerOptions.builder() .batchSize(10) .executor(executor) .pollTimeout(Duration.ZERO) .targetType(MailInfo.class) .build(); StreamMessageListenerContainer&lt;String, ObjectRecord&lt;String, MailInfo&gt;&gt; container = StreamMessageListenerContainer.create(redisConnectionFactory, options); prepareChannelAndGroup(stringRedisTemplate.opsForStream(), MAIL_CHANNEL, MAIL_GROUP); container.receive(Consumer.from(MAIL_GROUP, \"consumer-1\"), StreamOffset.create(MAIL_CHANNEL, ReadOffset.lastConsumed()), new StreamMessageListener(stringRedisTemplate)); this.container = container; this.container.start(); &#125; private void prepareChannelAndGroup(StreamOperations&lt;String, ?, ?&gt; ops, String channel, String group) &#123; String status = \"OK\"; try &#123; StreamInfo.XInfoGroups groups = ops.groups(channel); if (groups.stream().noneMatch(xInfoGroup -&gt; group.equals(xInfoGroup.groupName()))) &#123; status = ops.createGroup(channel, group); &#125; &#125; catch (Exception exception) &#123; RecordId initialRecord = ops.add(ObjectRecord.create(channel, \"Initial Record\")); Assert.notNull(initialRecord, \"Cannot initialize stream with key '\" + channel + \"'\"); status = ops.createGroup(channel, ReadOffset.from(initialRecord), group); &#125; finally &#123; Assert.isTrue(\"OK\".equals(status), \"Cannot create group with name '\" + group + \"'\"); &#125; &#125; @Override public void destroy() &#123; this.container.stop(); &#125; public static class StreamMessageListener implements StreamListener&lt;String, ObjectRecord&lt;String, MailInfo&gt;&gt; &#123; private final Logger logger = LoggerFactory.getLogger(StreamMessageListener.class); private final StringRedisTemplate stringRedisTemplate; public StreamMessageListener(StringRedisTemplate stringRedisTemplate) &#123; this.stringRedisTemplate = stringRedisTemplate; &#125; @Override public void onMessage(ObjectRecord&lt;String, MailInfo&gt; message) &#123; RecordId id = message.getId(); MailInfo messageValue = message.getValue(); logger.info(\"消费stream:&#123;&#125;中的信息:&#123;&#125;, 消息id:&#123;&#125;\", message.getStream(), messageValue, id); stringRedisTemplate.opsForStream().acknowledge(MAIL_GROUP, message); &#125; &#125;&#125;注意prepareChannelAndGroup方法，在初始化容器时，如果key对应的stream或者group不存在时会抛出异常，所以我们需要提前检查并且初始化。测试添加一个测试接口：1234567@GetMapping(\"/sendMail\")public ResponseEntity&lt;RecordId&gt; sendMail(String receiver, String description) &#123; MailInfo mailInfo = new MailInfo(receiver, description); ObjectRecord&lt;String, MailInfo&gt; record = Record.of(mailInfo).withStreamKey(channel); RecordId recordId = redisTemplate.opsForStream().add(record); return ResponseEntity.ok(recordId);&#125;访问进行测试：12020-06-28 19:26:17.870 INFO 21900 --- [ task-1] reamConsumerRunner$StreamMessageListener : 消费stream:channel:stream:mail中的信息:MailInfo(receiver&#x3D;534619360@qq.com, description&#x3D;发送邮件), 消息id:1593343576237-0控制台输出日志，如果在redis-cli中使用xpending命令检查ack信息会发现也是0，因为我们虽然使用receive方法注册，但是在onMessage中手动提交了确认，当然，你也可以使用receiveAutoAck方法添加。实践中踩到的坑自动ack和泛型类型错误这两个问题在前面已经提到了并且在2.3已经修复，这里不多说。还是那句话，如果想尝鲜，那么强烈推荐使用SpringBoot最新发布的版本。RedisTemplate序列化器使用错误导致容器无法反序列化RedisTemplate的hashvalue的序列化器最初使用的json序列化器，导致容器监听到新消息反序列化时抛出异常：12345678910111213java.lang.IllegalArgumentException: Value must not be null! at org.springframework.util.Assert.notNull(Assert.java:198) at org.springframework.data.redis.connection.stream.Record.of(Record.java:81) at org.springframework.data.redis.connection.stream.MapRecord.toObjectRecord(MapRecord.java:147) at org.springframework.data.redis.core.StreamObjectMapper.toObjectRecord(StreamObjectMapper.java:132) at org.springframework.data.redis.core.StreamObjectMapper.map(StreamObjectMapper.java:158) at org.springframework.data.redis.core.StreamOperations.read(StreamOperations.java:458) at org.springframework.data.redis.stream.DefaultStreamMessageListenerContainer.lambda$getReadFunction$2(DefaultStreamMessageListenerContainer.java:232) at org.springframework.data.redis.stream.StreamPollTask.doLoop(StreamPollTask.java:138) at org.springframework.data.redis.stream.StreamPollTask.run(StreamPollTask.java:123) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)这是为什么呢？我们知道Redis中Stream中存的是键值对并且DefaultStreamOperations中操作的都是byte[]，也就是说我们虽然添加的是ObjectRecord，但是会先转换成MapRecord，然后再被转换成ByteRecord，最后进行序列化。来看一下add方法：123456public RecordId add(Record&lt;K, ?&gt; record) &#123; Assert.notNull(record, \"Record must not be null\"); MapRecord&lt;K, HK, HV&gt; input = StreamObjectMapper.toMapRecord(this, record); //转换成MapRecord ByteRecord binaryRecord = input.serialize(keySerializer(), hashKeySerializer(), hashValueSerializer()); //再使用序列化器转换成ByteRecord return execute(connection -&gt; connection.xAdd(binaryRecord), true);&#125;通过上面这个方法我们可以发现stream序列化时和其他类型不一样，我们在使用json序列化一个对象时都是直接进行的，而这里分了两步并且序列化器是用于第二部转换，那么ObjectRecord是怎么转换成MapRecord的呢？点进StreamObjectMapper.toMapRecord方法可以看到其实是通过ObjectRecord#toMapRecord方法完成的，这个方法需要一个HashMapper用于将对象的属性/属性值映射构造成Map类型，你会发现opsForStream方法重载了一个默认无参的方法，而这个方法默认使用的是ObjectHashMapper，在我们构造StreamMessageListenerContainerOptionsBuilder时调用targetType时默认使用的也是ObjectHashMapper。而这个ObjectHashMapper会将对象中的属性和属性值转换成byte[]形式，所以在第一步之后这个MapRecord中的值的类型已经是byte[]了，那么也就导致第二步在使用json序列化器转换为ByteRecord时出现这种情况：objectMapper.writeValueAsBytes(byte[])，这是一个测试实例：12345678@Testvoid test() throws JsonProcessingException &#123; ObjectMapper mapper = new ObjectMapper(); byte[] value = \"534619360@qq.com\".getBytes(); byte[] bytes = mapper.writeValueAsBytes(value); System.out.println(new String(bytes)); //输出\"NTM0NjE5MzYwQHFxLmNvbQ==\"&#125;反应到stream中值就变成了\\“NTM0NjE5MzYwQHFxLmNvbQ==\\“（引号需要转义）。为了便于理解，我们可以使用设置使用json序列化器的RedisTemplate进行add断点debug测试看一下转换后的两个Record中的内容：123456@Testvoid test() &#123; stringRedisTemplate.setHashValueSerializer(RedisSerializer.json()); MailInfo mailInfo = new MailInfo(\"534619360@qq.com\", \"send mail\"); stringRedisTemplate.opsForStream().add(Record.of(mailInfo).withStreamKey(channel));&#125;运行测试并断点查看MapRecord和ByteRecord：使用Redis Desktop Manager查看值：测试结束终端抛出上面提到的异常。这个问题解决办法就是使用String序列化器也就是使用StringRedisTemplate，因为这个序列化器不能序列化byte[]类型的对象，使用这个序列化器在序列化时如果已经是byte[]，那么就会直接返回原byte[]：更具体的细节可以跟着add方法debug一遍。ReadOffset使用错误导致group中消费者消费失败异常：1RedisCommandExecutionException: ERR The $ ID is meaningless in the context of XREADGROUP: you want to read the history of this consumer by specifying a proper ID, or use the &gt; ID to get new messages. The $ ID would just return an empty result set.上面StreamOffset中也提到了，这涉及到0、&gt;、$的使用场景和范围，如果出现这个异常，很有可能你在消费者组模式下设置消费者读取的offset时使用了ReadOffset.latest()，而这个对应着$，也就是最新一条记录。如果不明白那么你可能对这三个标识符的使用还不是很理解，最好的解决办法就是使用redis命令先完整的操作一遍。stream或者group不存在导致启动抛出异常同样在上面提到了，在构造StreamMessageListenerContainer时需要stream和group存在才可以。解决方法就是提前检查并初始化，上面已给出代码。总结其实在实践之初，我在网上也搜了很多相关的资料，但是发现这些资料基本都是使用redis-cli进行命令上的操作，并没有SpringBoot中实现。这次实践可谓是艰辛，由于目前该支持的迭代次数比较少，不乏一些bug或者小问题（2.3已经比较稳定），并且只有lettuce提供了stream类型的操作实现，而lettuce本身又有些小毛病，这些因素结合在一起也就导致这个过程花费了我整整两天时间，而这篇博客又花了整整一下午的时间才算完成，其中可能有些内容因为涉及东西比较多只能粗略提一下，并且语言组织上不太好可能不好去理解。话说回来，这篇文章也算是我自己实践后的一个个人总结吧，这个过程其实学到的东西还是很多的，也不枉费花了这么多时间。如果你发现文章有什么地方有问题或者有什么地方不理解，也欢迎在评论区留言一起交流~","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://lolico.me/tags/Spring/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://lolico.me/tags/SpringBoot/"},{"name":"Redis","slug":"Redis","permalink":"https://lolico.me/tags/Redis/"},{"name":"MessageQueue","slug":"MessageQueue","permalink":"https://lolico.me/tags/MessageQueue/"}]},{"title":"WPF单文件发布${basedir}无效导致日志无法写入的问题","slug":"WPF单文件发布basedir无效导致日志无法写入的问题","date":"2020-06-20T04:51:36.000Z","updated":"2022-05-02T03:45:10.806Z","comments":true,"path":"2020/06/20/WPF单文件发布basedir无效导致日志无法写入的问题/","link":"","permalink":"https://lolico.me/2020/06/20/WPF%E5%8D%95%E6%96%87%E4%BB%B6%E5%8F%91%E5%B8%83basedir%E6%97%A0%E6%95%88%E5%AF%BC%E8%87%B4%E6%97%A5%E5%BF%97%E6%97%A0%E6%B3%95%E5%86%99%E5%85%A5%E7%9A%84%E9%97%AE%E9%A2%98/","excerpt":"","text":"写在前面还是NLog问题，虽然NLog上手简单，配置容易，但是在NetCore3下还是有一些坑的，虽然这不是NLog的问题。因为这个问题百度一圈都无果，所以在这里记录一下，希望可以帮助到百度的同学（虽然这个站点没有提交到百度收录？逃~问题由来好，那么现在回到主题。前一阵子在用WPF来做一个First、Follow集算法模拟的工具，项目中使用NLog记录日志，在NetCore 3.1下作为单文件发布。发布后File类型的日志target没有将日志如期写入到文件中。并且仅在单文件发布并且fileName使用相对路径或者${basedir}指定基础目录时，才会出现这个问题，其实这个问题的解决方法很简单，只需稍微改一下就可以解决。解决使用${basedir:fixtempdir=true}指定基础目录。这个问题主要原因其实是NetCore3单文件发布时AppDomain.BaseDirectory无法正确引用基础路径的问题，并且微软并没有打算在NetCore3修复这个问题，或许NetCore5会修复这个问题吧，文末会放几个链接，感兴趣可以去看看。写在最后又水了一篇文章，最近文章质量有点差，上个月还鸽掉了一篇Aop详解的文章（其实一直都在draft中），感觉有点罪恶感 :D参考：PublishSingleFile excluding appsettings not working as expectedSingle file publish: AppContext.BaseDirectory doesn’t point to apphost directoryWhen .net core app published as single file - ${basedir} is wrongWhy cannot write log to files when WPF application publishing as a single fileBasedir layout renderer","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Asp.Net Core","slug":"Asp-Net-Core","permalink":"https://lolico.me/tags/Asp-Net-Core/"},{"name":"NLog","slug":"NLog","permalink":"https://lolico.me/tags/NLog/"},{"name":"WPF","slug":"WPF","permalink":"https://lolico.me/tags/WPF/"}]},{"title":"Asp.Net Core中使用NLog路由不生效问题","slug":"ASP-NET-CORE中使用NLog路由不生效问题","date":"2020-06-16T13:44:44.000Z","updated":"2022-05-02T03:45:10.806Z","comments":true,"path":"2020/06/16/ASP-NET-CORE中使用NLog路由不生效问题/","link":"","permalink":"https://lolico.me/2020/06/16/ASP-NET-CORE%E4%B8%AD%E4%BD%BF%E7%94%A8NLog%E8%B7%AF%E7%94%B1%E4%B8%8D%E7%94%9F%E6%95%88%E9%97%AE%E9%A2%98/","excerpt":"","text":"问题由来在一次将Asp.net Core默认日志换成NLog时，发现NLog配置文件中的设置不生效？具体的来说就是在NLog文件中设置的路由以及对应的日志级别只有在Info或者以上时才生效，而Debug、Trace级别则不会有日志输出。比如我的NLog配置：123456789101112131415161718192021222324252627282930313233&lt;?xml version=\"1.0\" encoding=\"utf-8\" ?&gt;&lt;nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.nlog-project.org/schemas/NLog.xsd NLog.xsd\" autoReload=\"true\" throwExceptions=\"false\" throwConfigExceptions=\"true\" internalLogLevel=\"Warn\" internalLogFile=\"$&#123;basedir&#125;/logs/internal.log\"&gt; &lt;variable name=\"logDirectory\" value=\"$&#123;basedir&#125;/logs\"/&gt; &lt;extensions&gt; &lt;add assembly=\"NLog.Web.AspNetCore\"/&gt; &lt;/extensions&gt; &lt;targets&gt; &lt;default-wrapper xsi:type=\"BufferingWrapper\" bufferSize=\"100\"/&gt; &lt;target xsi:type=\"File\" name=\"file\" fileName=\"$&#123;logDirectory&#125;/$&#123;shortdate&#125;-$&#123;level&#125;.log\" encoding=\"utf-8\" layout=\"$&#123;longdate&#125;|$&#123;uppercase:$&#123;level&#125;&#125;|$&#123;logger&#125;|$&#123;message&#125; $&#123;exception:format=tostring&#125;\" /&gt; &lt;/targets&gt; &lt;targets&gt; &lt;default-wrapper xsi:type=\"AsyncWrapper\"&gt; &lt;wrapper-target xsi:type=\"RetryingWrapper\"/&gt; &lt;/default-wrapper&gt; &lt;target xsi:type=\"ColoredConsole\" name=\"console\" detectConsoleAvailable=\"true\" layout=\"$&#123;longdate&#125;|$&#123;uppercase:$&#123;level&#125;&#125;|$&#123;logger&#125;|$&#123;message&#125;\"/&gt; &lt;/targets&gt; &lt;rules&gt; &lt;logger name=\"Microsoft.*\" minlevel=\"Debug\" writeTo=\"console\"/&gt; &lt;logger name=\"WebApplication.*\" minlevel=\"Trace\" writeTo=\"console\"/&gt; &lt;logger name=\"*\" minlevel=\"Info\" writeTo=\"file\" final=\"true\"/&gt; &lt;/rules&gt;&lt;/nlog&gt;按照rules中的设置，Microsoft命名空间下Debug级别的日志应该都可以输出在控制台中的，但是启动后控制台的输出只有：123452020-06-16 20:41:34.9142|INFO|Microsoft.Hosting.Lifetime|Now listening on: https:&#x2F;&#x2F;localhost:50012020-06-16 20:41:34.9353|INFO|Microsoft.Hosting.Lifetime|Now listening on: http:&#x2F;&#x2F;localhost:50002020-06-16 20:41:34.9353|INFO|Microsoft.Hosting.Lifetime|Application started. Press Ctrl+C to shut down.2020-06-16 20:41:34.9353|INFO|Microsoft.Hosting.Lifetime|Hosting environment: Development2020-06-16 20:41:34.9353|INFO|Microsoft.Hosting.Lifetime|Content root path: D:\\workspace\\csharp\\WebApplication\\WebApplication注意这里的格式已经应用了NLog中设置的布局，这说明配置文件被加载了并没有问题，但为什么日志级别的设置不生效呢？原因所在其实是因为appsettings.{env}.json中日志级别的设置覆盖了Nlog中的设置。在我们创建一个Asp.Net Core项目时，一般会帮我们创建好两个appsettings.json文件：appsettings.json12345678910&#123; \"Logging\": &#123; \"LogLevel\": &#123; \"Default\": \"Information\", \"Microsoft\": \"Warning\", \"Microsoft.Hosting.Lifetime\": \"Information\" &#125; &#125;, \"AllowedHosts\": \"*\"&#125;appsettings.Development.json123456789&#123; \"Logging\": &#123; \"LogLevel\": &#123; \"Default\": \"Information\", \"Microsoft\": \"Warning\", \"Microsoft.Hosting.Lifetime\": \"Information\" &#125; &#125;&#125;注意这里使用.net core3.1创建的模板，2.1创建的项目命名空间以及对应日志级别会有所不同。从这两个文件很容易发现默认的日志级别为Information并且Microsoft命名空间下的日志级别被设置成了Warning，当然也就覆盖了NLog中的设置，为什么会覆盖呢？可以思考一下。并且这里的设置能够影响到NLog中的设置还有一个前提：将NLog添加到容器，并且是以DI的方式来获取ILogger：12345678910private static IHostBuilder CreateHostBuilder(string[] args)&#123; return Host.CreateDefaultBuilder(args) .ConfigureLogging(logBuilder =&gt; &#123; logBuilder.ClearProviders() .AddNLog(\"NLog.config\"); &#125;) .ConfigureWebHostDefaults(webBuilder =&gt; webBuilder.UseStartup&lt;Startup&gt;());&#125;如果你是这样添加NLog，然后使用DI在需要记录日志的类中注入ILogger的话，那很可能就中招了。1private static readonly NLog.Logger _logger = NLog.LogManager.GetCurrentClassLogger();如果你不使用DI来注入而是使用上面这个方式来获取logger，那么就不存在这个问题。但是我们使用容器主要的目的不就是容器可以更方便的管理对象之间的依赖吗？更具体地说那就是DI。那这个问题该怎样解决呢？解决方法解决的方法其实很简单：首先删除appsettings.{env}.json中日志相关的设置，然后在注册NLog时设置最低日志级别为你所用到的最低级别（因为就算去掉了这些设置，默认的日志级别也是Information），这样一来，就相当于把日志级别控制和输出都交给NLog来管理。比如我上面的文件中给自己项目的命名空间设置了Trace并且已是最低级别，那么在删除appsettings.{env}.json中日志相关的设置后可以这样来添加NLog：1234567891011private static IHostBuilder CreateHostBuilder(string[] args)&#123; return Host.CreateDefaultBuilder(args) .ConfigureLogging(logBuilder =&gt; &#123; logBuilder.ClearProviders() .SetMinimumLevel(LogLevel.Trace) // 最低为Trace .AddNLog(_configFileRelativePath); &#125;) .ConfigureWebHostDefaults(webBuilder =&gt; webBuilder.UseStartup&lt;Startup&gt;());&#125;或者你也可以使用AddFilter来细分使得日志输出可以“交到”NLog手中。当然，如果你不想删除原有的设置并且不想通过SetMinimumLevel(LogLevel)方法来设置最低级别，你也可以在appsettings.{env}.json文件中设置命名空间和相应的日志级别来保证NLog中的设置不会被覆盖（因为这个文件在启动时会自动被加载）。总之，只需要保证NLog中日志级别的设置不会因为该文件或者默认的Information级别所覆盖即可。如果不使用DI来获取的话那就当我没说。（逃","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Asp.Net Core","slug":"Asp-Net-Core","permalink":"https://lolico.me/tags/Asp-Net-Core/"},{"name":"NLog","slug":"NLog","permalink":"https://lolico.me/tags/NLog/"}]},{"title":"部署Asp.Net Core应用时遇到的两个问题","slug":"部署ASP-NET-CORE应用时遇到的两个问题","date":"2020-06-12T12:08:19.000Z","updated":"2022-05-02T03:45:10.810Z","comments":true,"path":"2020/06/12/部署ASP-NET-CORE应用时遇到的两个问题/","link":"","permalink":"https://lolico.me/2020/06/12/%E9%83%A8%E7%BD%B2ASP-NET-CORE%E5%BA%94%E7%94%A8%E6%97%B6%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%A4%E4%B8%AA%E9%97%AE%E9%A2%98/","excerpt":"","text":"在一次部署Asp.Net Core应用时遇到了这么几个问题：启动应用后，从IConfiguration中获取不到连接字符串。使用nginx反代后，Identity框架页面跳转后域名被改写成了localhost或者主机名。问题一：应用使用sqlite数据库，在程序启动后创建并初始化数据库，本地开发启动并没有报错，但是部署到服务器却获取不到连接字符串，报错：百度和谷歌都无果，最初我还以为是程序中某个地方可能出错了，但是在WSL上经过多次测试，发现如果没有在执行文件的目录下启动了项目才会报这样的错误，这个问题很奇怪，猜测是Directory.GetCurrentDirectory()获取路径导致，并未求证。知道了问题所在那么解决的办法就很简单了，cd到执行文件目录启动即可。问题二：这个问题是宝塔面板导致的，在设置反代的发送域名后，并没有反应到配置文件中，也就是说在面板上设置proxy_set_header Host $host;后文件中并没有改过来，依旧是localhost或者$hostname，也就导致了页面跳转时域名变成了localhost或者主机名。解决的办法很简单，只需要手动修改nginx配置文件中的反代发送域名即可。在这之前，其实还遇到了一个和nginx反代相关的问题：如果使用nginx来代理目录，从而实现一个域名下部署多个项目，这样做之后就导致Asp.net Core应用全部404，网上搜索一番，有些类似的问题解答提到使用Microsoft.AspNetCore.HttpOverrides包，但是我照着操作一番后依旧没用，目前比较笨的解决办法就是mvc的路由前手动加前缀，更好的办法目前没有找到，如果你知道，还请评论告知~","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Asp.Net Core","slug":"Asp-Net-Core","permalink":"https://lolico.me/tags/Asp-Net-Core/"},{"name":"Nginx","slug":"Nginx","permalink":"https://lolico.me/tags/Nginx/"}]},{"title":"在JetBrains系产品中使用非商店发行版WSL","slug":"在JetBrains系产品中使用非商店发行版WSL","date":"2020-05-19T09:48:45.000Z","updated":"2022-05-02T03:45:10.810Z","comments":true,"path":"2020/05/19/在JetBrains系产品中使用非商店发行版WSL/","link":"","permalink":"https://lolico.me/2020/05/19/%E5%9C%A8JetBrains%E7%B3%BB%E4%BA%A7%E5%93%81%E4%B8%AD%E4%BD%BF%E7%94%A8%E9%9D%9E%E5%95%86%E5%BA%97%E5%8F%91%E8%A1%8C%E7%89%88WSL/","excerpt":"","text":"JetBrains产品对于WSL提供了一定的支持，但是其只支持Microsoft Store中发行的WSL，对于类似ArchWSL这种非商店发行版，在配置工具链时却不能够被发现。下面给出两个方法来解决这个问题。由于我目前只使用过ArchWSL这个非商店发行版的WSL，所以下面以ArchWSL为例，对于其他版本的WSL，理论上也行得通。第一种方法很简单，只需要复制执行文件到指定目录只需将Arch.exe文件拷贝一份到C:\\Users\\lolico\\AppData\\Local\\Microsoft\\WindowsApps目录下即可。注意，如果你安装了多个Arch，在拷贝时需要将每个版本对应的执行文件都拷贝到WindowsApps目录下。第二种方法是网上搜索到的一个方法，并且在RubyMine官方文档中提到了这个方法以RubyMine为例，修改wsl.distributions.xml文件：123456&lt;descriptor&gt; &lt;id&gt;Arch&lt;/id&gt; &lt;microsoft-id&gt;Arch&lt;/microsoft-id&gt; &lt;executable-path&gt;Arch.exe&lt;/executable-path&gt; &lt;presentable-name&gt;Arch Linux&lt;/presentable-name&gt;&lt;/descriptor&gt;executable-path使用执行文件的绝对路径。wsl.distributions.xml文件位于产品对应的配置文件夹下，对于不同版本，配置文件夹位置可能不一样。旧版本软件的配置文件夹在%HOMEPATH%下，此时该文件位于配置文件夹下的config\\options目录中。在2020.1版本，配置文件夹迁移到了%HOMEPATH%\\AppData\\Roaming\\JetBrains下，此时该文件位于配置文件夹下的options目录中。由于我一直使用ToolBox来安装并管理这些软件，所以说如果你并不是从ToolBox中安装的软件，新版本的配置文件夹可能仍然在%HOMEPATH%下。最后，还想说一句，在使用商店发行版时我们可以用类似\\\\wsl$\\Ubuntu这种路径来访问WSL的根目录，在使用非商店发行版时却不行，解决的办法还是上面提到第一个方法，拷贝文件到WindowsApps之后即可使用\\\\wsl$\\Arch来访问Arch的根目录。参考：^ Custom WSL distributions^ Support custom WSL distributive (not from Microsoft Store)","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"WSL","slug":"WSL","permalink":"https://lolico.me/tags/WSL/"},{"name":"IDEA","slug":"IDEA","permalink":"https://lolico.me/tags/IDEA/"},{"name":"WebStorm","slug":"WebStorm","permalink":"https://lolico.me/tags/WebStorm/"},{"name":"PyCharm","slug":"PyCharm","permalink":"https://lolico.me/tags/PyCharm/"}]},{"title":"SpringBoot2中AOP默认使用CGLIB代理","slug":"SpringBoot2中AOP默认使用CGLIB代理","date":"2020-05-03T11:18:32.000Z","updated":"2022-05-02T03:45:10.806Z","comments":true,"path":"2020/05/03/SpringBoot2中AOP默认使用CGLIB代理/","link":"","permalink":"https://lolico.me/2020/05/03/SpringBoot2%E4%B8%ADAOP%E9%BB%98%E8%AE%A4%E4%BD%BF%E7%94%A8CGLIB%E4%BB%A3%E7%90%86/","excerpt":"在一次偶然情况下发现SpringBoot开发的应用在没有使用@EnableAspectJAutoProxy注解的情况下，AOP还是可以正常工作。不经引起了我的注意，随后便猜测SpringBoot中是否存在一个自动配置类在不使用注解的情况下完成自动配置并开启了AOP。","text":"在一次偶然情况下发现SpringBoot开发的应用在没有使用@EnableAspectJAutoProxy注解的情况下，AOP还是可以正常工作。不经引起了我的注意，随后便猜测SpringBoot中是否存在一个自动配置类在不使用注解的情况下完成自动配置并开启了AOP。在Idea中尝试搜索AopAutoConfiguration，果然不出所料，有这么一个自动配置类：123456789101112131415161718192021222324252627@Configuration(proxyBeanMethods = false)@ConditionalOnProperty(prefix = \"spring.aop\", name = \"auto\", havingValue = \"true\", matchIfMissing = true)public class AopAutoConfiguration &#123; @Configuration(proxyBeanMethods = false) @ConditionalOnClass(Advice.class) static class AspectJAutoProxyingConfiguration &#123; @Configuration(proxyBeanMethods = false) @EnableAspectJAutoProxy(proxyTargetClass = false) @ConditionalOnProperty(prefix = \"spring.aop\", name = \"proxy-target-class\", havingValue = \"false\", matchIfMissing = false) static class jdkDynamicAutoProxyConfiguration &#123; &#125; @Configuration(proxyBeanMethods = false) @EnableAspectJAutoProxy(proxyTargetClass = true) @ConditionalOnProperty(prefix = \"spring.aop\", name = \"proxy-target-class\", havingValue = \"true\", matchIfMissing = true) static class CglibAutoProxyConfiguration &#123; &#125; &#125; // ...&#125;可以看到@ConditionalOnProperty注解中matchIfMissing属性的设置，也正是这个属性的设置使得我们在不使用@EnableAspectJAutoProxy注解开启AOP的情况下，AOP也可以正常工作。从这个自动配置类中还能够看出AOP默认使用Cglib代理。那么如果我们使用@EnableAspectJAutoProxy注解去指定默认不使用Cglib代理，有没有用呢？经过测试发现，使用@EnableAspectJAutoProxy注解显示指定是没有用的。那么该如何设置默认使用jdk动态代理呢？根据自动配置类能知道，我们只需要在application.properties中指定spring.aop.proxy-target-class=false或者设置spring.aop.auto=false关闭aop自动配置后自行使用@EnableAspectJAutoProxy注解进行设置。并且如果查看SpringBoot1.5.x中的这个自动配置类会发现默认是使用jdk动态代理，那么为什么在SpringBoot2.x中改为默认使用Cglib了呢？使用jdk动态代理会存在一个代理问题：目标对象一定要实现接口。因为jdk动态代理是基于接口的，并且意味着当使用@Autowired注入一个使用jdk代理生成的对象时必须使用接口。就像这样：12@AutowiredUserService userService;一旦使用实现类的方式进行注入就会失败：12@AutowiredUserServiceImpl userService;使用Cglib代理就不存在这个问题，原因就在于Cglib是使用子类的方式进行代理。当查看类似@EnableCaching、@EnableAsync、@EnableTransactionManagement注解中proxyTargetClass属性的注释，我们还会发现注释中说到，这个属性设置为true后会影响Spring管理的所有Bean使用的代理方式。但是我经过测试发现其他注解的这个属性设置为true时并不会影响@EnableAsync的代理方式。但是@EnableAsync的这个属性设置为true后会影响其他注解下对象的代理方式。(SpringBoot2.2.2下测试)注意：proxyTargetClass属性默认为false时并不意味着如果目标对象没有实现接口，生成代理类就会失败，这种情况下Spring会使用Cglib代理。参考：^ Use @EnableTransactionManagement(proxyTargetClass = true)^ @EnableTransactionManagement proxyTargetClass not control by spring.aop.proxyTargetClass","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://lolico.me/tags/Spring/"},{"name":"AOP","slug":"AOP","permalink":"https://lolico.me/tags/AOP/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://lolico.me/tags/SpringBoot/"}]},{"title":"SpringSecurity跨域","slug":"SpringSecurity跨域","date":"2020-04-26T16:01:12.000Z","updated":"2022-05-02T03:45:10.806Z","comments":true,"path":"2020/04/26/SpringSecurity跨域/","link":"","permalink":"https://lolico.me/2020/04/26/SpringSecurity%E8%B7%A8%E5%9F%9F/","excerpt":"写在前面在SpringSecurity中配置跨域，我相信所有用过SpringSecurity的人应该都知道，因为实在是太简单了。那我为什么还要写这篇文章呢？写这篇文章的目的当然不是去解释如何配置跨域，而是通过分析Spring对跨域支持的源码来感受设计中的优雅。先声明一下开发环境：SpringBoot：2.2.2","text":"写在前面在SpringSecurity中配置跨域，我相信所有用过SpringSecurity的人应该都知道，因为实在是太简单了。那我为什么还要写这篇文章呢？写这篇文章的目的当然不是去解释如何配置跨域，而是通过分析Spring对跨域支持的源码来感受设计中的优雅。先声明一下开发环境：SpringBoot：2.2.2正文既然说到SpringSecurity配置跨域，那么我们就先简单复习一下如何配置跨域。配置跨域我们都知道集成SpringSecurity后配置跨域我们只需要在继承WebSecurityConfigurerAdapter类，重写configure(HttpSecurity http)方法，开启cors并提供一个跨域配置源即可。下面是一个例子：开启跨域123456789101112131415161718192021222324@Overrideprotected void configure(HttpSecurity http) throws Exception &#123; http.sessionManagement() .sessionCreationPolicy(SessionCreationPolicy.STATELESS) // 前后端分离 .and() .csrf().disable() // 禁用csrf .cors(); // 跨域 // ... 省略其他配置&#125;// 提供一个CorsConfigurationSource// 这里直接注册成Bean即可，注意方法名必须是corsConfigurationSource，后面会解释// 也可以cors().configurationSource(corsConfigurationSource())指定@Beanpublic CorsConfigurationSource corsConfigurationSource() &#123; CorsConfiguration configuration = new CorsConfiguration(); configuration.addAllowedOrigin(\"*\"); // 根据实际的需要去设置 configuration.addAllowedMethod(\"*\"); // 同上 configuration.addAllowedHeader(\"*\"); configuration.setMaxAge(3600L); configuration.setAllowCredentials(true); UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource(); source.registerCorsConfiguration(\"/**\", configuration); return source;&#125;就如前面所说，只需要开启cors再提供一个跨域配置源即可。方法很简单，但这里有个坑需要注意一下。暴露公共接口时跨域的一个坑如果我们还重写了configure(WebSecurity web)方法，使用web.ignoring().antMatchers(ignorePaths)去暴露一个公共接口’/pub’那么上面的跨域配置对这个接口来说就没用，也就是说这个接口会出现跨域问题。然而我们原本就是为了提供公共接口’/pub’，但现在却有跨域问题，那怎么能行！！！（一般来说这个方法是对静态资源设置直接放行，而不是公共接口！）那这到底是为什么呢？因为SpringSecurity配置跨域支持，是通过CorsFilter过滤器来实现的，我们web.ignoring()中设置后对应的接口请求就不会经过CorsFilter来处理，这个接口当然就存在跨域问题了！之所以说这个方法是对静态资源设置直接放行，而不是公共接口也是这个原因，那正确的方法是什么呢？还是configure(HttpSecurity http)方法：123456789101112@Overrideprotected void configure(HttpSecurity http) throws Exception &#123; http.sessionManagement() .sessionCreationPolicy(SessionCreationPolicy.STATELESS) // 前后端分离 .and() .csrf().disable() // 禁用csrf .cors() // 跨域 .and() .authorizeRequests() .antMatchers(\"/pub/**\").permitAll() // 匿名通过认证 .anyRequest().authenticated() //剩下的任何请求都需要认证&#125;cors方法现在我们来看一下cors()方法，点进这个方法看看，其实很简单，就是应用了一个CorsConfigurer配置类。如果看过SpringSecurity自动配置，对形如xxxConfigurer的类名应该不陌生。这个Configurer其实就是在”FilterChain”上添加了一个过滤器，即CorsFilter我们都知道CorsFilter的构造方法需要一个CorsConfigurationSource，在请求到来时，使用CorsProcessor根据提供的CorsConfiguration去对请求进行处理（在CorsFilter中默认是DefaultCorsProcessor）而CorsConfiguration是通过CorsConfigurationSource#getCorsConfiguration方法获得的，所以说怎么获得CorsConfigurationSource至关重要。还记得上面在配置CorsConfigurationSource时，我们直接注册Bean而不是通过configurationSource()方法指定吗？这种方法为什么是可行的呢？来看一下CorsConfigurer是如何获得CorsConfigurationSource并构造CorsFilter的：CorsConfigurer#getCorsFilter1234567891011121314151617181920212223242526272829303132333435363738private CorsFilter getCorsFilter(ApplicationContext context) &#123; //如果指定了CorsConfigurationSource，那么用指定的 if (this.configurationSource != null) &#123; return new CorsFilter(this.configurationSource); &#125; boolean containsCorsFilter = context.containsBeanDefinition(CORS_FILTER_BEAN_NAME); //如果容器中已经有名字是’corsFilter‘的bean，则用已经有的 if (containsCorsFilter) &#123; return context.getBean(CORS_FILTER_BEAN_NAME, CorsFilter.class); &#125; boolean containsCorsSource = context.containsBean(CORS_CONFIGURATION_SOURCE_BEAN_NAME); //如果既没有指定，容器中也不存在名字是’corsFilter‘的CorsFilter //那么看一下容器中有没有名字是’corsConfigurationSource‘的CorsConfigurationSource //如果有，取出来作为CorsConfigurationSource if (containsCorsSource) &#123; CorsConfigurationSource configurationSource = context.getBean(CORS_CONFIGURATION_SOURCE_BEAN_NAME, CorsConfigurationSource.class); return new CorsFilter(configurationSource); &#125; //如果也没有corsConfigurationSource，看看类路径下存不存在HandlerMappingIntrospector这个类 boolean mvcPresent = ClassUtils.isPresent(HANDLER_MAPPING_INTROSPECTOR,context.getClassLoader()); if (mvcPresent) &#123; //如果存在 return MvcCorsFilter.getMvcCorsFilter(context); &#125; return null;&#125;static class MvcCorsFilter &#123; //内部类 private static final String HANDLER_MAPPING_INTROSPECTOR_BEAN_NAME = \"mvcHandlerMappingIntrospector\"; private static CorsFilter getMvcCorsFilter(ApplicationContext context) &#123; if (!context.containsBean(HANDLER_MAPPING_INTROSPECTOR_BEAN_NAME)) &#123; throw new NoSuchBeanDefinitionException(HANDLER_MAPPING_INTROSPECTOR_BEAN_NAME, \"A Bean named \" + HANDLER_MAPPING_INTROSPECTOR_BEAN_NAME +\" of type \" + HandlerMappingIntrospector.class.getName() + \" is required to use MvcRequestMatcher. Please ensure Spring Security &amp; Spring MVC are configured in a shared ApplicationContext.\"); &#125; // 从容器中取出HandlerMappingIntrospector作为CorsConfigurationSource HandlerMappingIntrospector mappingIntrospector = context.getBean(HANDLER_MAPPING_INTROSPECTOR_BEAN_NAME, HandlerMappingIntrospector.class); return new CorsFilter(mappingIntrospector); &#125; &#125;获取CorsConfigurationSource并构造CorsFilter的步骤注释里写的很清楚了，正常来说我们配置跨域配置源不管是直接指定也好，还是注册成Bean也好（注意Bean名字的要求），都是可以被获取到的。一般情况下，我们也的确是这样做的（直接提供一个CorsConfigurationSource）。但为什么最后有MvcCorsFilter.getMvcCorsFilter(context)这样一个调用？通过这个方法里抛出的异常信息不难猜测到是SpringSecurity为了兼容SpringMVC中配置跨域的方式。还记得不使用SpringSecurity时如何在SpringMVC中配置支持跨域吗？两种方式：将@CrossOrigin注解标注在支持跨域的接口上重写WebMvcConfigurer#addCorsMappings方法进行全局配置看到这里你可能会猜测：是不是HandlerMappingIntrospector实现了CorsConfigurationSource，并且是根据上面两种方式的配置来返回跨域配置的呢？事实上，的确是这样的。为了便于理解后面给出的代码，先来看看CorsFilter类和CorsConfigurationSource接口：CorsConfigurationSource1234public interface CorsConfigurationSource &#123; @Nullable CorsConfiguration getCorsConfiguration(HttpServletRequest request);&#125;跨域配置源，实现类要实现getCorsConfiguration方法返回一个CorsConfiguration跨域配置，其中包含允许那些域、请求方法、请求头，是否允许携带凭证，缓存时间是多久，允许携带的头属性等信息。CorsConfigurationSource有五个实现类：CorsInterceptorHandlerMappingIntrospectorPreFlightHandlerResourceHttpRequestHandlerUrlBasedCorsConfigurationSourceCorsFilter123456789101112131415161718192021222324252627public class CorsFilter extends OncePerRequestFilter &#123; private final CorsConfigurationSource configSource; private CorsProcessor processor = new DefaultCorsProcessor(); public CorsFilter(CorsConfigurationSource configSource) &#123; Assert.notNull(configSource, \"CorsConfigurationSource must not be null\"); this.configSource = configSource; &#125; public void setCorsProcessor(CorsProcessor processor) &#123; Assert.notNull(processor, \"CorsProcessor must not be null\"); this.processor = processor; &#125; @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException &#123; // 获取CorsConfiguration CorsConfiguration corsConfiguration = this.configSource.getCorsConfiguration(request); // 根据CorsConfiguration处理请求 boolean isValid = this.processor.processRequest(corsConfiguration, request, response); if (!isValid || CorsUtils.isPreFlightRequest(request)) &#123; return; &#125; filterChain.doFilter(request, response); &#125;&#125;DefaultCorsProcessor#processRequest中根据请求是否跨域，是否是预检请求以及CorsConfiguration等信息来对请求进行处理和在响应头中写入一些信息。具体的源码就不分析了，还是比较好理解的。前提是需要对CORS有一定的了解，可以看下HTTP访问控制（CORS）这篇文章。HandlerMappingIntrospectorHandlerMappingIntrospector比较特别，不要认为这是个拦截器，”Introspector”翻译成中文是内省者的意思。这个类在初始化后会调用afterPropertiesSet方法，将容器中所有的HandlerMapping添加到该类的handlerMappings这个List中。来看一下官方对于这个类的解释：1234Helper class to get information from the HandlerMapping that would serve a specific request.Provides the following methods: - getMatchableHandlerMapping(javax.servlet.http.HttpServletRequest) — obtain a HandlerMapping to check request-matching criteria against. - getCorsConfiguration(javax.servlet.http.HttpServletRequest) — obtain the CORS configuration for the request.这个类是一个帮助类，用于从HandlerMapping中获取请求的特定信息，提供了两个方法。第一个方法用于获取一个MatchableHandlerMapping来检查请求匹配条件，第二个方法用于获取适用于这个请求的CorsConfiguration跨域配置。我们重点关注第二个方法：HandlerMappingIntrospector#getCorsConfiguration1234567891011121314151617181920212223242526272829public CorsConfiguration getCorsConfiguration(HttpServletRequest request) &#123; Assert.notNull(this.handlerMappings, \"Handler mappings not initialized\"); HttpServletRequest wrapper = new RequestAttributeChangeIgnoringWrapper(request); for (HandlerMapping handlerMapping : this.handlerMappings) &#123; HandlerExecutionChain handler = null; try &#123; handler = handlerMapping.getHandler(wrapper); // 获取处理执行链 &#125; catch (Exception ex) &#123; // Ignore &#125; if (handler == null) &#123; continue; &#125; if (handler.getInterceptors() != null) &#123; //遍历拦截器，如果拦截器同时实现了CorsConfigurationSource则用这个拦截器作为跨域配置源 for (HandlerInterceptor interceptor : handler.getInterceptors()) &#123; if (interceptor instanceof CorsConfigurationSource) &#123; return ((CorsConfigurationSource) interceptor).getCorsConfiguration(wrapper); &#125; &#125; &#125; //从执行链获取处理器，如果处理器本身也实现了CorsConfigurationSource，则用处理器作为跨域配置源 if (handler.getHandler() instanceof CorsConfigurationSource) &#123; return ((CorsConfigurationSource) handler.getHandler()).getCorsConfiguration(wrapper); &#125; &#125; return null;&#125;这个CorsConfigurationSource实现类根据请求从HandlerMapping中获取获取HandlerExecutionChain执行链，再依次从执行链的拦截器和处理器中获取CorsConfigurationSource，如果获取到了再调用其HandlerMappingIntrospector#getCorsConfiguration方法返回跨域配置。具体来说就是那两个if判断。所以这么说来的话，HandlerMappingIntrospector虽然实现了CorsConfigurationSource但其本质有点像一个委托类？它检查请求对应的执行链上的拦截器和处理器有没有实现CorsConfigurationSource，如果有，再委托给这个CorsConfigurationSource来获取CorsConfiguration。所以说如果我们在一个Controller的接口上标注了@CrossOrigin注解，那么对应的，在拦截器中获取不到CorsConfiguration，就会从这个Handler上获取到CorsConfiguration，也就是将@CrossOrigin注解中提供的信息封装成了CorsConfiguration。那为什么还会先检查执行链中的拦截器呢？因为SpringMVC中还有第二种方法配置跨域支持，也就是上面提到的重写WebMvcConfigurer#addCorsMappings方法进行全局配置。那为什么重写这个方法添加跨域配置最后会注册成拦截器呢？（一个实现了CorsConfigurationSource的拦截器）这就要说到SpringBoot在WebMvc的自动配置、WebMvcConfigurer和HandlerMapping了。如果你有仔细看过SpringBoot在SpringMVC的自动配置方面的源码，你一定知道WebMvcConfigurationSupport这个最主要的配置类在注册HandlerMapping的时候会从一个CorsRegisty中获取跨域配置：（这里以RequestMappingHandlerMapping为例）WebMvcConfigurationSupport.java12345678910111213141516171819202122@Beanpublic RequestMappingHandlerMapping requestMappingHandlerMapping( @Qualifier(\"mvcContentNegotiationManager\") ContentNegotiationManager contentNegotiationManager, @Qualifier(\"mvcConversionService\") FormattingConversionService conversionService, @Qualifier(\"mvcResourceUrlProvider\") ResourceUrlProvider resourceUrlProvider) &#123; RequestMappingHandlerMapping mapping = createRequestMappingHandlerMapping(); mapping.setOrder(0); mapping.setInterceptors(getInterceptors(conversionService, resourceUrlProvider)); mapping.setContentNegotiationManager(contentNegotiationManager); mapping.setCorsConfigurations(getCorsConfigurations()); //设置跨域配置 // ...省略一大段set return mapping;&#125;protected final Map&lt;String, CorsConfiguration&gt; getCorsConfigurations() &#123; if (this.corsConfigurations == null) &#123; CorsRegistry registry = new CorsRegistry(); addCorsMappings(registry); //向CorsRegistry中添加跨域映射 this.corsConfigurations = registry.getCorsConfigurations(); //获取跨域配置 &#125; return this.corsConfigurations;&#125;addCorsMappings()方法是个空方法，并且只有DelegatingWebMvcConfiguration类重写了这个方法。实际上WebMvcConfigurationSupport这个类中用@Bean这个可传递的注解标注了很多方法但该类上并没有标注@Configuration，那么为什么还会起到配置类的作用呢？其实真正的配置类是DelegatingWebMvcConfiguration。DelegatingWebMvcConfiguration在DelegatingWebMvcConfiguration这个类上有个@Configuration注解，并且继承自WebMvcConfigurationSupport，实际上它就是个委托类。可以说这个类才是真正的配置类，去看看DelegatingWebMvcConfiguration这个类，相信你一定会发现什么！！！DelegatingWebMvcConfiguration中有WebMvcConfigurerComposite这么一个对象，并且将容器中所有WebMvcConfigurer注入进来：DelegatingWebMvcConfiguration.java12345678910111213@Configuration(proxyBeanMethods = false)public class DelegatingWebMvcConfiguration extends WebMvcConfigurationSupport &#123; // WebMvcConfigurer复合类 private final WebMvcConfigurerComposite configurers = new WebMvcConfigurerComposite(); // 将容器中所有WebMvcConfigurer添加到WebMvcConfigurerComposite @Autowired(required = false) public void setConfigurers(List&lt;WebMvcConfigurer&gt; configurers) &#123; if (!CollectionUtils.isEmpty(configurers)) &#123; this.configurers.addWebMvcConfigurers(configurers); &#125; &#125; // ...省略&#125;如果你去看了一下这个类的源码，你就会发现WebMvcConfigurer中有的方法这个类都有，并且这个委托类仅仅是将请求委托给configurers，来看看重写的addCorsMappings方法：DelegatingWebMvcConfiguration#addCorsMappings1234@Overrideprotected void addCorsMappings(CorsRegistry registry) &#123; this.configurers.addCorsMappings(registry);&#125;调用WebMvcConfigurerComposite#addCorsMappings，显而易见WebMvcConfigurerComposite是个复合的WebMvcConfigurer，他也实现了WebMvcConfigurer并且内部维护了一个List&lt;WebMvcConfigurer&gt; delegates列表，实现的所有方法会依次调用列表中WebMvcConfigurer对应的方法。（并且你还能发现WebMvcConfigurer中的方法都是作为回调方法并且大部分是返回void的）说到这里，不得不说一个题外话。如果看Spring源码比较多的话，就会发现Spring中类的命名都有规律可循并且某些后缀都是有特定意义的，比如xxxComposite、xxxConfigurer、Delegatingxxx、xxxDelegator等等，这样我们看到这个类名就立马能猜到它的作用。我们平时对WebMvc进行一些配置都是实现WebMvcConfigurer类，重写其中的方法。下面是一个例子：1234567891011121314@Configurationpublic class WebMvcConfig implements WebMvcConfigurer &#123; @Override public void addCorsMappings(CorsRegistry registry) &#123; registry.addMapping(\"/**\") .allowedOrigins(\"*\") .allowedHeaders(\"*\") .allowedMethods(\"*\") .allowCredentials(true) .maxAge(3600); &#125; // ...&#125;说到这，也就是相当于WebMvcConfigurationSupport#getCorsConfigurations方法会回调容器中所有WebMvcConfigurer实现类的addCorsMappings()方法，向CorsRegistry中添加跨域映射，然后再取出CorsConfiguration返回：12345678protected final Map&lt;String, CorsConfiguration&gt; getCorsConfigurations() &#123; if (this.corsConfigurations == null) &#123; CorsRegistry registry = new CorsRegistry(); addCorsMappings(registry); //向CorsRegistry中添加跨域映射 this.corsConfigurations = registry.getCorsConfigurations(); //获取跨域配置 &#125; return this.corsConfigurations;&#125;最后反应到AbstractHandlerMapping中的就是使用CorsConfiguration注册一个CorsInterceptor拦截器，这个拦截器是AbstractHandlerMapping中的一个内部类，继承自HandlerInterceptorAdapter，并且实现了CorsConfigurationSource。看到这里，如果没有了解过HandlerMapping，可能会一头雾水，可以看看我的这篇文章源码角度分析Spring容器启动阶段注册Controller处理器的流程，虽然不是讲HandlerMapping，但是相信在看完后，会对HandlerMapping有一个理解。CorsInterceptor12345678910111213141516171819private class CorsInterceptor extends HandlerInterceptorAdapter implements CorsConfigurationSource &#123; @Nullable private final CorsConfiguration config; public CorsInterceptor(@Nullable CorsConfiguration config) &#123; this.config = config; &#125; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler)throws Exception &#123; return corsProcessor.processRequest(this.config, request, response); &#125; @Override @Nullable public CorsConfiguration getCorsConfiguration(HttpServletRequest request) &#123; return this.config; &#125;&#125;这个类只重写了拦截器的preHandle方法，其他方法都是空方法。而且你能发现这个preHandle方法中的内容和CorsFilter#doFilterInternal方法基本是一模一样的，都是根据CorsConfiguration使用跨域处理器处理请求。看到这里，现在应该知道关于HandlerMappingIntrospector的猜测是没错的，并且知道了HandlerMappingIntrospector是如何与SpringMVC两种支持跨域的配置方式联系起来的，这里再次总结一下：首先获取请求对应的执行链上的拦截器，判断拦截器有没有实现CorsConfigurationSource（CorsInterceptor类），如果有则调用getCorsConfiguration获取CorsConfiguration后返回如果拦截器上获取失败，则判断处理器有没有实现CorsConfigurationSource（PreFlightHandler类），如果有则调用getCorsConfiguration获取CorsConfiguration后返回从而实现了兼容SpringMVC中两种配置跨域的方式。这其中最关键的几点就在于CorsConfigurer获取CorsConfigurationSource并且构造CorsFilter的步骤、HandlerMappingIntrospector获取CorsConfiguration的步骤，还有Spring回调WebMvcConfigurer对HandlerMapping进行设置跨域配置等信息的步骤其中还涉及到了SpringMVC中HandlerMapping、HandlerExecutionChain、Handler、Interceptor等相关知识。根据这次的分析，能得到几个结论：SpringMVC支持跨域两种方式一个是基于处理器实现，另一个是基于拦截器实现。SpringSecurity跨域是基于过滤器，并且兼容了SpringMVC的两种配置（使用HandlerMappingIntrospector“桥接”）。SpringSecurity中的CorsConfigurer使用HandlerMappingIntrospector来兼容SpringMVC跨域两种方式。HandlerMappingIntrospector获取CorsConfiguration时的优先级是先拦截器，再处理器。SpringBoot注册HandlerMapping或者说通过WebMvcAutoConfiguration自动配置来对WebMvc必要的组件进行装配和注入。WebMvcConfigurer是DelegatingWebMvcConfiguration类驱动WebMvcConfigurerComposite来进行回调的。并且经过这次的源码阅读，也是足足感受到Spring设计上的优雅。写在最后文章写的有点乱，并且有点跳跃。仅仅是跟着文章来看可能不大能看懂，最好在电脑上根据源码来阅读。这篇文章也仅仅是作为我个人在一次踩坑后好奇心大法，阅读源码后的一段总结以及感悟吧，自己能看懂并且以后还能看懂也就满意了。如果这篇文章有幸被你刷到并且你能够看懂我想表达的那我自然是更高兴。其实这个博客存在的理由也仅仅是为了记录自己学习过程中的感悟和总结，便于自己以后回顾，毕竟我比较健忘。所以需要记录下有必要的，并且在个人看来，这篇文章干货还是足足的，所以说更加有必要记录。其实在写文章之初我也不想写这么一篇文章，因为实在是太难写明白了，并且由于涉及到的东西比较分散很难进行组织，也可能我表达能力差的原因吧，但最终还是花了一下午加一晚上，在不断修改下产出了这么一篇很长很长很长的文章，可能是写过的字数最多的文章了吧😥。文章中可能有错别字也可能有错误的内容，如果你发现文章有什么错误的地方或者没表述清楚的内容，欢迎在评论中交流。","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://lolico.me/tags/Spring/"},{"name":"Web","slug":"Web","permalink":"https://lolico.me/tags/Web/"},{"name":"Security","slug":"Security","permalink":"https://lolico.me/tags/Security/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://lolico.me/tags/SpringBoot/"},{"name":"CORS","slug":"CORS","permalink":"https://lolico.me/tags/CORS/"}]},{"title":"VueJS学习笔记","slug":"Vue学习笔记","date":"2020-04-24T14:47:31.000Z","updated":"2022-05-02T03:45:10.806Z","comments":true,"path":"2020/04/24/Vue学习笔记/","link":"","permalink":"https://lolico.me/2020/04/24/Vue%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"写在前面原本是打算写一个VueJS学习笔记专栏，用于记录vue学习过程中的一些感想，但后来想想，如此做实在是太麻烦，并且每篇文章的篇幅也会比较短，所以现在考虑直接在这一篇博文中进行总结。将学习过程中的感谢或者踩得一些坑直接记录在此一篇文章中，尽量做到每个点都短小精悍。该篇博文并非最终稿，内容会随着文章的更新不断丰富。官方中文文档：Guide：https://cn.vuejs.org/v2/guide/API：https://cn.vuejs.org/v2/api/Style Guide：https://cn.vuejs.org/v2/style-guide/Examples：https://cn.vuejs.org/v2/examples/下面大部分内容都可以从官方文档中找到。这篇总结，仅将我个人认为有必要记录的进行汇总，以方便后续查找和回顾。正文在选项属性或者回调方法使用箭头函数会导致在方法内使用this获取不到vue实例错误示范12created: () =&gt; console.log(this.a)vm.$watch('a', newValue =&gt; this.myMethod())事件总线机制下，监听总线事件的回调方法要使用箭头函数，否则this指代总线实例。12345mounted()&#123; // 挂载后执行 EventBus.$on('event-name',data =&gt; &#123; // 这里要用箭头函数，否则this指代EventBus this.data = data; &#125;)&#125;v-bind、v-on、v-slot指令使用动态指令参数（2.6.0+）123&lt;a :[attr]=\"value\"&gt;...&lt;/a&gt;&lt;a @[event]=\"value\"&gt;...&lt;/a&gt;&lt;template #[solt]&gt;...&lt;/template&gt;attr、event和solt会作为一个javascript表达式进行求值在DOM中使用模板时，避免使用大写字符来命名键名，因为浏览器会把attribute名全部强制转换为小写。数据一般是从父组件流向子组件的，prop的值会因父组件中数据的改变而改变。不要修改prop的值，如果一定要这么做，请使用计算属性或者data。计算属性默认只有getter，但是我们也可以提供一个setter。1234567891011121314computed: &#123; fullName: &#123; // getter get: function () &#123; return this.firstName + ' ' + this.lastName &#125;, // setter set: function (newValue) &#123; var names = newValue.split(' ') this.firstName = names[0] this.lastName = names[names.length - 1] &#125; &#125;&#125;父组件中的data可以是一个对象也可以是一个方法，但是子组件的data属性必须是一个方法。由于JavaScript的限制，Vue不能检测数组和对象的变化。也就是说对对象的属性或数组进行修改添加删除不会反应到视图中（但值的却改变了），可以使用vm.$set实例方法（全局方法的别名），或Vue.set全局方法。123456789var vm = new Vue(&#123; data:&#123; lisi:&#123; age: 16 &#125; &#125;&#125;)vm.lisi.age = 18; // 直接对对象属性进行修改是不会直接响应到视图中vm.$set(this.lisi,'age',18); // 响应式v-if和v-show的异同：v-if指令是直接销毁和重建DOM达到让元素显示和隐藏的效果v-show指令通过修改元素的display属性让其显示或者隐藏使用v-cloak指令解决页面加载时闪烁的问题事件修饰符、按键修饰符以及系统修饰键使用ref属性在父组件中调用子组件的方法。123456789101112131415161718192021222324252627282930313233343536373839&lt;div id=\"app\"&gt; &lt;button @click=\"add\"&gt; Click this button &#123;&#123;count&#125;&#125; times.&lt;/button&gt; &lt;children ref=\"child\"&gt;&lt;/children&gt;&lt;/div&gt;&lt;template id=\"btn\"&gt; &lt;div&gt; &lt;button @click=\"add\"&gt; Click this button &#123;&#123;count&#125;&#125; times.&lt;/button&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; var btn = &#123; template: '#btn', data() &#123; return &#123; count: 0 &#125; &#125;, methods: &#123; add() &#123; this.count++; &#125; &#125; &#125; const vm = new Vue(&#123; el: '#app', data:&#123; count: 0 &#125;, methods: &#123; add() &#123; this.count++; this.$refs.child.add(); // 调用子组件方法 &#125; &#125;, components: &#123; 'children': btn &#125; &#125;)&lt;/script&gt;","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Vue.js","slug":"Vue-js","permalink":"https://lolico.me/tags/Vue-js/"}]},{"title":"修改评论插件为gitalk","slug":"修改评论插件为gitalk","date":"2020-04-24T08:45:20.000Z","updated":"2022-05-02T03:45:10.806Z","comments":true,"path":"2020/04/24/修改评论插件为gitalk/","link":"","permalink":"https://lolico.me/2020/04/24/%E4%BF%AE%E6%94%B9%E8%AF%84%E8%AE%BA%E6%8F%92%E4%BB%B6%E4%B8%BAgitalk/","excerpt":"","text":"正式将评论插件由valine更改为gitalk，提高了评论的门槛，但考虑到文章受众以及博客类型，还是可以接受的。之前的评论丢失，后续也可能会考虑回到valine。","categories":[{"name":"不正常的文章","slug":"不正常的文章","permalink":"https://lolico.me/categories/%E4%B8%8D%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[]},{"title":"记一次无法获取Vue实例的坑","slug":"记一次无法获取Vue实例的坑","date":"2020-04-22T14:16:44.000Z","updated":"2022-05-02T03:45:10.810Z","comments":true,"path":"2020/04/22/记一次无法获取Vue实例的坑/","link":"","permalink":"https://lolico.me/2020/04/22/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%97%A0%E6%B3%95%E8%8E%B7%E5%8F%96Vue%E5%AE%9E%E4%BE%8B%E7%9A%84%E5%9D%91/","excerpt":"不要在选项属性或回调上使用箭头函数，比如created: () =&gt; console.log(this.a)或vm.$watch(&#39;a&#39;, newValue =&gt; this.myMethod())。因为箭头函数并没有this，this会作为变量一直向上级词法作用域查找，直至找到为止，经常导致Uncaught TypeError: Cannot read property of undefined或Uncaught TypeError: this.myMethod is not a function之类的错误。","text":"不要在选项属性或回调上使用箭头函数，比如created: () =&gt; console.log(this.a)或vm.$watch(&#39;a&#39;, newValue =&gt; this.myMethod())。因为箭头函数并没有this，this会作为变量一直向上级词法作用域查找，直至找到为止，经常导致Uncaught TypeError: Cannot read property of undefined或Uncaught TypeError: this.myMethod is not a function之类的错误。错误示范：12345678910111213&lt;el-button type=\"primay\" icon=\"el-icon-plus\" @click=\"add\"&gt;&lt;/el-button&gt;&lt;p&gt;&#123;&#123;count&#125;&#125;&lt;/p&gt;&lt;script&gt; const app = new Vue(&#123; // ... data: &#123; count: 1 &#125;, methods: &#123; add: () =&gt; this.count++ &#125; &#125;);&lt;/script&gt;正确示范：12345678910111213&lt;script&gt; const app = new Vue(&#123; // ... methods: &#123; add: function () &#123; this.count++ &#125;, minus() &#123; this.count-- &#125; &#125; &#125;);&lt;/script&gt;","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Vue.js","slug":"Vue-js","permalink":"https://lolico.me/tags/Vue-js/"}]},{"title":"Git连接多个GitHub账号","slug":"Git连接多个GitHub账号","date":"2020-04-15T11:11:50.000Z","updated":"2022-05-02T03:45:10.806Z","comments":true,"path":"2020/04/15/Git连接多个GitHub账号/","link":"","permalink":"https://lolico.me/2020/04/15/Git%E8%BF%9E%E6%8E%A5%E5%A4%9A%E4%B8%AAGitHub%E8%B4%A6%E5%8F%B7/","excerpt":"前言用ssh连接GitHub，需要在GitHub账号上传唯一的公钥。当我们需要连接两个或多个GitHub账号，上传同一个公钥是不允许的，那么该如何设置才能在一台电脑上连接多个GitHub账号呢？","text":"前言用ssh连接GitHub，需要在GitHub账号上传唯一的公钥。当我们需要连接两个或多个GitHub账号，上传同一个公钥是不允许的，那么该如何设置才能在一台电脑上连接多个GitHub账号呢？创建密钥并上传到GitHub假设我们已经有一对默认的密钥id_rsa、id_rsa.pub关联了a账号，现在我们来为b账号创建一个密钥：1ssh-keygen -t rsa -f ~/.ssh/id_rsa_b -C \"youmail@example.com\"注意文件名不要与其他的密钥重复，否则会覆盖之前的密钥。windows下使用绝对路径：C:\\Users\\xxx\\.ssh\\id_rsa_b接下来我们就可以在用户目录下的.ssh文件夹中找到id_rsa_b和id_rsa_b.pub两个文件，将id_rsa_b.pub文件中的内容保存到b账号的ssh keys中。配置身份验证使用的密钥接下来我们要做的就是对不同账号配置使用不同的密钥去连接github。在.ssh文件夹中创建一个config文件（无扩展名），填入以下内容：1234567891011# defaultHost github.com HostName github.com PreferredAuthentications publickey IdentityFile ~&#x2F;.ssh&#x2F;id_rsa# bHost b.github.com HostName github.com PreferredAuthentications publickey IdentityFile ~&#x2F;.ssh&#x2F;id_rsa_b在这部分配置中我们使用不同的主机标识去映射同一个HostName即github.com，但是我们使用不同的密钥文件去进行身份验证。配置中的Host在不和其他Host重复的情况下可以随意填写，但是建议使用一眼就能看懂的标识（并且这个标识在后面是需要用到的）到这里，其实所有的工作都已经完成。在进行下一步操作前我们先测试ssh是否能连接到github：12ssh -T git@github.comssh -T git@b.github.com不出意外，我们将看到验证成功的提示。如果提示 CreateProcessW failed error:2，先将config文件中的代理设置注释便可，实际上并不影响后续对仓库的推送。对b账号的仓库单独设置用户名和邮箱现在我们要做的就是对b账号下的仓库进行设置，因为在原本只有一个账号时，我们应该都用过下面这个命令来对git设置一个全局的用户名和邮箱：12git config --global user.name \"a\"git config --global user.email \"a@example.com\"现在我们当然不能对b账号下的仓库也使用全局的用户名和邮箱。如果使用全局的邮箱将b的仓库push到github，那么在github提交记录中看到的提交者将会是a，所以说我们需要对b账号下的仓库单独配置用户名和邮箱，进入项目文件夹：12git config user.name \"b\"git config user.email \"b@example.com\"邮箱要使用b账号注册github时使用的邮箱，因为github提交记录中的提交者是根据这个邮箱来查找的，这也是不能使用全局邮箱后提交者是a的原因。修改远程仓库的地址接下来我们还要重新设置远程仓库的地址，因为克隆仓库或者创建github仓库添加远程仓库地址时使用的主机标识默认是github.com，然而在config文件中对这个Host是使用~/.ssh/id_rsa密钥去验证，所以当我们本地已有b账号下的仓库或者未来克隆b账号下的仓库时要修改默认的远程仓库地址：12git remote rm origingit remote add origin git@b.github.com:b/repo.git注意不要照抄，根据config文件中配置的Host，github账号以及仓库名去设置‘@’符号后面的东西。所有的工作都已经完成，push测试一下：1git push origin master如果我们单纯的使用git push可能会报错，因为虽然添加了远程仓库，但是并没有设置本地分支具体跟踪哪个上游分支。使用-u或--set-upstream-to选项运行git branch来显式地设置：1git branch -u origin/master master总结总的来说，我们就是使用了不同的主机标识去映射github.com，并且对不同的标识在连接github时使用相应的密钥去验证身份。我们设置多个标识，相应的，我们也要修改远程仓库使用的Host标识（因为克隆下来的仓库的远程地址Host标识默认使用github.com）。虽然上面我们是拿两个账号来举例子，但是对于多个账号，设置的方法还是一模一样的。","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"git","slug":"git","permalink":"https://lolico.me/tags/git/"}]},{"title":"python3安装dlib库","slug":"python3安装dlib库","date":"2020-04-12T06:44:09.000Z","updated":"2022-05-02T03:45:10.806Z","comments":true,"path":"2020/04/12/python3安装dlib库/","link":"","permalink":"https://lolico.me/2020/04/12/python3%E5%AE%89%E8%A3%85dlib%E5%BA%93/","excerpt":"python3编译安装dlib库十分麻烦，这里提供已经编译好的whl文件，使用pip直接安装即可。","text":"python3编译安装dlib库十分麻烦，这里提供已经编译好的whl文件，使用pip直接安装即可。python3.6下载：dlib-19.8.1-cp36-cp36m-win_amd64.whlmd5：9a704406fbb4036f70b5f174fec9db1fsha1：e2e49b82b8dee6a9483362713239558c42c38feapython3.7下载：dlib-19.17.99-cp37-cp37m-win_amd64.whlmd5：b8c35e6e0098a7ece3e1a6935bbf1ae8sha1：886f510821c3033649edcf86ea80ec1157f0b1a7python3.8下载：dlib-19.19.0-cp38-cp38-win_amd64.whlmd5：7e00b04c3cf468e102b338d6837f4d5dsha1：129d0142f1232d60c6571dc07eacdcd392b92f7b安装：1$ pip install dlib-xx.xx.xx-cpxx-cpxx-win_amd64.whl #安装相应的文件","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://lolico.me/tags/Python/"},{"name":"pip","slug":"pip","permalink":"https://lolico.me/tags/pip/"},{"name":"dlib","slug":"dlib","permalink":"https://lolico.me/tags/dlib/"}]},{"title":"解锁网易云音乐","slug":"解锁网易云音乐","date":"2020-03-23T10:26:55.000Z","updated":"2022-05-02T03:45:10.810Z","comments":true,"path":"2020/03/23/解锁网易云音乐/","link":"","permalink":"https://lolico.me/2020/03/23/%E8%A7%A3%E9%94%81%E7%BD%91%E6%98%93%E4%BA%91%E9%9F%B3%E4%B9%90/","excerpt":"","text":"前言通过配置下文中的代理，实现解锁网易云无版权音乐以及试听音乐，文中使用到的项目：UnblockNeteaseMusic。注意：互联网并非法外之地，此代理完全免费并仅用作学习与交流，使用过程中出现任何问题本人概不负责。如发现任何收费倒卖等行为请及时举报并反馈。食用方法使用前你需要知道：服务端已做限制：仅允许代理网易云相关域名和ip的请求，其他请求一律拒绝。由于服务器带宽只有5Mbps，所以理论速度不会超过640kb/s。如果使用的人比较多，可能出现加载比较慢的现象。建议网易云音乐内开启边听边存，常听的歌下载到本地。最后，你也可以通过文末的打赏按钮对我进行打赏鼓励~（大雾现提供两种方法，不想折腾的使用方法一（局限性较大），否则请选择方法二（推荐）。方法一：系统代理PAC使用系统代理PAC解锁是最简单的方法，缺点是 Android 和 iOS 只能在连接WiFi的环境下使用。下面介绍不同平台系统代理PAC的设置方法，对号入座。Windows以 Windows 10 为例，进入「Windows 设置」&gt;「网络和 Internet」&gt;「代理」&gt;「自动设置代理」&gt;「使用设置脚本」，填写以下地址：1http:&#x2F;&#x2F;music.lolico.me:39000&#x2F;proxy.pac进入网易云音乐「设置」&gt;「工具」&gt;「Http代理」，选择「使用 IE 代理设置」。MacOS进入「系统偏好设置」&gt;「网络」&gt;「高级」&gt;「代理」，填写以下地址：1http:&#x2F;&#x2F;music.lolico.me:39000&#x2F;proxy.pacAndroid进入「设置」&gt;「WLAN」&gt;「修改网络」&gt;「高级选项」&gt;「代理」&gt;「代理自动配置」（不同机型设置的地方不一样，也可能在wifi右边的感叹号中），填写以下地址：1http:&#x2F;&#x2F;music.lolico.me:39000&#x2F;proxy.paciOS首先下载CA证书（打不开的请挂代理），前往“设置-通用-描述文件”，安装「UnblockNeteaseMusic Root CA」，然后在“设置-通用-关于本机-证书信任设置”处开启对「UnblockNeteaseMusic Root CA」的信任，最后给当前连接的wifi配置http代理，选择自动并填入以下地址：1http:&#x2F;&#x2F;music.lolico.me:39000&#x2F;proxy.pac方法二：代理软件使用代理软件，任何网络环境都可用，下面放上不同平台主流代理软件的使用步骤，至于文中没有提到的客户端，能力者自行根据提供的现有配置修改。Clash for Windows👉安装软件👉导入配置文件👉进入「General」，开启「System Proxy」👉进入网易云音乐「设置」&gt;「工具」&gt;「Http代理」，选择「使用 IE 代理设置」。Clash for MacOS👉安装软件👉导入配置文件Clash for Android👉安装软件👉导入配置文件👉保存后应用此配置👉回到主界面启动代理注意：鉴于安卓端导入配置文件无法调起Clash进行自动导入，请手动导入配置：（最新版已支持，上方直接下载）👉进入Clash应用，依次点击「配置」&gt;「新配置」&gt;「从URL导入」👉填写名称：lolico.me，URL地址：https://lolico.me/subscribe/Clash/config.yaml ，自动更新：1440👉保存后选中此配置👉回到主界面启动代理Clash配置中有多个节点，当节点不可用时，请切换至其他节点或尝试更新配置文件。iOS首先下载CA证书（打不开的请挂代理），前往“设置-通用-描述文件”，安装「UnblockNeteaseMusic Root CA」，然后在“设置-通用-关于本机-证书信任设置”处开启对「UnblockNeteaseMusic Root CA」的信任。Shadowrocket👉安装软件👉导入节点👉导入配置QuantumultX👉安装软件👉导入配置👉进入应用，长按🎸网易云音乐策略组并添加解锁节点这里另外再提供一个包含：策略组、常用分流、脚本订阅的精简全局配置文件（适用于QuantumultX v1.0.10及以上版本）：https://lolico.me/subscribe/QuantumultX/simple.conf注意：如果测试节点连接延迟显示timeout/超时是正常的，服务端开启严格模式后仅能通过网易云相关域名或ip的请求。部分解锁节点来自telegram频道，如有侵权，请联系删除，谢谢！FAQ为什么开启代理后，听数字专辑中的音乐会提示购买？直接搜数字专辑中的音乐在播放时可能出现这种现象，尝试从专辑中进入并播放。为什么开启代理后，登录网易云音乐提示网络异常？先关闭代理再进行登录，进入后再开启代理。为什么播放音乐提示网络不给力或者歌曲不存在？iOS端出现网络不给力时，请确保CA证书已信任；歌曲不存在，请尝试使用其他节点解锁，不同节点在搜索音源时使用的平台不同，部分歌曲找不到是正常的现象。为什么播放的音乐是live版或者完全不同的一首音乐？由于解锁服务是从其他平台搜索音源，并且选择策略不可能做到十全十美，在音乐重名并且火热程度不同的情况下，可能会出现这种现象，目前没有较好的解决方法。为什么开启代理后某些网站或应用加载资源很慢甚至失败？由于使用代理并且根据请求分流，所以说相比不开代理理论上的确会有延迟（基本忽略不计）。如果感觉有明显的网络延迟并且确定不是由于自己网络环境较差所致，请在必要时再开启代理，日常上网关闭即可。这写的都是些啥玩意？……","categories":[{"name":"不正常的文章","slug":"不正常的文章","permalink":"https://lolico.me/categories/%E4%B8%8D%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[]},{"title":"嵌套列表推导式","slug":"嵌套列表推导式","date":"2020-03-15T06:36:20.000Z","updated":"2022-05-02T03:45:10.810Z","comments":true,"path":"2020/03/15/嵌套列表推导式/","link":"","permalink":"https://lolico.me/2020/03/15/%E5%B5%8C%E5%A5%97%E5%88%97%E8%A1%A8%E6%8E%A8%E5%AF%BC%E5%BC%8F/","excerpt":"","text":"列表解析中的第一个表达式可以是任何表达式，包括列表解析。考虑下面由三个长度为 4 的列表组成的 3x4 矩阵：12345&gt;&gt;&gt; matrix = [... [1, 2, 3, 4],... [5, 6, 7, 8],... [9, 10, 11, 12],... ]现在，如果你想交换行和列，可以用嵌套的列表推导式：12&gt;&gt;&gt; [[row[i] for row in matrix] for i in range(4)][[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]像前面看到的，嵌套的列表推导式是对 for 后面的内容进行求值，所以上例就等价于：123456&gt;&gt;&gt; transposed = []&gt;&gt;&gt; for i in range(4):... transposed.append([row[i] for row in matrix])...&gt;&gt;&gt; transposed[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]反过来说，如下也是一样的：12345678910&gt;&gt;&gt; transposed = []&gt;&gt;&gt; for i in range(4):... # the following 3 lines implement the nested listcomp... transposed_row = []... for row in matrix:... transposed_row.append(row[i])... transposed.append(transposed_row)...&gt;&gt;&gt; transposed[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]在实际中，使用内置函数组成复杂流程语句。对此种情况zip()函数将会做的更好：12&gt;&gt;&gt; list(zip(*matrix))[(1, 5, 9), (2, 6, 10), (3, 7, 11), (4, 8, 12)]","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://lolico.me/tags/Python/"}]},{"title":"2020年JetBrains Quest第三弹","slug":"2020年JetBrains-Quest第三弹","date":"2020-03-14T08:52:33.000Z","updated":"2022-05-02T03:45:10.806Z","comments":true,"path":"2020/03/14/2020年JetBrains-Quest第三弹/","link":"","permalink":"https://lolico.me/2020/03/14/2020%E5%B9%B4JetBrains-Quest%E7%AC%AC%E4%B8%89%E5%BC%B9/","excerpt":"2020年3月13，JetBrains Quest第三弹到来：","text":"2020年3月13，JetBrains Quest第三弹到来：给个提示，上面的那一串是经过了Base64编码解谜后这次的奖励是一张8折优惠券？？？算了算了，告辞","categories":[{"name":"不正常的文章","slug":"不正常的文章","permalink":"https://lolico.me/categories/%E4%B8%8D%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"JetBrains Quest","slug":"JetBrains-Quest","permalink":"https://lolico.me/tags/JetBrains-Quest/"}]},{"title":"2020年JetBrains Quest第二弹","slug":"2020年JetBrains-Quest第二弹","date":"2020-03-11T07:33:33.000Z","updated":"2022-05-02T03:45:10.806Z","comments":true,"path":"2020/03/11/2020年JetBrains-Quest第二弹/","link":"","permalink":"https://lolico.me/2020/03/11/2020%E5%B9%B4JetBrains-Quest%E7%AC%AC%E4%BA%8C%E5%BC%B9/","excerpt":"","text":"2020年3月11，JetBrains Quest第二弹到来：.spleh A+lrtC/dmC .thgis fo tuo si ti semitemos ,etihw si txet nehw sa drah kooL .tseretni wohs dluohs uoy ecalp a si ,dessecorp si xat hctuD erehw esac ehT .sedih tseuq fo txen eht erehw si ,deificeps era segaugnal cificeps-niamod tcudorp ehT看着这一串数字不难看出来是经过reverse过的，python解决：12s = '.spleh A+lrtC/dmC .thgis fo tuo si ti semitemos ,etihw si txet nehw sa drah kooL .tseretni wohs dluohs uoy ecalp a si ,dessecorp si xat hctuD erehw esac ehT .sedih tseuq fo txen eht erehw si ,deificeps era segaugnal cificeps-niamod tcudorp ehT'print(s[::-1])输出：The product domain-specific languages are specified, is where the next of quest hides. The case where Dutch tax is processed, is a place you should show interest. Look hard as when text is white, sometimes it is out of sight. Cmd/Ctrl+A helps.来到MPS产品页，搜索Dutch tax：点击Read MPS case study跳转到一个PDF文件：还记得这个提示吗：Look hard as when text is white, sometimes it is out of sight. Cmd/Ctrl+A helps.Ctrl+A试一下：右边有4行文字隐藏了，复制出来康康：This is our 20th year as a company,we have shared numbers in our JetBrainsAnnual report, sharing the section with18,650 numbers will progress your que这句话的提到了JetBrains Annual report，看看去https://www.jetbrains.com/company/annualreport/2019/在这个页面兜兜转转，搜索18650，怎么都发现不了什么线索，参考这个帖子评论区，发现这些数字加起来其实就是18650而线索就藏在分享的编辑栏里面：点击分享：I have found the JetBrains Quest! Sometimes you just need to look closely at the Haskell language, Hello,World! in the hackathon lego brainstorms project https://blog.jetbrains.com/blog/2019/11/22/jetbrains-7th-annual-hackathon/#JetBrainsQuest给了个博客链接，点进去搜索lego brainstorms：还是没有头绪，F12开发者模式查看这种图片：发现在alt属性中有这么一串文字：d1D j00 kN0w J378r41n2 12 4lW4Y2 H1R1N9? ch3CK 0u7 73h K4r33r2 P493 4nD 533 1f 7H3r3 12 4 J08 F0r J00 0R 4 KW357 cH4LL3n93 70 90 fUr7h3r @ l3457.这玩意有的单词看着想是某些字母用数字代替，有的又看不出来，在gist上看了下才知道这是嘤文的火星文🙄🙄🙄，其实在第一弹的邮件里也有一串差不多的彩蛋。翻译过来就是：Did you know Jetbrains is always hiring? Check out the kareers(careers) page and see if there is a job for you or for kwest(quest) challenge to go further at least.去职位发布页面看看：搜索Quest并点进去：看一下啥是cheat at Konami games：上上下下左右左右BA，原来还有个名字叫做Konami Code，相当于一个隐藏游戏的启动代码。魂斗罗30条命！我来辽！！！↑↑↓↓←→←→BA打掉所有块，3个月奖励到手。","categories":[{"name":"不正常的文章","slug":"不正常的文章","permalink":"https://lolico.me/categories/%E4%B8%8D%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"JetBrains Quest","slug":"JetBrains-Quest","permalink":"https://lolico.me/tags/JetBrains-Quest/"}]},{"title":"2020年JetBrains Quest第一弹","slug":"2020年JetBrains-Quest第一弹","date":"2020-03-10T12:53:12.000Z","updated":"2022-05-02T03:45:10.806Z","comments":true,"path":"2020/03/10/2020年JetBrains-Quest第一弹/","link":"","permalink":"https://lolico.me/2020/03/10/2020%E5%B9%B4JetBrains-Quest%E7%AC%AC%E4%B8%80%E5%BC%B9/","excerpt":"","text":"2020年3月9日，JetBrains官方推特发布了这么一条消息：48 61 76 65 20 79 6f 75 20 73 65 65 6e 20 74 68 65 20 73 6f 75 72 63 65 20 63 6f 64 65 20 6f 66 20 74 68 65 20 4a 65 74 42 72 61 69 6e 73 20 77 65 62 73 69 74 65 3f观察这些数字，不难猜测是字符对应的ascii码的十六进制数，转换后，得到这样的提示：Have you seen the source code of the JetBrains website?问我们是否看过JetBrains网站的源码打开JetBrains官网查看源码，搜索JetBrains Quest：Welcome to the JetBrains Quest.​What awaits ahead is a series of challenges. Each one will require a little initiative, a little thinking, and a whole lot of JetBrains to get to the end. Cheating is allowed and in some places encouraged. You have until the 15th of March at 12:00 CET to finish all the quests.Getting to the end of each quest will earn you a reward.Let the quest commence!​JetBrains has a lot of products, but there is one that looks like a joke on our Products page, you should start there… (hint: use Chrome Incognito mode)It’s dangerous to go alone take this key: Good luck! == Jrrg#oxfn$大概说的就是在3月15日欧洲中部时间12:00前完成谜题就可以拿到奖励，并且给了我们一个密钥：Good luck! == Jrrg#oxfn$谜题：JetBrains有很多产品，但是在我们的产品页面上有一个看起来像joke的产品，您应该从那里开始…（提示：使用谷歌无痕模式）谷歌浏览器无痕模式访问JetBrains产品页（实际上我不开无痕模式进入也是可以的）在产品里找到一个叫JK的产品，点击Learn More：You have discovered our JetBrains Quest! If you don’t know what this is, you should start from Twitter, Facebook or LinkedIn.​To continue to the next challenge you need to go to the following link… But there is a problem, the last 3 digits are missing:​https://jb.gg/###​To get these digits you need to know how many prime numbers there are between 500 and 5000​Good Luck!500到5000里有多少个质数，简单，574个。补充到链接上也就是让我们去这个地方：https://jb.gg/574重定向来到了这里：如果你对JetBrains网站很了解你就会知道这个Logo是youtrack，也就是JebBrains网站的问题区，将后面的问题编码输进去，得到链接：https://youtrack.jetbrains.com/issue/MPS-31816跳转到这个页面：JetBrains Quest​“The key is to think back to the beginning.” – The JetBrains Quest team​Qlfh$#Li#|rx#duh#uhdglqj#wklv#|rx#pxvw#kdyh#zrunhg#rxw#krz#wr#ghfu|sw#lw1#Wklv#lv#rxu#lvvxh#wudfnhu#ghvljqhg#iru#djloh#whdpv1#Lw#lv#iuhh#iru#xs#wr#6#xvhuv#lq#Forxg#dqg#iru#43#xvhuv#lq#Vwdqgdorqh/#vr#li#|rx#zdqw#wr#jlyh#lw#d#jr#lq#|rxu#whdp#wkhq#zh#wrwdoo|#uhfrpphqg#lw1#|rx#kdyh#ilqlvkhg#wkh#iluvw#Txhvw/#qrz#lw“v#wlph#wr#uhghhp#|rxu#iluvw#sul}h1#Wkh#frgh#iru#wkh#iluvw#txhvw#lv#‟WkhGulyhWrGhyhors†1#Jr#wr#wkh#Txhvw#Sdjh#dqg#xvh#wkh#frgh#wr#fodlp#|rxu#sul}h1#kwwsv=22zzz1mhweudlqv1frp2surpr2txhvw2告诉我们需要回头想一下密钥，那不就是网站源码里的Good luck! == Jrrg#oxfn$嘛。那后面那一串东西和这个有什么关系呢？我就不卖关子了，其实也就是凯撒加密，源码里告诉我们的Good luck! == Jrrg#oxfn$其实就相当于一个输入输出案例：明文Good luck!经凯撒加密后得到Jrrg#oxfn$凯撒加密：将明文字符以某个数字移位得到另一个字符，说人话也就是把字符的ascii码加或者减某个数得到另一个字符的ascii也就是密文所以说给出的这个输入输出我们可以知道这个数字是3。所以说将给出的这个密文还原成明文只需要将每个字符的ascii码减三得到的字符串就是明文了：1234567if __name__ == \"__main__\": s = \"Qlfh$#Li#|rx#duh#uhdglqj#wklv#|rx#pxvw#kdyh#zrunhg#rxw#krz#wr#ghfu|sw#lw1#Wklv#lv#rxu#lvvxh#wudfnhu#ghvljqhg#iru#djloh#whdpv1#Lw#lv#iuhh#iru#xs#wr#6#xvhuv#lq#Forxg#dqg#iru#43#xvhuv#lq#Vwdqgdorqh/#vr#li#|rx#zdqw#wr#jlyh#lw#d#jr#lq#|rxu#whdp#wkhq#zh#wrwdoo|#uhfrpphqg#lw1#|rx#kdyh#ilqlvkhg#wkh#iluvw#Txhvw/#qrz#lw“v#wlph#wr#uhghhp#|rxu#iluvw#sul&#125;h1#Wkh#frgh#iru#wkh#iluvw#txhvw#lv#‟WkhGulyhWrGhyhors†1#Jr#wr#wkh#Txhvw#Sdjh#dqg#xvh#wkh#frgh#wr#fodlp#|rxu#sul&#125;h1#kwwsv=22zzz1mhweudlqv1frp2surpr2txhvw2\" step = ord('J')-ord('G') #Good luck! == Jrrg#oxfn$ list = list(s) for i in range(len(list)): list[i] = chr(ord(list[i]) - step) print(\"\".join(list))输出：Nice! If you are reading this you must have worked out how to decrypt it. This is our issue tracker designed for agile teams. It is free for up to 3 users in Cloud and for 10 users in Standalone, so if you want to give it a go in your team then we totally recommend it. you have finished the first Quest, now it’s time to redeem your first prize. The code for the first quest is “TheDriveToDevelop”. Go to the Quest Page and use the code to claim your prize. https://www.jetbrains.com/promo/quest/得到一个网址和兑换码。接下来的兑奖环节应该就不用多说了。","categories":[{"name":"不正常的文章","slug":"不正常的文章","permalink":"https://lolico.me/categories/%E4%B8%8D%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"JetBrains Quest","slug":"JetBrains-Quest","permalink":"https://lolico.me/tags/JetBrains-Quest/"}]},{"title":"获取泛型参数的类型","slug":"获取泛型参数的类型","date":"2020-03-10T09:18:17.000Z","updated":"2022-05-02T03:45:10.810Z","comments":true,"path":"2020/03/10/获取泛型参数的类型/","link":"","permalink":"https://lolico.me/2020/03/10/%E8%8E%B7%E5%8F%96%E6%B3%9B%E5%9E%8B%E5%8F%82%E6%95%B0%E7%9A%84%E7%B1%BB%E5%9E%8B/","excerpt":"","text":"现在有这样一个场景：有一个按钮监听器类ButtonListener：ButtonListener.java123456import me.lolico.demo.button.event.ButtonEvent;import java.util.EventListener;public interface ButtonListener&lt;E extends ButtonEvent&gt; extends EventListener &#123; void onButtonEvent(E event);&#125;以及一个监听按钮name是否改变即ButtonNameHasChangedEvent事件的实现类ButtonNameListener：ButtonNameListener.java1234567891011import me.lolico.demo.button.Button;import me.lolico.demo.button.ButtonListener;import me.lolico.demo.button.event.ButtonNameHasChangedEvent;public class ButtonNameListener implements ButtonListener&lt;ButtonNameHasChangedEvent&gt; &#123; @Override public void onButtonEvent(ButtonNameHasChangedEvent event) &#123; Button button = (Button) event.getSource(); System.out.println(button + \"name has changed!\"); &#125;&#125;当我们调用设置按钮setName方法时需要发布ButtonNameHasChangedEvent事件，我们需要怎么去通知监听这个事件的监听器呢？我们需要获取到所有的按钮监听器，然后遍历，获取泛型类型，如果类型匹配，那么则通知这个监听器所以现在问题变成了如何获取按钮监听器的泛型类型，如果我们百度一下，清一色的答案都是下面这种：获取某个类的泛型参数的类型1((ParameterizedType) clazz.getGenericSuperclass()).getActualTypeArguments()对于这种场景，那么就是一个异常抛出：1java.lang.ClassCastException: java.lang.Class cannot be cast to java.lang.reflect.ParameterizedType为什么呢，因为Class#getGenericSuperclass()方法返回的是超类的Type，所以说这种方法只能用于获取超类上面的泛型类型，而我们上面的案例明显是要获取接口上的的泛型类型，所以我们应该使用的是Class#getGenericInterfaces()方法。获取一个类上的所有泛型类型：12345678910111213public Set&lt;Type&gt; resolveGenericType(Class&lt;?&gt; clazz) &#123; Set&lt;Type&gt; genericSet = new HashSet&lt;&gt;(); Type superclass = clazz.getGenericSuperclass(); if (superclass instanceof ParameterizedType) &#123; genericSet.addAll(Arrays.asList(((ParameterizedType) superclass).getActualTypeArguments())); &#125; Type[] interfaces = clazz.getGenericInterfaces(); for (Type type : interfaces) &#123; Type[] genericType = ((ParameterizedType) type).getActualTypeArguments(); genericSet.addAll(Arrays.asList(genericType)); &#125; return genericSet;&#125;注意：获取的泛型类型不包括实现的接口继承的接口上的泛型类型，因为Class#getGenericInterfaces()方法不是递归获取所有接口类型，只获取当前类实现的接口的类型。","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://lolico.me/tags/Java/"}]},{"title":"源码角度分析Spring容器启动阶段注册Controller处理器的流程","slug":"源码角度分析Spring容器启动阶段注册Controller处理器的流程","date":"2020-03-09T08:09:08.000Z","updated":"2022-05-02T03:45:10.810Z","comments":true,"path":"2020/03/09/源码角度分析Spring容器启动阶段注册Controller处理器的流程/","link":"","permalink":"https://lolico.me/2020/03/09/%E6%BA%90%E7%A0%81%E8%A7%92%E5%BA%A6%E5%88%86%E6%9E%90Spring%E5%AE%B9%E5%99%A8%E5%90%AF%E5%8A%A8%E9%98%B6%E6%AE%B5%E6%B3%A8%E5%86%8CController%E5%A4%84%E7%90%86%E5%99%A8%E7%9A%84%E6%B5%81%E7%A8%8B/","excerpt":"","text":"前言我们都知道，在一个请求被前端控制器DispatchServlet捕获后会经历下面几个流程：DispatherServlet根据请求URL解析获取请求URI，调用HandlerMapping#getHandler方法获取HandlerExecutionChain获取返回的HandlerExecutionChain处理器执行链（包括处理器对象和拦截器对象）根据处理器执行链获取一个处理器适配器HandlerAdapter，如果成功获取，则开始执行拦截器）处理器适配器根据请求的Handler（一般来说是HandlerMethod）适配并根据配置的HttpMessageConveter将请求消息解析为模型数据，填充 Handler入参，开始执行处理器逻辑。处理器执行完毕，返回ModelAndView，处理器适配器接收到后返回给DispatherServletDispatherServlet根据模型和视图请求对应的视图解析器视图解析器解析模型数据获取对应的视图，渲染视图后返回给DispatherServletDispatherServlet将渲染后的视图相应给用户或客户端那么Spring容器启动后是如何自动发现处理器（我在这称之为自动发现机制）并进行注册的呢？在web环境下Spring容器启动时会注册HandlerMapping，具体在SpringBoot中，WebMvcAutoConfiguration会通过WebMvcConfigurationSupport#requestMappingHandlerMapping方法向容器中注册一个HandlerMapping的实现RequestMappingHandlerMapping自动发现机制的实现Spring容器启动时会注册HandlerMapping，在这里我们就以RequestMappingHandlerMapping实现类为例进行分析RequestMappingHandlerMappingRequestMappingHandlerMapping#afterPropertiesSet方法实际上调用了父类的afterPropertiesSet的方法：RequestMappingHandlerMapping#afterPropertiesSet1234public void afterPropertiesSet() &#123; ... super.afterPropertiesSet();&#125;而在父类的这个方法中进行初始化处理器逻辑：AbstractHandlerMethodMapping#afterPropertiesSet12345678/** * Detects handler methods at initialization. * @see #initHandlerMethods */@Overridepublic void afterPropertiesSet() &#123; initHandlerMethods();&#125;在initHandlerMethods方法中先从容器中获取所有的候选bean，调用processCandidateBean方法：AbstractHandlerMethodMapping#initHandlerMethods1234567891011121314/** * Scan beans in the ApplicationContext, detect and register handler methods. * @see #getCandidateBeanNames() * @see #processCandidateBean * @see #handlerMethodsInitialized */protected void initHandlerMethods() &#123; for (String beanName : getCandidateBeanNames()) &#123; if (!beanName.startsWith(SCOPED_TARGET_NAME_PREFIX)) &#123; processCandidateBean(beanName); &#125; &#125; handlerMethodsInitialized(getHandlerMethods());&#125;在processCandidateBean方法中根据bean的类型调用由子类实现的isHandler方法判断是否是处理器，然后调用detectHandlerMethods方法寻找该处理器中的处理方法并注册。来看下RequestMappingHandlerMapping#isHandler1234protected boolean isHandler(Class&lt;?&gt; beanType) &#123; return (AnnotatedElementUtils.hasAnnotation(beanType, Controller.class) || AnnotatedElementUtils.hasAnnotation(beanType, RequestMapping.class));&#125;对应的AnnotatedElementUtils#hasAnnotation方法，最终会调用到AnnotatedElementUtils#searchWithFindSemantics方法，代码片段如下12345678910111213141516171819202122 else if (element instanceof Class) &#123; Class&lt;?&gt; clazz = (Class&lt;?&gt;) element; if (!Annotation.class.isAssignableFrom(clazz)) &#123; // Search on interfaces 在实现接口中查找 for (Class&lt;?&gt; ifc : clazz.getInterfaces()) &#123; T result = searchWithFindSemantics(ifc, annotationTypes, annotationName, containerType, processor, visited, metaDepth); if (result != null) &#123; return result; &#125; &#125; // Search on superclass 在父类中查找 Class&lt;?&gt; superclass = clazz.getSuperclass(); if (superclass != null &amp;&amp; superclass != Object.class) &#123; T result = searchWithFindSemantics(superclass, annotationTypes, annotationName, containerType, processor, visited, metaDepth); if (result != null) &#123; return result; &#125; &#125; &#125;&#125;发现这个地方查找是否有指定注解时，如果继承的类或实现的接口有相应的注解也是可以的，这个特性在某些情况下是很有用的，比如在自动配置类中可以利用这一特点，使用@Bean注解再配合@Conditionalxxx等注解实现按需注入Controller。我们只要定义一个标记类/接口，再在该类上注解@Controller或@RequestMapping，然后让需要按需注入的Controller继承这个标记类/接口即可。注意，在一般情况下使用@Bean或@Component注解是不能将一个Bean注册为Controller的AbstractHandlerMethodMapping#detectHandlerMethods现在我们来看下这个自动发现机制中最关键的方法：AbstractHandlerMethodMapping#detectHandlerMethods12345678910111213141516171819202122232425262728293031protected void detectHandlerMethods(Object handler) &#123; Class&lt;?&gt; handlerType = (handler instanceof String ? obtainApplicationContext().getType((String) handler) : handler.getClass()); if (handlerType != null) &#123; // 获取用户定义的类，防止在代理模式下不能获取到方法以及上面的注解 Class&lt;?&gt; userType = ClassUtils.getUserClass(handlerType); // 返回方法及其相关元数据的一个map，元数据是回调lambda获取的，可以看下MetadataLookup#inspect函数式接口 Map&lt;Method, T&gt; methods = MethodIntrospector.selectMethods(userType, (MethodIntrospector.MetadataLookup&lt;T&gt;) method -&gt; &#123; try &#123; // 由子类实现的抽象方法 // 在RequestMappingHandlerMapping中是RequestMappingInfo return getMappingForMethod(method, userType); &#125; catch (Throwable ex) &#123; throw new IllegalStateException(\"Invalid mapping on handler class [\" + userType.getName() + \"]: \" + method, ex); &#125; &#125;); if (logger.isTraceEnabled()) &#123; logger.trace(formatMappings(userType, methods)); &#125; methods.forEach((method, mapping) -&gt; &#123; // 获取该方法的可调用方法 Method invocableMethod = AopUtils.selectInvocableMethod(method, userType); // 注册 registerHandlerMethod(handler, invocableMethod, mapping); &#125;); &#125;&#125;而在RequestMappingHandlerMapping#getMappingForMethod中先检查是否注解了@RequestMapping，如果有则获取注解中的请求的路径，请求的方式（GET,POST,…)等等信息，封装到RequestMappingInfo中返回，具体的代码就不放了，还是很好理解的。再来看下最后这个AbstractHandlerMethodMapping#registerHandlerMethod方法AbstractHandlerMethodMapping#registerHandlerMethod123protected void registerHandlerMethod(Object handler, Method method, T mapping) &#123; this.mappingRegistry.register(mapping, handler, method);&#125;很好理解，调用mappingRegistry#register方法进行注册，那这个mappingRegistry是什么东西呢？MappingRegistry实际上就是AbstractHandlerMethodMapping类中的一个内部类，看名字很好理解：映射注册表，这个类中维护了存放映射信息的mapMappingRegistryMappingRegistry是AbstractHandlerMethodMapping类中的一个内部类，在其中维护了五个用于存放映射信息的Map：MappingRegistry类字段1234567891011// 真正意义上的注册表，以RequestMappingInfo为key// MappingRegistration中存放请求映射信息RequestMappingInfo、处理器方法HandlerMethod（即标注了@RequestMapping的处理方法）、映射路径url、处理器nameprivate final Map&lt;T, MappingRegistration&lt;T&gt;&gt; registry = new HashMap&lt;&gt;();// RequestMappingInfo和HandlerMethod的mapprivate final Map&lt;T, HandlerMethod&gt; mappingLookup = new LinkedHashMap&lt;&gt;();// url(请求路径)和RequestMappingInfo的mapprivate final MultiValueMap&lt;String, T&gt; urlLookup = new LinkedMultiValueMap&lt;&gt;();// 处理器name和处理器方法的mapprivate final Map&lt;String, List&lt;HandlerMethod&gt;&gt; nameLookup = new ConcurrentHashMap&lt;&gt;();// 处理器方法和跨域配置的mapprivate final Map&lt;HandlerMethod, CorsConfiguration&gt; corsLookup = new ConcurrentHashMap&lt;&gt;();MappingRegistry#registerMappingRegistry#register12345678910111213141516171819202122232425262728293031323334353637public void register(T mapping, Object handler, Method method) &#123; // Assert that the handler method is not a suspending one. if (KotlinDetector.isKotlinType(method.getDeclaringClass()) &amp;&amp; KotlinDelegate.isSuspend(method)) &#123; throw new IllegalStateException(\"Unsupported suspending handler method detected: \" + method); &#125; this.readWriteLock.writeLock().lock(); try &#123; // 创建处理器方法 HandlerMethod handlerMethod = createHandlerMethod(handler, method); validateMethodMapping(handlerMethod, mapping); // 将映射信息和处理器方法放到map中 this.mappingLookup.put(mapping, handlerMethod); // 获取映射的请求路径数组，在RequestMapping注解中可对一个方法指定多个映射路径 List&lt;String&gt; directUrls = getDirectUrls(mapping); for (String url : directUrls) &#123; // 放入map this.urlLookup.add(url, mapping); &#125; // 如果name存储策略不为空，将处理器name和处理器方法放到nameLookup map中 String name = null; if (getNamingStrategy() != null) &#123; name = getNamingStrategy().getName(handlerMethod, mapping); // 将处理器name和处理器方法放到nameLookup map中 addMappingName(name, handlerMethod); &#125; // 跨域配置 CorsConfiguration corsConfig = initCorsConfiguration(handler, method, mapping); if (corsConfig != null) &#123; this.corsLookup.put(handlerMethod, corsConfig); &#125; // 将映射信息和MappingRegistration放到注册表Map this.registry.put(mapping, new MappingRegistration&lt;&gt;(mapping, handlerMethod, directUrls, name)); &#125; finally &#123; this.readWriteLock.writeLock().unlock(); &#125;&#125;这个方法说白了，就是把处理器，处理器方法，请求映射信息等等信息放到Map中，看到这里可能会对RequestMappingInfo和 MappingRegistration这两个东西感到疑惑，其实很简单，前者是Spring容器启动时控制器自动发现机制根据方法上@RequestMapping注解中的信息封装的对象，决定了什么样的请求能命中那个处理器方法，这也是MappingRegistry#registry注册表中以RequestMappingInfo为key的原因，而MappingRegistration中封装了处理器Handler,处理器方法HandlerMethod信息。所以现在能知道一个请求到来时是如何找到处理器方法并调用的了：根据请求的url到MappingRegistry#urlLookup字段中匹配，如果匹配上，则取出对应的RequestMappingInfo，再到MappingRegistry#registry字段中取出MappingRegistration，再取出MappingRegistration中的处理器Handler和方法HandlerMethod，反射调用完成请求。当然，这只是大概的流程。后语Spring容器启动，注册处理器的流程分析完了。其实说白了，Spring容器注册控制器就是扫描容器中的bean然后检查是否是控制器Controller，然后将其中注解有@RequestMapping的方法注册为处理器方法。其实HandlerMapping的实现类并不是只有RequestMappingHandlerMapping一个，但是是AbstractHandlerMethodMapping提供的主要的实现逻辑，而实现类只是提供了基础的判断：是否是处理器（isHandler)，获取请求映射信息getMappingForMethod等抽象方法，所以说如果在某些场景下需要实现自定义的HandlerMapping时我们可以通过继承RequestMappingInfoHandlerMapping然后重写isHandler和getMappingForMethod方法即可。（RequestMappingHandlerMapping继承自RequestMappingInfoHandlerMapping）至于案例，以后有空了再补上","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://lolico.me/tags/Spring/"},{"name":"Java","slug":"Java","permalink":"https://lolico.me/tags/Java/"},{"name":"Web","slug":"Web","permalink":"https://lolico.me/tags/Web/"}]},{"title":"Hello World","slug":"hello-world","date":"2020-03-02T16:00:00.000Z","updated":"2022-05-02T03:45:10.806Z","comments":true,"path":"2020/03/02/hello-world/","link":"","permalink":"https://lolico.me/2020/03/02/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.博客以迁移至Hexo，托管在GitHub上，目前感觉除了速度其他都还好，后续可能考虑托管在对象存储上。尝试着把typecho的内容迁移了过来，还有待完善。保留的内容文章数据文章分类以及tag丢失的内容评论数据文章中图片","categories":[],"tags":[]},{"title":"源码角度分析Shiro认证流程以及一个前后端分离案例","slug":"源码角度分析Shiro认证流程以及一个前后端分离案例","date":"2020-02-04T10:50:51.000Z","updated":"2022-05-02T03:45:10.810Z","comments":true,"path":"2020/02/04/源码角度分析Shiro认证流程以及一个前后端分离案例/","link":"","permalink":"https://lolico.me/2020/02/04/%E6%BA%90%E7%A0%81%E8%A7%92%E5%BA%A6%E5%88%86%E6%9E%90Shiro%E8%AE%A4%E8%AF%81%E6%B5%81%E7%A8%8B%E4%BB%A5%E5%8F%8A%E4%B8%80%E4%B8%AA%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E6%A1%88%E4%BE%8B/","excerpt":"","text":"从源码去分析认证流程前，你需要知道Shiro是什么，以及Shiro中的基本组件。在看本篇文章前，我假设你已经知道上述东西，并且后续的分析不会对这些组件是什么进行讲解。如果你并不了解Shiro可以看下我的这篇博文：Shiro简介 对于更详细的分析，大家可以百度、google一下，资料应该是很全的。Shiro工作流程简述Shiro进行认证的本质还是通过过滤器进行拦截，过滤器拦截后判断是否需要进行认证，如果需要，取出”token”并交给SecurityManager进行认证，认证通过后放行，如果不需要认证则直接放行。至于为什么token打上引号，是因为token并不一定是普遍意义上的JWT（json web token）,也可以是基于BASIC HTTP的token，还可以是表单中的用户名和密码…所以Shiro中就内置了一些常用的Filter，有基于表单认证的FormAuthenticationFilter类和基于BASIC HTTP的BasicHttpAuthenticationFilter类，还有不需要认证直接放行的AnonymousFilter类，也有一些用于检查Roles和Permissions的过滤器，具体的可以去DefaultFilter中看看。过滤器Shiro中的过滤器其实还是Servlet中的Filter，只不过对其进行了封装。先来看下Shiro中Filter的类图Shiro FilterAbstractFilter：提供了简化的初始化逻辑和access到初始化参数，并且提供了getInitParam(String paramName)方法获取。NameableFilter：为Filter提供name属性值，可通过getter和setter方法获取和设置。OncePerRequestFilter：继承自NameableFilter，通过名字看出，一次请求执行一次。不难看出Shiro中的所有Filter都是通过继承OncePerRequestFilter抽象类而来，来看下这个类的doFilter(...)方法：12345678910111213141516171819202122232425public final void doFilter(ServletRequest request, ServletResponse response, FilterChain filterChain) throws ServletException, IOException &#123; String alreadyFilteredAttributeName = getAlreadyFilteredAttributeName(); if ( request.getAttribute(alreadyFilteredAttributeName) != null ) &#123; filterChain.doFilter(request, response); &#125; else if (!isEnabled(request, response) || shouldNotFilter(request) ) &#123; filterChain.doFilter(request, response); &#125; else &#123; request.setAttribute(alreadyFilteredAttributeName, Boolean.TRUE); try &#123; doFilterInternal(request, response, filterChain); &#125; finally &#123; request.removeAttribute(alreadyFilteredAttributeName); &#125; &#125;&#125;// 默认实现是使用过滤器的name作为属性名，如果为空则用类的全路径名作为属性名// 这个属性名一般来说是唯一的protected String getAlreadyFilteredAttributeName() &#123; String name = getName(); if (name == null) &#123; name = getClass().getName(); &#125; return name + ALREADY_FILTERED_SUFFIX; // ALREADY_FILTERED_SUFFIX = \".FILTERED\";&#125;可以看出首先调用getAlreadyFilteredAttributeName()获取当前过滤器的属性名，该方法的默认实现是使用过滤器的name作为属性名，如果为空则用类的全路径名作为属性名，这个属性名一般来说是唯一的。获取到属性名后看下request中有没有这个属性，如果存在，则放行，继续执行下一个过滤器。如果不存在，则继续判断过滤器是否启用，或者是否直接放行，如果是则也放行，最后上述两种情况都不符合，也就是说需要进行过滤,先将过滤器的属性名设置到这次请求中，再尝试进行具体逻辑doFilterInternal(...)方法（该方法是抽象方法，需要子类实现），最后finally中逻辑显而易见，过滤器具体逻辑执行完毕后移除过滤器的属性名。说的简单点，也就是实现了一次请求过滤一次，然后将过滤器具体的逻辑放在了这个抽象方法中：1protected abstract void doFilterInternal(ServletRequest request, ServletResponse response, FilterChain chain) throws ServletException, IOException;AdviceFilter类、PathMatchingFilter类和AccessControlFilter类AdviceFilte类AdviceFilter类继承自OncePerRequestFilter，也是个抽象类，但他实现了父类的doFilterInternal(...)方法中，将具体逻辑又分为三个步骤：123456789101112131415161718192021222324public void doFilterInternal(ServletRequest request, ServletResponse response, FilterChain chain) throws ServletException, IOException &#123; Exception exception = null; try &#123; //执行前置处理 boolean continueChain = preHandle(request, response); if (log.isTraceEnabled()) &#123; log.trace(\"Invoked preHandle method. Continuing chain?: [\" + continueChain + \"]\"); &#125; //前置处理如果没问题，执行executeChain(...)方法 if (continueChain) &#123; executeChain(request, response, chain); &#125; //执行后置处理 postHandle(request, response); if (log.isTraceEnabled()) &#123; log.trace(\"Successfully invoked postHandle method\"); &#125; &#125; catch (Exception e) &#123; exception = e; &#125; finally &#123; cleanup(request, response, exception); &#125;&#125;preHandle(...)方法默认返回true，其实所有子类过滤器的逻辑应该放在这里面。executeChain(ServletRequest request, ServletResponse response, FilterChain chain)方法一定要注意，因为这个方法的逻辑是chain.doFilter(request, response)，执行下一个过滤器postHandle(...)方法默认是一个空方法。所有过滤器真正的逻辑应该在preHandle(...)中而不是executeChain(...)中，自定义过滤器重写方法的时候一定要注意。看到这你可能会疑惑：真正的前置处理在哪里？其实并没有提供真正意义上的前置处理，为什么这么说呢？看下PathMatchingFilter和AccessControlFilter就知道了。PathMatchingFilter类继承自AdviceFilter的PathMatchingFilter中重写的preHandler方法会检查请求路径是否匹配配置，匹配的话则执行isFilterChainContinued()方法，而这个方法中调用了一个抽象方法onPreHandle(...)，源码如下，就不解释了。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253protected boolean preHandle(ServletRequest request, ServletResponse response) throws Exception &#123; if (this.appliedPaths == null || this.appliedPaths.isEmpty()) &#123; if (log.isTraceEnabled()) &#123; log.trace(\"appliedPaths property is null or empty. This Filter will passthrough immediately.\"); &#125; return true; &#125; for (String path : this.appliedPaths.keySet()) &#123; // If the path does match, then pass on to the subclass implementation for specific checks //(first match 'wins'): if (pathsMatch(path, request)) &#123; log.trace(\"Current requestURI matches pattern '&#123;&#125;'. Determining filter chain execution...\", path); Object config = this.appliedPaths.get(path); return isFilterChainContinued(request, response, path, config); &#125; &#125; //no path matched, allow the request to go through: return true;&#125;/** * Simple method to abstract out logic from the preHandle implementation - it was getting a bit unruly. * * @since 1.2 */@SuppressWarnings(&#123;\"JavaDoc\"&#125;)private boolean isFilterChainContinued(ServletRequest request, ServletResponse response, String path, Object pathConfig) throws Exception &#123; if (isEnabled(request, response, path, pathConfig)) &#123; //isEnabled check added in 1.2 if (log.isTraceEnabled()) &#123; log.trace(\"Filter '&#123;&#125;' is enabled for the current request under path '&#123;&#125;' with config [&#123;&#125;]. \" + \"Delegating to subclass implementation for 'onPreHandle' check.\", new Object[]&#123;getName(), path, pathConfig&#125;); &#125; //The filter is enabled for this specific request, so delegate to subclass implementations //so they can decide if the request should continue through the chain or not: return onPreHandle(request, response, pathConfig); &#125; if (log.isTraceEnabled()) &#123; log.trace(\"Filter '&#123;&#125;' is disabled for the current request under path '&#123;&#125;' with config [&#123;&#125;]. \" + \"The next element in the FilterChain will be called immediately.\", new Object[]&#123;getName(), path, pathConfig&#125;); &#125; //This filter is disabled for this specific request, //return 'true' immediately to indicate that the filter will not process the request //and let the request/response to continue through the filter chain: return true;&#125;AccessControlFilter类AccessControlFilter抽象类继承自PathMatchingFilterAccessControlFilter实现了onPreHandle(...)方法：12345678910public boolean onPreHandle(ServletRequest request, ServletResponse response, Object mappedValue) throws Exception &#123; return isAccessAllowed(request, response, mappedValue) || onAccessDenied(request, response, mappedValue);&#125;protected abstract boolean isAccessAllowed(ServletRequest request, ServletResponse response, Object mappedValue) throws Exception;protected boolean onAccessDenied(ServletRequest request, ServletResponse response, Object mappedValue) throws Exception &#123; return onAccessDenied(request, response);&#125;protected abstract boolean onAccessDenied(ServletRequest request, ServletResponse response) throws Exception;看到这里也就明朗了，返回isAccessAllowed(...) || onAccessDenied(...)，这两个方法都是抽象方法，这个逻辑的意思解释起来就是：先执行isAccessAllowed方法看下能不能访问能访问则直接返回也就是true，如果不能访问，则执行onAccessDenied方法并返回结果（注意理解‘或’运算符）。AuthenticationFilter类和AuthenticatingFilter类注意这两个类名的不同。AuthenticationFilter只实现了isAccessAllowed(...)方法：12345protected boolean isAccessAllowed(ServletRequest request, ServletResponse response, Object mappedValue) &#123; // 返回绑定到当前线程上的主体是否已经认证的结果 Subject subject = getSubject(request, response); return subject.isAuthenticated();&#125;而AuthenticatingFilter继承自AuthenticationFilter类：12345678910111213141516171819202122protected boolean executeLogin(ServletRequest request, ServletResponse response) throws Exception &#123; AuthenticationToken token = createToken(request, response); if (token == null) &#123; String msg = \"createToken method implementation returned null. A valid non-null AuthenticationToken \" + \"must be created in order to execute a login attempt.\"; throw new IllegalStateException(msg); &#125; try &#123; Subject subject = getSubject(request, response); subject.login(token); return onLoginSuccess(token, subject, request, response); &#125; catch (AuthenticationException e) &#123; return onLoginFailure(token, e, request, response); &#125;&#125;protected abstract AuthenticationToken createToken(ServletRequest request, ServletResponse response) throws Exception;protected boolean isAccessAllowed(ServletRequest request, ServletResponse response, Object mappedValue) &#123; return super.isAccessAllowed(request, response, mappedValue) || (!isLoginRequest(request, response) &amp;&amp; isPermissive(mappedValue));&#125;解释一下这个isAccessAllowed(...)方法：The default implementation returns true if the user is authenticated. Will also return true if the isLoginRequest returns false and the “permissive” flag is set如果已经认证则返回true，或者请求不需要认证并且设置了”permissive”，设置”permissive”是什么意思呢：比如说配置过滤器的路由策略时：map.add(“/**”,”authc[permissive]”)所以这个类其实已经提供了一个通用的逻辑，一般来说，也是能够适应大多数场景下的需求的，所以说，一般我们自定义过滤器就是继承AuthenticatingFilter类，然后只需要重写onAccessDenied(...)方法，在其中调用executeLogin方法进行认证，然后提供创建Token的具体逻辑也就是createToken(..)方法就可以了。如果有特殊需求，比如对于Option请求直接放行，那么可以重写isAccessAllowed(...)方法，判断是否是option请求，一般来说我们还是会调用一下父类的通用判断方法：super.isAccessAllowed(...)，后续的案例就用了这种方法实现跨域请求直接放行。并且可以看到executeLogin(..)方法中获取Subject并使用createToken方法返回的Token去调用login进行认证，对于认证成功和认证失败还提供了回调处理，我们可以重写这两个方法以满足某些场景下的需求，比如jwt认证成功后判断是否需要刷新token。SecurityManager当我们使用Subject去调用login(AuthenticationToken)方法时，实际上是委托给DelegatingSubject去处理,而这个类又会从SecurityManager中获取信息再进行处理:DelegatingSubject#login方法12345public void login(AuthenticationToken token) throws AuthenticationException &#123; ... Subject subject = securityManager.login(this, token); ...&#125;SecurityManager#login方法1234567891011121314151617181920public Subject login(Subject subject, AuthenticationToken token) throws AuthenticationException &#123; AuthenticationInfo info; try &#123; //调用authenticate方法 info = authenticate(token); &#125; catch (AuthenticationException ae) &#123; try &#123; onFailedLogin(token, ae, subject); &#125; catch (Exception e) &#123; if (log.isInfoEnabled()) &#123; log.info(\"onFailedLogin method threw an \" + \"exception. Logging and propagating original AuthenticationException.\", e); &#125; &#125; throw ae; //propagate &#125; Subject loggedIn = createSubject(token, info, subject); onSuccessfulLogin(token, info, loggedIn); return loggedIn;&#125;AbstractSecurityManager中有一个Authenticator认证器，在SecurityManager进行认证的时候就是委托它进行认证的：123public AuthenticationInfo authenticate(AuthenticationToken token) throws AuthenticationException &#123; return this.authenticator.authenticate(token);&#125;Authenticator是一个接口，并且只有一个认证方法，该方法返回认证信息。1234public interface Authenticator &#123; public AuthenticationInfo authenticate(AuthenticationToken authenticationToken) throws AuthenticationException;&#125;AbstractAuthenticator#authenticate方法：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public final AuthenticationInfo authenticate(AuthenticationToken token) throws AuthenticationException &#123; if (token == null) &#123; throw new IllegalArgumentException(\"Method argument (authentication token) cannot be null.\"); &#125; log.trace(\"Authentication attempt received for token [&#123;&#125;]\", token); AuthenticationInfo info; try &#123; //调用`doAuthenticate(AuthenticationToken)`抽象方法 info = doAuthenticate(token); if (info == null) &#123; String msg = \"No account information found for authentication token [\" + token + \"] by this \" + \"Authenticator instance. Please check that it is configured correctly.\"; throw new AuthenticationException(msg); &#125; &#125; catch (Throwable t) &#123; AuthenticationException ae = null; if (t instanceof AuthenticationException) &#123; ae = (AuthenticationException) t; &#125; if (ae == null) &#123; //Exception thrown was not an expected AuthenticationException. Therefore it is probably a little more //severe or unexpected. So, wrap in an AuthenticationException, log to warn, and propagate: String msg = \"Authentication failed for token submission [\" + token + \"]. Possible unexpected \" + \"error? (Typical or expected login exceptions should extend from AuthenticationException).\"; ae = new AuthenticationException(msg, t); if (log.isWarnEnabled()) log.warn(msg, t); &#125; try &#123; notifyFailure(token, ae); &#125; catch (Throwable t2) &#123; if (log.isWarnEnabled()) &#123; String msg = \"Unable to send notification for failed authentication attempt - listener error?. \" + \"Please check your AuthenticationListener implementation(s). Logging sending exception \" + \"and propagating original AuthenticationException instead...\"; log.warn(msg, t2); &#125; &#125; throw ae; &#125; log.debug(\"Authentication successful for token [&#123;&#125;]. Returned account [&#123;&#125;]\", token, info); notifySuccess(token, info); return info;&#125;该方法调用doAuthenticate(AuthenticationToken)抽象方法，返回认证信息。Shiro中的认证器只有一个实现类：ModularRealmAuthenticatorModularRealmAuthenticator#doAuthenticate方法123456789protected AuthenticationInfo doAuthenticate(AuthenticationToken authenticationToken) throws AuthenticationException &#123; assertRealmsConfigured(); Collection&lt;Realm&gt; realms = getRealms(); if (realms.size() == 1) &#123; return doSingleRealmAuthentication(realms.iterator().next(), authenticationToken); &#125; else &#123; return doMultiRealmAuthentication(realms, authenticationToken); &#125;&#125;如果只有一个Realm，执行doSingleRealmAuthentication(..)方法否则执行doMultiRealmAuthentication(..)方法这两个方法有什么区别呢？区别在于第二个方法多了一个认证策略AuthenticationStrategy，有三个实现：AllSuccessfulStrategy：需要所有的Realm认证通过AtLeastOneSuccessfulStrategy：至少需要一个Realm认证通过FirstSuccessfulStrategy：只需要一个Realm认证通过最后两个认证策略有什么不同呢？前者在第一个Realm认证成功后还会继续认证剩下的Realm，并把所有的认证信息AuthenticationInfo进行合并。后者在第一个Realm认证成功后直接返回认证信息。默认使用的是AtLeastOneSuccessfulStrategy来看下doSingleRealmAuthentication(..)和doMultiRealmAuthentication(..)这两个方法：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657protected AuthenticationInfo doSingleRealmAuthentication(Realm realm, AuthenticationToken token) &#123; if (!realm.supports(token)) &#123; String msg = \"Realm [\" + realm + \"] does not support authentication token [\" + token + \"]. Please ensure that the appropriate Realm implementation is \" + \"configured correctly or that the realm accepts AuthenticationTokens of this type.\"; throw new UnsupportedTokenException(msg); &#125; AuthenticationInfo info = realm.getAuthenticationInfo(token); if (info == null) &#123; String msg = \"Realm [\" + realm + \"] was unable to find account data for the \" + \"submitted AuthenticationToken [\" + token + \"].\"; throw new UnknownAccountException(msg); &#125; return info;&#125;protected AuthenticationInfo doMultiRealmAuthentication(Collection&lt;Realm&gt; realms, AuthenticationToken token) &#123; AuthenticationStrategy strategy = getAuthenticationStrategy(); AuthenticationInfo aggregate = strategy.beforeAllAttempts(realms, token); if (log.isTraceEnabled()) &#123; log.trace(\"Iterating through &#123;&#125; realms for PAM authentication\", realms.size()); &#125; for (Realm realm : realms) &#123; aggregate = strategy.beforeAttempt(realm, token, aggregate); if (realm.supports(token)) &#123; log.trace(\"Attempting to authenticate token [&#123;&#125;] using realm [&#123;&#125;]\", token, realm); AuthenticationInfo info = null; Throwable t = null; try &#123; info = realm.getAuthenticationInfo(token); &#125; catch (Throwable throwable) &#123; t = throwable; if (log.isDebugEnabled()) &#123; String msg = \"Realm [\" + realm + \"] threw an exception during a multi-realm authentication attempt:\"; log.debug(msg, t); &#125; &#125; aggregate = strategy.afterAttempt(realm, token, info, aggregate, t); &#125; else &#123; log.debug(\"Realm [&#123;&#125;] does not support token &#123;&#125;. Skipping realm.\", realm, token); &#125; &#125; aggregate = strategy.afterAllAttempts(token, aggregate); return aggregate;&#125;doSingleRealmAuthentication(..)方法不需要解释。doMultiRealmAuthentication(..)方法大体就是便利所有的Realm，如果这个Realm支持当前这个Token，则调用getAuthenticationInfo(AuthenticationToken)方法获取认证信息，然后根据使用的认证策略去处理认证信息。而getAuthenticationInfo(AuthenticationToken)方法很简单：12345678910111213141516171819202122public final AuthenticationInfo getAuthenticationInfo(AuthenticationToken token) throws AuthenticationException &#123; AuthenticationInfo info = getCachedAuthenticationInfo(token); if (info == null) &#123; //otherwise not cached, perform the lookup: info = doGetAuthenticationInfo(token); log.debug(\"Looked up AuthenticationInfo [&#123;&#125;] from doGetAuthenticationInfo\", info); if (token != null &amp;&amp; info != null) &#123; cacheAuthenticationInfoIfPossible(token, info); &#125; &#125; else &#123; log.debug(\"Using cached authentication info [&#123;&#125;] to perform credentials matching.\", info); &#125; if (info != null) &#123; assertCredentialsMatch(token, info); &#125; else &#123; log.debug(\"No AuthenticationInfo found for submitted AuthenticationToken [&#123;&#125;]. Returning null.\", token); &#125; return info;&#125;先从缓存中取，如果缓存里没有则调用doGetAuthenticationInfo(AuthenticationToken)方法获取（我们实现自己的Realm时一般就要实现这个方法，这个是获取认证信息的方法，还有一个获取权限信息的方法）最后，如果info不为null，调用assertCredentialsMatch(..)方法判断token和info是否匹配。默认使用的CredentialsMatcher是SimpleCredentialsMatcher，即调用AuthenticationToken和AuthenticationInfo的getCredentials()后进行简单的equal匹配。一个前后端分离案例JWTToken123456789101112131415161718192021222324252627282930313233343536373839404142public class JWTToken implements HostAuthenticationToken &#123; public static final JWTToken NONE = new JWTToken(null, null); private String token; private String host; public JWTToken(String token) &#123; this(token, null); &#125; public JWTToken(String token, String host) &#123; this.token = token; this.host = host; &#125; public String getToken() &#123; return this.token; &#125; public String getHost() &#123; return host; &#125; @Override public Object getPrincipal() &#123; return token; &#125; @Override public Object getCredentials() &#123; return token; &#125; @Override public String toString() &#123; return \"JWTToken&#123;\" + \"token='\" + token + '\\'' + \", host='\" + host + '\\'' + '&#125;'; &#125;&#125;JwtHttpAuthenticationFilter123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385package me.lolico.blog.web.filter;import me.lolico.blog.web.JWTToken;import org.apache.shiro.authc.AuthenticationException;import org.apache.shiro.authc.AuthenticationToken;import org.apache.shiro.subject.Subject;import org.apache.shiro.web.filter.authc.AuthenticatingFilter;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import javax.servlet.ServletRequest;import javax.servlet.ServletResponse;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.util.HashSet;import java.util.Locale;import java.util.Set;public class JwtHttpAuthenticationFilter extends AuthenticatingFilter &#123; /** * This class's private logger. */ private static final Logger log = LoggerFactory.getLogger(JwtHttpAuthenticationFilter.class); /** * HTTP Authorization header, equal to &lt;code&gt;Authorization&lt;/code&gt; */ private static final String AUTHORIZATION_HEADER = \"Authorization\"; /** * HTTP Authentication header, equal to &lt;code&gt;WWW-Authenticate&lt;/code&gt; */ private static final String AUTHENTICATE_HEADER = \"WWW-Authenticate\"; /** * The authzScheme default value to look for in the &lt;code&gt;Authorization&lt;/code&gt; header */ private static final String DEFAULT_AUTHORIZATION_SCHEME = \"Bearer\"; /** * The name that is displayed during the challenge process of authentication, defauls to &lt;code&gt;application&lt;/code&gt; * and can be overridden by the &#123;@link #setApplicationName(String) setApplicationName&#125; method. */ private String applicationName = \"application\"; /** * The authzScheme value to look for in the &lt;code&gt;Authorization&lt;/code&gt; header, defaults to &lt;code&gt;Bearer&lt;/code&gt; * Can override by &#123;@link #setAuthzScheme(String)&#125; */ private String authzScheme = DEFAULT_AUTHORIZATION_SCHEME; /** * &lt;code&gt;true&lt;/code&gt; will enable \"OPTION\" request method, &lt;code&gt;false&lt;/code&gt; otherwise */ private boolean isCorsEnable = true; /** * the callback handler for successful authentication */ private SuccessfulHandler successfulHandler; /** * the callback handler for unsuccessful authentication */ private UnsuccessfulHandler unsuccessfulHandler; public JwtHttpAuthenticationFilter() &#123; unsuccessfulHandler = (token, e, request, response) -&gt; &#123; //defaults to set 401-unauthorized http status HttpServletResponse httpResponse = ((HttpServletResponse) response); String authcHeader = getAuthzScheme() + \" realm=\\\"\" + getApplicationName() + \"\\\"\"; httpResponse.setHeader(AUTHENTICATE_HEADER, authcHeader); httpResponse.setStatus(HttpServletResponse.SC_UNAUTHORIZED); &#125;; &#125; public JwtHttpAuthenticationFilter(String authzScheme, boolean isCorsEnable, SuccessfulHandler successfulHandler, UnsuccessfulHandler unsuccessfulHandler) &#123; this.authzScheme = authzScheme; this.isCorsEnable = isCorsEnable; this.successfulHandler = successfulHandler; this.unsuccessfulHandler = unsuccessfulHandler; &#125; /** * Returns the name that is displayed during the challenge process of authentication * Default value is &lt;code&gt;application&lt;/code&gt; * * @return the name that is displayed during the challenge process of authentication */ public String getApplicationName() &#123; return applicationName; &#125; /** * Sets the name that is displayed during the challenge process of authentication * Default value is &lt;code&gt;application&lt;/code&gt; * * @param applicationName the name that is displayed during the challenge process of authentication */ public void setApplicationName(String applicationName) &#123; this.applicationName = applicationName; &#125; /** * Returns the HTTP &lt;b&gt;&lt;code&gt;Authorization&lt;/code&gt;&lt;/b&gt; header value that this filter will respond to as indicating * a login request. * &lt;p/&gt; * Unless overridden by the &#123;@link #setAuthzScheme(String)&#125; method, the * default value is &lt;code&gt;Bearer&lt;/code&gt;. * * @return the Http 'Authorization' header value that this filter will respond to as indicating a login request */ public String getAuthzScheme() &#123; return authzScheme; &#125; /** * Sets the HTTP &lt;b&gt;&lt;code&gt;Authorization&lt;/code&gt;&lt;/b&gt; header value that this filter will respond to as indicating a * login request. * &lt;p/&gt; * Unless overridden by this method, the default value is &lt;code&gt;Bearer&lt;/code&gt; * * @param authzScheme the HTTP &lt;code&gt;Authorization&lt;/code&gt; header value that this filter will respond to as * indicating a login request. */ public void setAuthzScheme(String authzScheme) &#123; this.authzScheme = authzScheme; &#125; /** * Default value is &lt;code&gt;true&lt;/code&gt; * * @param corsEnable &lt;code&gt;true&lt;/code&gt; will enable \"OPTION\" request method, &lt;code&gt;false&lt;/code&gt; otherwise */ public void setCorsEnable(boolean corsEnable) &#123; isCorsEnable = corsEnable; &#125; /** * Default value is &lt;code&gt;true&lt;/code&gt; * * @return is cors enable */ public boolean isCorsEnable() &#123; return isCorsEnable; &#125; /** * Returns the callback handler for successful authentication * * @return the callback handler for successful authentication */ public SuccessfulHandler getSuccessfulHandler() &#123; return successfulHandler; &#125; /** * @param successfulHandler the callback handler for successful authentication */ public void setSuccessfulHandler(SuccessfulHandler successfulHandler) &#123; this.successfulHandler = successfulHandler; &#125; /** * Returns the callback handler for unsuccessful authentication * * @return the callback handler for unsuccessful authentication */ public UnsuccessfulHandler getUnsuccessfulHandler() &#123; return unsuccessfulHandler; &#125; /** * @param unsuccessfulHandler the callback handler for successful authentication */ public void setUnsuccessfulHandler(UnsuccessfulHandler unsuccessfulHandler) &#123; this.unsuccessfulHandler = unsuccessfulHandler; &#125; /** * The Basic authentication filter can be configured with a list of HTTP methods to which it should apply. This * method ensures that authentication is &lt;em&gt;only&lt;/em&gt; required for those HTTP methods specified. For example, * if you had the configuration: * &lt;pre&gt; * [urls] * /basic/** = authcJwt[POST,PUT,DELETE] * &lt;/pre&gt; * then a GET request would not required authentication but a POST would. * * @param request The current HTTP servlet request. * @param response The current HTTP servlet response. * @param mappedValue The array of configured HTTP methods as strings. This is empty if no methods are configured. */ protected boolean isAccessAllowed(ServletRequest request, ServletResponse response, Object mappedValue) &#123; HttpServletRequest httpRequest = ((HttpServletRequest) request); String httpMethod = httpRequest.getMethod(); // Check whether the current request's method requires authentication. // If no methods have been configured, then all of them require auth, // otherwise only the declared ones need authentication. Set&lt;String&gt; methods = httpMethodsFromOptions((String[]) mappedValue); boolean authcRequired = methods.size() == 0; // If enable cors and this request_method is equal to \"OPTION\", do not authentication. // Can override by configuration: // /** = authcJwt[POST,DELETE,OPTION] // then a OPTION request would required authentication. // if (isCorsEnable &amp;&amp; httpMethod.equalsIgnoreCase(\"OPTION\")) &#123; // authcRequired = false; // &#125; for (String m : methods) &#123; if (httpMethod.toUpperCase(Locale.ENGLISH).equals(m)) &#123; // list of methods is in upper case authcRequired = true; break; &#125; &#125; // if (isCorsEnable &amp;&amp; httpMethod.equalsIgnoreCase(\"OPTION\")) &#123; // responseForCors(request, response); // &#125; if (authcRequired) &#123; return super.isAccessAllowed(request, response, mappedValue); &#125; else &#123; return true; &#125; &#125; /** * cors support */ @Override protected boolean preHandle(ServletRequest request, ServletResponse response) throws Exception &#123; if (isCorsEnable() &amp;&amp; ((HttpServletRequest) request).getMethod().equals(\"OPTIONS\")) &#123; responseForCors(request, response); return false; &#125; return super.preHandle(request, response); &#125; private void responseForCors(ServletRequest request, ServletResponse response) &#123; HttpServletRequest httpRequest = (HttpServletRequest) request; HttpServletResponse httpResponse = (HttpServletResponse) response; httpResponse.setHeader(\"Access-Control-Allow-Origin\", httpRequest.getHeader(\"Origin\")); httpResponse.setHeader(\"Access-Control-Allow-Headers\", httpRequest.getHeader(\"Access-Control-Allow-Headers\")); httpResponse.setHeader(\"Access-Control-Allow-Methods\", \"GET,POST,PUT,DELETE,OPTIONS\"); httpResponse.setHeader(\"Access-Control-Allow-Credentials\", \"true\"); httpResponse.setStatus(HttpServletResponse.SC_OK); &#125; private Set&lt;String&gt; httpMethodsFromOptions(String[] options) &#123; Set&lt;String&gt; methods = new HashSet&lt;&gt;(); if (options != null) &#123; for (String option : options) &#123; // to be backwards compatible with 1.3, we can ONLY check for known args // ideally we would just validate HTTP methods, but someone could already be using this for webdav if (!option.equalsIgnoreCase(PERMISSIVE)) &#123; methods.add(option.toUpperCase(Locale.ENGLISH)); &#125; &#125; &#125; return methods; &#125; /** * Processes unauthenticated requests. It handles the two-stage request/challenge authentication protocol. * * @param request incoming ServletRequest * @param response outgoing ServletResponse * @return true if the request should be processed; false if the request should not continue to be processed */ @Override protected boolean onAccessDenied(ServletRequest request, ServletResponse response) throws Exception &#123; boolean loggedIn = false; //false by default or we wouldn't be in this method if (isLoginRequest(request, response)) &#123; if (log.isDebugEnabled()) &#123; log.debug(\"Attempting to execute login with auth header\"); &#125; loggedIn = executeLogin(request, response); &#125; return loggedIn; &#125; /** * Returns &lt;code&gt;true&lt;/code&gt; if the incoming request have &#123;@link #getAuthzHeader(ServletRequest)&#125; * and the header's value is start with &#123;@link #getAuthzScheme()&#125;, &lt;code&gt;false&lt;/code&gt; otherwise. * * @param request the incoming &lt;code&gt;ServletRequest&lt;/code&gt; * @param response the outgoing &lt;code&gt;ServletResponse&lt;/code&gt; * @return &lt;code&gt;true&lt;/code&gt; if the incoming request is required auth, &lt;code&gt;false&lt;/code&gt; otherwise. */ @Override protected boolean isLoginRequest(ServletRequest request, ServletResponse response) &#123; String authzHeader = getAuthzHeader(request); String scheme = getAuthzScheme().toLowerCase(Locale.ENGLISH); return authzHeader != null &amp;&amp; authzHeader.toLowerCase(Locale.ENGLISH).startsWith(scheme); &#125; /** * @param request the incoming &lt;code&gt;ServletRequest&lt;/code&gt; * @return the &lt;code&gt;Authorization&lt;/code&gt; header's value */ private String getAuthzHeader(ServletRequest request) &#123; return ((HttpServletRequest) request).getHeader(AUTHORIZATION_HEADER); &#125; /** * Returns the authentication token encapsulated by the value of the Authorization header * * @param request the incoming &lt;code&gt;ServletRequest&lt;/code&gt; * @param response the outgoing &lt;code&gt;ServletResponse&lt;/code&gt; * @return the authentication token encapsulated by the value of the Authorization header */ @Override protected AuthenticationToken createToken(ServletRequest request, ServletResponse response) throws Exception &#123; String authzHeader = getAuthzHeader(request); if (authzHeader == null || authzHeader.length() == 0) &#123; return JWTToken.NONE; &#125; String scheme = getAuthzScheme(); if (scheme != null &amp;&amp; scheme.length() != 0) &#123; authzHeader = authzHeader.substring(scheme.length()); &#125; String token = authzHeader.trim(); String host = request.getRemoteHost(); return new JWTToken(token, host); &#125; /** * Callback processing after authentication successful. */ @Override protected boolean onLoginSuccess(AuthenticationToken token, Subject subject, ServletRequest request, ServletResponse response) throws Exception &#123; if (successfulHandler != null) &#123; if (log.isDebugEnabled()) &#123; log.debug(\"&#123;&#125; can pass auth, the auth subject is &#123;&#125;\", token, subject); &#125; successfulHandler.onSuccessful(token, subject, request, response); &#125; return true; &#125; /** * Callback processing after authentication failure. */ @Override protected final boolean onLoginFailure(AuthenticationToken token, AuthenticationException e, ServletRequest request, ServletResponse response) &#123; if (unsuccessfulHandler != null) &#123; if (log.isDebugEnabled()) &#123; log.debug(\"&#123;&#125; can not pass auth, the auth exception message is &#123;&#125;\", token, e.getMessage()); &#125; unsuccessfulHandler.onUnsuccessful(token, e, request, response); &#125; return false; &#125; &#125;interface UnsuccessfulHandler &#123; /** * Callback processing when auth successful * * @param token the token can not pass authentication * @param e the exception thrown during authentication * @param request the incoming &lt;code&gt;ServletRequest&lt;/code&gt; * @param response the outgoing &lt;code&gt;ServletResponse&lt;/code&gt; */ void onUnsuccessful(AuthenticationToken token, AuthenticationException e, ServletRequest request, ServletResponse response);&#125;interface SuccessfulHandler &#123; /** * Callback processing when auth unsuccessful * * @param token the token can pass authentication * @param subject the incoming auth &lt;code&gt;Subject&lt;/code&gt; * @param request the incoming &lt;code&gt;ServletRequest&lt;/code&gt; * @param response the outgoing &lt;code&gt;ServletResponse&lt;/code&gt; */ void onSuccessful(AuthenticationToken token, Subject subject, ServletRequest request, ServletResponse response);&#125;JwtRealm1234567891011121314151617181920212223@Componentpublic class JwtRealm extends AuthorizingRealm &#123; @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) &#123; return null; &#125; @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException &#123; String jwt = ((JWTToken) token).getToken(); boolean authResult = JwtUtils.verifyToken(jwt); if (!authResult) &#123; throw new IncorrectCredentialsException(); &#125; return new SimpleAuthenticationInfo(jwt, jwt, getName()); &#125; @Override public boolean supports(AuthenticationToken token) &#123; return token instanceof JWTToken; &#125;&#125;JwtUtils123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140@Slf4j@Componentpublic class JwtUtils &#123; private static String issuer; private static String secret; private static Duration lifeTime; private static SignatureAlgorithm algorithm; @Autowired public void init(SecurityProperties securityProperties) &#123; SecurityProperties.JWT jwt = securityProperties.getJwt(); JwtUtils.issuer = jwt.getIss(); JwtUtils.secret = jwt.getSecret(); JwtUtils.lifeTime = jwt.getLifeTime(); JwtUtils.algorithm = jwt.getAlg(); &#125; public static String createToken(String subject) &#123; Map&lt;String, Object&gt; claims = Collections.emptyMap(); return doCreateToken(subject, claims, lifeTime); &#125; public static String createToken(String subject, Consumer&lt;Map&lt;String, Object&gt;&gt; consumer) &#123; Map&lt;String, Object&gt; claims = new HashMap&lt;&gt;(); consumer.accept(claims); return doCreateToken(subject, claims, lifeTime); &#125; public static String createToken(String subject, Map&lt;String, Object&gt; claims) &#123; return createToken(subject, map -&gt; map.putAll(claims)); &#125; public static String createToken(String subject, Map&lt;String, Object&gt; claims, long expiration, ChronoUnit unit) &#123; return doCreateToken(subject, claims, Duration.of(expiration, unit)); &#125; private static String doCreateToken(String subject, Map&lt;String, Object&gt; claims, Duration expiration) &#123; Instant now = Instant.now(); JwtBuilder builder = Jwts.builder() .setHeaderParam(Header.TYPE, Header.JWT_TYPE) //添加令牌类型 .addClaims(claims) //添加自定义Claims .setSubject(subject) //接受人 .setIssuedAt(Date.from(now)) //签发时间 .signWith(algorithm, secret); if (StringUtils.hasText(issuer)) &#123; builder.setIssuer(issuer); //签发人 &#125; if (expiration != null &amp;&amp; expiration.isNegative()) &#123; builder.setExpiration(Date.from(now.plus(expiration))); //过期时间 &#125; String token = builder.compact(); if (log.isTraceEnabled()) &#123; log.trace(\"Create token[&#123;&#125;] in &#123;&#125;\", token, Date.from(now)); &#125; return token; &#125; public static Claims getClaims(String token) &#123; Claims body; try &#123; body = Jwts.parser() .setSigningKey(secret) .parseClaimsJws(token) .getBody(); &#125; catch (ExpiredJwtException e) &#123; // ignoring expired token exception body = e.getClaims(); &#125; catch (Exception e) &#123; if (log.isDebugEnabled()) &#123; log.debug(\"An exception[&#123;&#125;] occurred during get claims\", e.getMessage()); &#125; body = null; &#125; return body; &#125; public static boolean verifyToken(String token) &#123; //noinspection rawtypes Jwt jwt; try &#123; jwt = parseToken(token); &#125; catch (Exception e) &#123; if (log.isDebugEnabled()) &#123; log.debug(\"Token[&#123;&#125;] verify failed, message: &#123;&#125;\", token, e.getMessage()); &#125; return false; &#125; Claims claims = (Claims) jwt.getBody(); String issuer = claims.getIssuer(); if (issuer != null &amp;&amp; !issuer.equals(JwtUtils.issuer)) &#123; if (log.isDebugEnabled()) &#123; String msg = \"Incorrect issuer: \" + issuer; log.debug(\"Token[&#123;&#125;] verify failed, message: &#123;&#125;\", token, msg); &#125; return false; &#125; String subject = claims.getSubject(); if (!StringUtils.hasText(subject)) &#123; if (log.isDebugEnabled()) &#123; String msg = \"subject cannot be null or empty\"; log.debug(\"Token[&#123;&#125;] verify failed, message: &#123;&#125;\", token, msg); &#125; return false; &#125; return true; &#125; /** * @see JwtParser#parse(String) */ @SuppressWarnings(\"rawtypes\") private static Jwt parseToken(String token) throws ExpiredJwtException, MalformedJwtException, SignatureException &#123; return Jwts.parser() .setSigningKey(secret) .parse(token); &#125; public static boolean isValidToken(String token, String subject) &#123; Optional&lt;String&gt; username = getClaimFromToken(token, Claims::getSubject); return username.filter(s -&gt; (s.equals(subject) &amp;&amp; !isTokenExpired(token))).isPresent(); &#125; public static boolean isTokenExpired(String token) &#123; Optional&lt;Date&gt; expiration = getClaimFromToken(token, Claims::getExpiration); return expiration.map(date -&gt; date.before(new Date())).orElse(false); &#125; public static &lt;T&gt; Optional&lt;T&gt; getClaimFromToken(String token, Function&lt;Claims, T&gt; resolver) &#123; Claims claims = getClaims(token); if (claims == null) &#123; if (log.isDebugEnabled()) &#123; log.debug(\"Cannot operate on a null Claims\"); &#125; return Optional.empty(); &#125; return Optional.ofNullable(resolver.apply(claims)); &#125;&#125;ShiroConfig123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990@Configuration@EnableConfigurationProperties(SecurityProperties.class)@ConditionalOnProperty(name = \"me.lolico.blog.security.enable\", matchIfMissing = true)public class ShiroConfig &#123; @Bean public SecurityManager securityManager(Collection&lt;Realm&gt; realms) &#123; DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager(realms); /* * 关闭shiro自带的session */ DefaultSubjectDAO subjectDAO = new DefaultSubjectDAO(); DefaultSessionStorageEvaluator defaultSessionStorageEvaluator = new DefaultSessionStorageEvaluator(); defaultSessionStorageEvaluator.setSessionStorageEnabled(false); subjectDAO.setSessionStorageEvaluator(defaultSessionStorageEvaluator); securityManager.setSubjectDAO(subjectDAO); //认证器 ModularRealmAuthenticator authenticator = new ModularRealmAuthenticator(); authenticator.setRealms(realms); //认证策略 authenticator.setAuthenticationStrategy(new FirstSuccessfulStrategy()); securityManager.setAuthenticator(authenticator); return securityManager; &#125; @Bean public ShiroFilterFactoryBean shiroFilterFactoryBean(SecurityManager securityManager) &#123; ShiroFilterFactoryBean factoryBean = new ShiroFilterFactoryBean(); factoryBean.setSecurityManager(securityManager); // 自定义过滤器 Map&lt;String, Filter&gt; map = new HashMap&lt;&gt;(); map.put(\"auth\", new JwtHttpAuthenticationFilter()); factoryBean.setFilters(map); // 自定义路由策略 Map&lt;String, String&gt; definitionMap = new LinkedHashMap&lt;&gt;(); definitionMap.put(\"/login\", \"anon\"); definitionMap.put(\"/register\", \"anon\"); definitionMap.put(\"/u/confirm/**\", \"anon\"); definitionMap.put(\"/**\", \"auth\"); factoryBean.setFilterChainDefinitionMap(definitionMap); return factoryBean; &#125; /** * A &#123;@code credentialsMatcher&#125;, * using SHA256 algorithm and iteration three times * * @return a credentialsMatcher */ @Bean public CredentialsMatcher hashedCredentialsMatcher() &#123; HashedCredentialsMatcher credentialsMatcher = new HashedCredentialsMatcher(); credentialsMatcher.setHashAlgorithmName(Sha256Hash.ALGORITHM_NAME); credentialsMatcher.setHashIterations(Constant.security.ITERATIONS); credentialsMatcher.setStoredCredentialsHexEncoded(Constant.security.TO_HEX); return credentialsMatcher; &#125; /** * Annotation support */ @Bean @DependsOn(\"lifecycleBeanPostProcessor\") public DefaultAdvisorAutoProxyCreator defaultAdvisorAutoProxyCreator() &#123; DefaultAdvisorAutoProxyCreator defaultAdvisorAutoProxyCreator = new DefaultAdvisorAutoProxyCreator(); // 强制使用cglib，防止重复代理和可能引起代理出错的问题 // https://zhuanlan.zhihu.com/p/29161098 defaultAdvisorAutoProxyCreator.setProxyTargetClass(true); return defaultAdvisorAutoProxyCreator; &#125; @Bean public LifecycleBeanPostProcessor lifecycleBeanPostProcessor() &#123; return new LifecycleBeanPostProcessor(); &#125; @Bean public AuthorizationAttributeSourceAdvisor authorizationAttributeSourceAdvisor(SecurityManager securityManager) &#123; AuthorizationAttributeSourceAdvisor advisor = new AuthorizationAttributeSourceAdvisor(); advisor.setSecurityManager(securityManager); return advisor; &#125; &#125;JwtRealm#doGetAuthorizationInfo获取权限可以从token中解析然后返回，注意在生成token的时候要放到Claims中JwtAuthenticationFilter#isAccessAllowed方法中注释的部分和JwtAuthenticationFilter#preHandle方法是支持cors的两种方式。至于其他地方，应该不难理解。后语Shiro的认证流程到现在，那么也就分析完了。从Shiro的Filter到SecurityManager再到前后端分离案例，其实一路看下来，Shiro框架的代码是十分优雅并且简单易用的。文章中代码较多。如有任何错误，还请指出，谢谢。","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Shiro","slug":"Shiro","permalink":"https://lolico.me/tags/Shiro/"},{"name":"Web","slug":"Web","permalink":"https://lolico.me/tags/Web/"},{"name":"Security","slug":"Security","permalink":"https://lolico.me/tags/Security/"}]},{"title":"Shiro简介","slug":"Shiro简介","date":"2020-02-04T10:48:33.000Z","updated":"2022-05-02T03:45:10.806Z","comments":true,"path":"2020/02/04/Shiro简介/","link":"","permalink":"https://lolico.me/2020/02/04/Shiro%E7%AE%80%E4%BB%8B/","excerpt":"","text":"Apache Shiro是一个强大且易用的Java安全框架,执行身份验证、授权、密码和会话管理。使用Shiro的易于理解的API,您可以快速、轻松地获得任何应用程序,从最小的移动应用程序到最大的网络和企业应用程序。Shiro 可以非常容易的开发出足够好的应用，其不仅可以用在 JavaSE 环境，也可以用在JavaEE 环境。Shiro 可以帮助我们完成：认证、授权、加密、会话管理、与 Web 集成、缓存等。Authentication：身份认证/登录，验证用户是不是拥有相应的身份；Authorization：授权，即权限验证，验证某个已认证的用户是否拥有某个权限；即判断用户是否能做事情，常见的如：验证某个用户是否拥有某个角色。或者细粒度的验证某个用户对某个资源是否具有某个权限；Session Manager：会话管理，即用户登录后就是一次会话，在没有退出之前，它的所有信息都在会话中；会话可以是普通JavaSE 环境的，也可以是如 Web 环境的；Cryptography：加密，保护数据的安全性，如密码加密存储到数据库，而不是明文存储；Web Support：Web 支持，可以非常容易的集成到 Web 环境；Caching：缓存，比如用户登录后，其用户信息、拥有的角色/权限不必每次去查，这样可以提高效率；Concurrency：shiro 支持多线程应用的并发验证，即如在一个线程中开启另一个线程，能把权限自动传播过去；Testing：提供测试支持；Run As：允许一个用户假装为另一个用户（如果他们允许）的身份进行访问；Remember Me：记住我，这个是非常常见的功能，即一次登录后，下次再来的话不用登录了。注：Shiro 不会去维护用户、维护权限；这些需要我们自己去设计/提供；然后通过相应的接口注入给 Shiro 即可。从外部看，Shiro 中对外交互的API如下：Subject：主体，代表了当前“用户”，这个用户不一定是一个具体的人，与当前应用交互的任何东西都是 Subject，如网络爬虫，机器人等；即一个抽象概念；所有 Subject 都绑定到 SecurityManager，与 Subject 的所有交互都会委托给 SecurityManager；可以把 Subject 认为是一个门面；SecurityManager 才是实际的执行者；SecurityManager：安全管理器；即所有与安全有关的操作都会与 SecurityManager 交互；且它管理着所有 Subject；可以看出它是 Shiro 的核心，它负责与后边介绍的其他组件进行交互，如果学习过 SpringMVC，你可以把它看成 DispatcherServlet 前端控制器；Realm：域，Shiro 从从 Realm 获取安全数据（如用户、角色、权限），就是说 SecurityManager要验证用户身份，那么它需要从 Realm 获取相应的用户进行比较以确定用户身份是否合法；也需要从 Realm 得到用户相应的角色/权限进行验证用户是否能进行操作；可以把 Realm 看成 DataSource，即安全数据源。从内部看，Shiro 中的架构如下：Subject：主体，可以看到主体可以是任何可以与应用交互的“用户”；SecurityManager ： 相 当 于 SpringMVC 中 的 DispatcherServlet 或 者 Struts2 中 的 FilterDispatcher；是 Shiro 的心脏；所有具体的交互都通过 SecurityManager 进行控制；它管理着所有 Subject、且负责进行认证和授权、及会话、缓存的管理。Authenticator：认证器，负责主体认证的，这是一个扩展点，如果用户觉得 Shiro 默认的不好，可以自定义实现；其需要认证策略（Authentication Strategy），即什么情况下算用户认证通过了；Authrizer：授权器，或者访问控制器，用来决定主体是否有权限进行相应的操作；即控制着用户能访问应用中的哪些功能；Realm：可以有 1 个或多个 Realm，可以认为是安全实体数据源，即用于获取安全实体的；可以是 JDBC 实现，也可以是 LDAP 实现，或者内存实现等等；由用户提供；注意：不知道你的用户/权限存储在哪及以何种格式存储；所以我们一般在应用中都需要实现自己的 Realm；SessionManager：如果写过 Servlet 就应该知道 Session 的概念，Session 呢需要有人去管理它的生命周期，这个组件就是 SessionManager；而 Shiro 并不仅仅可以用在 Web 环境，也可以用在如普通的 JavaSE 环境、EJB 等环境；所有呢，Shiro 就抽象了一个自己的 Session来管理主体与应用之间交互的数据；这样的话，比如我们在 Web 环境用，刚开始是一台Web 服务器；接着又上了台 EJB 服务器；这时想把两台服务器的会话数据放到一个地方，这个时候就可以实现自己的分布式会话（如把数据放到 Memcached 服务器）；SessionDAO：DAO 大家都用过，数据访问对象，用于会话的 CRUD，比如我们想把 Session保存到数据库，那么可以实现自己的 SessionDAO，通过如 JDBC 写到数据库；比如想把Session 放到 Memcached 中，可以实现自己的 Memcached SessionDAO；另外 SessionDAO中可以使用 Cache 进行缓存，以提高性能；CacheManager：缓存控制器，来管理如用户、角色、权限等的缓存的；因为这些数据基本上很少去改变，放到缓存中后可以提高访问的性能Cryptography：密码模块，Shiro 提高了一些常见的加密组件用于如密码加密/解密的。","categories":[{"name":"不正常的文章","slug":"不正常的文章","permalink":"https://lolico.me/categories/%E4%B8%8D%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Shiro","slug":"Shiro","permalink":"https://lolico.me/tags/Shiro/"},{"name":"Web","slug":"Web","permalink":"https://lolico.me/tags/Web/"},{"name":"Security","slug":"Security","permalink":"https://lolico.me/tags/Security/"}]},{"title":"时间戳作为salt时的精度问题","slug":"时间戳作为salt时的精度问题","date":"2020-01-23T10:46:22.000Z","updated":"2022-05-02T03:45:10.810Z","comments":true,"path":"2020/01/23/时间戳作为salt时的精度问题/","link":"","permalink":"https://lolico.me/2020/01/23/%E6%97%B6%E9%97%B4%E6%88%B3%E4%BD%9C%E4%B8%BAsalt%E6%97%B6%E7%9A%84%E7%B2%BE%E5%BA%A6%E9%97%AE%E9%A2%98/","excerpt":"","text":"前言在web项目中采用用户注册时的时间戳作为密码加密的salt：123public String getSalt(User user) &#123; return String.valueOf(user.getRegistrationTime().getTime()/1000L);&#125;数据库中保存注册时间戳的字段类型使用Timestamp(0)即10位精确到的秒时间戳注册用户逻辑：12345678910111213public User registerAnAccount(User user) &#123; if (isExist(user.getName(), user.getEmail())) &#123; return null; &#125; HttpServletRequest request = ((ServletRequestAttributes) Objects.requireNonNull(RequestContextHolder.getRequestAttributes())).getRequest(); user.setRegistrationIp(request.getRemoteAddr()); user.setRegistrationTime(Timestamp.from(Instant.now())); user.setStatus(User.Status.WAITING_CONFIRMATION); user.setPassword(HashUtils.hash(user.getPassword(), getSalt(user))); return repository.save(user);&#125;获取时间戳后设置注册用户的属性，使用时间戳作为salt给密码加密保存到数据库。getSalt(User)方法直接返回timestamp.getTime()/1000L的值，是一个10位精确到秒的时间戳。在用户登录时发现部分用户登录密码错误。可以保证的是业务代码的逻辑是没有问题的，那么可以肯定应该就是数据存储到数据库时发生了问题。原因模拟注册操作，打上断点：salt：1579764044registrationTime：2020-01-23 15:20:44.986（可以看到nanos字段为986000000，精确到毫秒）模拟登录操作，采用Shiro框架实现认证和鉴权，在返回SimpleAuthenticationInfo时打上断点：查看从数据库查出来的用户信息和salt值：salt：1579764045registrationTime：2020-01-23 15:20:45.0（nanons字段为0因为数据库字段设置为精确到秒）在这个测试用例之前还模拟了一些用户注册和登录，发现用户在登陆时的salt值和注册时的是一样的，可以登录成功，而这个在登陆时的却比注册时所用的salt大1，观察到能登陆成功的用户信息注册时的时间戳字段毫秒部分都小于500，而这个用例的毫秒部分为986，猜测在保存时间戳到数据库，丢失精度（毫秒部分）时会进行四舍五入，毫秒部分大于500进1，所以导致的就是在注册时如果毫秒部分大于500，注册get的盐值会比登录时get的盐值要小1，也就是上面图片中的情况。google并且大量测试证实了猜想。解决数据库Timestamp类型长度设置为3即精确到毫秒（可以保证在保存时不会发生丢失精度导致的四舍五入情况）修改getSalt(User)方法：1234567public String getSalt(User user) &#123; int nanos = user.getRegistrationTime().getNanos(); if (nanos &gt; 500000000) &#123; return String.valueOf(user.getRegistrationTime().getTime() / 1000L + 1); &#125; return String.valueOf(user.getRegistrationTime().getTime() / 1000L);&#125;注册时设置registrationTime123&#x2F;&#x2F;user.setRegistrationTime(Timestamp.from(Instant.now()));&#x2F;&#x2F;改为下面这种，截断毫秒部分user.setRegistrationTime(new Timestamp(Instant.now().getEpochSecond()*1000));","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://lolico.me/tags/Java/"},{"name":"Password","slug":"Password","permalink":"https://lolico.me/tags/Password/"},{"name":"Salt","slug":"Salt","permalink":"https://lolico.me/tags/Salt/"}]},{"title":"SpringBoot Aop+注解实现动态多数据源","slug":"SpringBoot-Aop-注解实现动态多数据源","date":"2020-01-17T10:43:19.000Z","updated":"2022-05-02T03:45:10.806Z","comments":true,"path":"2020/01/17/SpringBoot-Aop-注解实现动态多数据源/","link":"","permalink":"https://lolico.me/2020/01/17/SpringBoot-Aop-%E6%B3%A8%E8%A7%A3%E5%AE%9E%E7%8E%B0%E5%8A%A8%E6%80%81%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%90/","excerpt":"","text":"前言Spring提供了AbstractRoutingDataSource类以方便开发者实现多数据源，看一下AbstractRoutingDataSource#getConnection()的源码：1234@Overridepublic Connection getConnection() throws SQLException &#123; return determineTargetDataSource().getConnection();&#125;可以看到在getConnection()方法中是通过调用determineTargetDataSource().getConnection();获取一个连接，继续追踪到determineTargetDataSource()方法：12345678910111213141516protected DataSource determineTargetDataSource() &#123; Assert.notNull(this.resolvedDataSources, \"DataSource router not initialized\"); //获取key,模板方法模式 Object lookupKey = determineCurrentLookupKey(); //根据key获取DataSource DataSource dataSource = this.resolvedDataSources.get(lookupKey); //如果dataSource为空并且启用获取默认dataSource或lookupKey为空时取默认的DataSource //（lenientFallback默认为true） if (dataSource == null &amp;&amp; (this.lenientFallback || lookupKey == null)) &#123; dataSource = this.resolvedDefaultDataSource; &#125; if (dataSource == null) &#123;//如果dataSource为空抛出异常 throw new IllegalStateException(\"Cannot determine target DataSource for lookup key [\" + lookupKey + \"]\"); &#125; return dataSource;&#125;可以看到determineTargetDataSource()方法先调用determineCurrentLookupKey()获取lookupKey，再通过this.resolvedDataSources.get(lookupKey);取出DataSource，我们看一下determineCurrentLookupKey()方法，发现这个方法是个abstract方法，也就是说子类必须要实现，再看下this.resolvedDataSources是个什么东西：1private Map&lt;Object, DataSource&gt; resolvedDataSources;所以说AbstractRoutingDataSource中维护了一个Map，在getConnection的时候先获取key再从resolvedDataSources中get一个DataSource返回（如果为空时判断是否启用获取默认dataSource再决定是否用默认的dataSource）而获取key的方法determineCurrentLookupKey()由子类实现（模板方法模式）。所以实现动态多数据源的思路就十分明确了定义一个DynamicDataSourceContextHolder用于保存当前线程需要使用的dataSource对应的key重写determineCurrentLookupKey()方法将这个key返回实际上完成上述两个步骤其实就可以实现多数据源了，只要在getConnection前调用DynamicDataSourceContextHolder#setKey方法设置需要使用的dataSource对应的key就可以了。但通常来说，我们并不希望设置使用那个数据库的代码侵入到我们的业务代码中，所以我们可以利用aop实现：定义一个注解@DataSource和注解切面DataSourceAspect，然后就可以在需要切换数据库的方法上使用注解进行设置。代码DataSourceConfiguration12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970@Slf4j@Configurationpublic class DataSourceConfiguration implements ApplicationContextAware &#123; private ApplicationContext applicationContext; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; this.applicationContext = applicationContext; &#125; /* configuration */ @Bean @Qualifier(\"defaultDataSource\") @ConfigurationProperties(prefix = \"spring.datasource.first\") public DataSource dataSource1() &#123; return DataSourceBuilder.create().build(); &#125; @Bean @ConfigurationProperties(prefix = \"spring.datasource.second\") public DataSource dataSource2() &#123; return DataSourceBuilder.create().build(); &#125; @Bean @Primary public DataSource dataSource(Map&lt;String, DataSource&gt; dataSourceMap, @Qualifier(\"defaultDataSource\") DataSource defaultDataSource) &#123; AbstractRoutingDataSource dataSource = new AbstractRoutingDataSource() &#123; @Override protected Object determineCurrentLookupKey() &#123; return DynamicDataSourceContextHolder.getKey(); &#125; @Override public void setTargetDataSources(Map&lt;Object, Object&gt; targetDataSources) &#123; super.setTargetDataSources(targetDataSources); DynamicDataSourceContextHolder.setDataSourceMap(targetDataSources); &#125; @Override public void setDefaultTargetDataSource(Object defaultTargetDataSource) &#123; if (defaultTargetDataSource instanceof String) &#123; super.setDefaultTargetDataSource(dataSourceMap.get(defaultTargetDataSource)); DynamicDataSourceContextHolder.setDefaultKey((String) defaultTargetDataSource); &#125; else if (defaultTargetDataSource instanceof DataSource) &#123; super.setDefaultTargetDataSource(defaultTargetDataSource); DynamicDataSourceContextHolder.setDefaultKey(resolveSpecifiedLookupKey((DataSource) defaultTargetDataSource)); &#125; else &#123; log.info(\"Why am i here?\"); &#125; &#125; private String resolveSpecifiedLookupKey(DataSource defaultTargetDataSource) &#123; String[] beanDefinitionNames = applicationContext.getBeanNamesForType(defaultTargetDataSource.getClass()); for (String beanDefinitionName : beanDefinitionNames) &#123; if (applicationContext.getBean(beanDefinitionName) == defaultTargetDataSource) &#123; return beanDefinitionName; &#125; &#125; return null; &#125; &#125;; dataSource.setTargetDataSources(Collections.unmodifiableMap(dataSourceMap)); dataSource.setDefaultTargetDataSource(defaultDataSource); return dataSource; &#125; &#125;DynamicDataSourceContextHolder12345678910111213141516171819202122232425262728@Slf4jpublic class DynamicDataSourceContextHolder &#123; private final static ThreadLocal&lt;String&gt; KEY = new ThreadLocal&lt;&gt;(); private static Map&lt;Object, Object&gt; targetDataSourceMap; private static String defaultKey; public static void setDataSourceMap(Map&lt;Object, Object&gt; targetDataSourceMap) &#123; DynamicDataSourceContextHolder.targetDataSourceMap = targetDataSourceMap; &#125; public static String getKey() &#123; return Optional.ofNullable(DynamicDataSourceContextHolder.KEY.get()) .orElseGet(() -&gt; DynamicDataSourceContextHolder.defaultKey); &#125; public static void setKey(String key) &#123; DynamicDataSourceContextHolder.KEY.set(targetDataSourceMap.containsKey(key) ? key : DynamicDataSourceContextHolder.defaultKey); &#125; public static void remove() &#123; DynamicDataSourceContextHolder.KEY.remove(); &#125; public static void setDefaultKey(String defaultKey) &#123; DynamicDataSourceContextHolder.defaultKey = defaultKey; log.debug(\"设置defaultKey:[&#123;&#125;]\", defaultKey); &#125;&#125;DataSource注解1234567@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)@Inherited@Documentedpublic @interface DataSource &#123; String value() default \"\";&#125;DataSourceAspect切面12345678910111213141516171819202122@Slf4j@Component@Aspect@Order(Ordered.LOWEST_PRECEDENCE - 1)public class DataSourceAspect &#123; @Pointcut(value = \"@annotation(dataSource)\", argNames = \"dataSource\") public void pointcut(DataSource dataSource) &#123; &#125; @Before(value = \"pointcut(dataSource)\", argNames = \"dataSource\") public void before(DataSource dataSource) &#123; String value = dataSource.value(); DynamicDataSourceContextHolder.setKey(value); log.debug(\"使用数据库&#123;&#125;\", value); &#125; @After(\"@annotation(cn.griouges.learnspringboot.common.annotation.DataSource)\") public void after() &#123; DynamicDataSourceContextHolder.remove(); &#125;&#125;测试发现如果切面优先级为Ordered.LOWEST_PRECEDENCE时，每次都会在getConnection之后再拦截进行设置key，不符合我们的需求，添加@Order(Ordered.LOWEST_PRECEDENCE - 1)设置切面优先级，在获取数据库连接前进行设置数据库key。配置完毕后续还有数据源，只要注册bean到容器中就可以自动添加到AbstractRoutingDataSource的targetDataSources中，key为bean的name。测试application.properties中添加配置12345678spring.datasource.first.jdbc-url=jdbc:mysql://localhost:3306/mysite?useUnicode=true&amp;characterEncoding=utf-8spring.datasource.first.username=rootspring.datasource.first.password=leisure.spring.datasource.first.driver-class-name=com.mysql.cj.jdbc.Driverspring.datasource.second.jdbc-url=jdbc:mysql://localhost:3306/test?useUnicode=true&amp;characterEncoding=utf-8spring.datasource.second.username=rootspring.datasource.second.password=leisure.spring.datasource.second.driver-class-name=com.mysql.cj.jdbc.Driverservice层的方法上添加注解1234@DataSource(\"dataSource2\")public User findUserForLogin(String username, String password) &#123; return userRepository.findByUsernameAndPassword(username, password);&#125;测试发现在Dao层的接口进行注解时，拦截会在获取连接后执行，导致失效。具体原因没去深追，后续有时间再断点调试查看是什么原因，orm使用的是Sprng Data Jpa，使用mybatis貌似不会出现这种情况。controler添加测试方法12345678@PostMapping(\"/test\")public AjaxResponseVO test(String username,String password) &#123; User userForLogin = service.findUserForLogin(username, password); if (userForLogin != null) &#123; return AjaxResponseVO.success(\"登录成功\"); &#125; return AjaxResponseVO.fail(\"用户名或密码错误\");&#125;post测试：测试通过，打印日志:","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://lolico.me/tags/Spring/"},{"name":"Java","slug":"Java","permalink":"https://lolico.me/tags/Java/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://lolico.me/tags/SpringBoot/"}]},{"title":"SpringBoot时间格式化总结","slug":"SpringBoot时间格式化总结","date":"2020-01-16T12:18:15.000Z","updated":"2022-05-02T03:45:10.806Z","comments":true,"path":"2020/01/16/SpringBoot时间格式化总结/","link":"","permalink":"https://lolico.me/2020/01/16/SpringBoot%E6%97%B6%E9%97%B4%E6%A0%BC%E5%BC%8F%E5%8C%96%E6%80%BB%E7%BB%93/","excerpt":"","text":"Json中的时间对于json形式的请求或响应(content-type=application/json)，格式化时间有如下方法：配置spring.jackson.date-format使用@JsonFormat自定义ObjectMapper通过Jackson2ObjectMapperBuilderCustomizer自定义ObjectMapper自定义com.fasterxml.jackson.databind.Module见org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration非Json中的时间对于表单请求，格式化时间有如下方法：配置spring.mvc.format.date配置spring.mvc.format.time配置spring.mvc.format.date-time定义Converter定义Formatter使用@DateTimeFormat见org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration.EnableWebMvcConfiguration#mvcConversionService","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://lolico.me/tags/Spring/"},{"name":"Java","slug":"Java","permalink":"https://lolico.me/tags/Java/"},{"name":"Web","slug":"Web","permalink":"https://lolico.me/tags/Web/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://lolico.me/tags/SpringBoot/"}]},{"title":"SpringBoot时间类型参数绑定和序列化为Json时格式化的问题","slug":"SpringBoot时间类型参数绑定和序列化为Json时格式化的问题","date":"2020-01-15T10:34:15.000Z","updated":"2022-05-02T03:45:10.806Z","comments":true,"path":"2020/01/15/SpringBoot时间类型参数绑定和序列化为Json时格式化的问题/","link":"","permalink":"https://lolico.me/2020/01/15/SpringBoot%E6%97%B6%E9%97%B4%E7%B1%BB%E5%9E%8B%E5%8F%82%E6%95%B0%E7%BB%91%E5%AE%9A%E5%92%8C%E5%BA%8F%E5%88%97%E5%8C%96%E4%B8%BAJson%E6%97%B6%E6%A0%BC%E5%BC%8F%E5%8C%96%E7%9A%84%E9%97%AE%E9%A2%98/","excerpt":"","text":"前言在使用Spring进行web开发时经常会遇到前后台互相传值的问题，大致分无非就是下面两种情况：将参数以及值直接放在request的请求体（POST）或者url（GET）中。将参数以及值以JSON的形式发送（POST或者GET）到服务端。Spring其实对前后台传值时参数的绑定提供了支持，像我们平时接触的转换器Converter以及消息转换器HttpMessageConverter的工作就是将‘值’进行类型转化或格式化后绑定到我们的方法参数中。对于简单的基础类型，我们一般并不需要进行处理，而是转换成对应的类型后直接拿原始的值就行了；但是对于某些类型，比如时间，我们通常会考虑进行格式化后传到前台或者要指定传来的格式才能绑定到方法中，所以就需要指定一个标准。这往往让人很困惑，因为可能传来的是request中的也可能是requestBody中的，而在发送给前台时也可能是以JSON或者其他的形式，在网上查了一番资料发现实在是太乱了，经过找资料和测试，现在来总结一下。Controller中接受request中的参数接受Date、LocalDateTime、LocalTime等参数并绑定到方法入参中常用的是下面两种方法：使用@DateTimeFormat注解这种方式比较简单，但缺点是不够灵活。1234567//1.只能将Get请求中格式为yyyy-MM-dd HH:mm:ss的date参数的值绑定到方法的date参数,接受其他类型的请求可以将GetMapping改为RequestMapping//2.参数类型可以是Date或者jdk8中新的时间类型，如：@DateTimeFormat(pattern = \"yyyy-MM-dd\") LocalDate date@GetMapping(\"/date\")public LocalDateTime getDate(@DateTimeFormat(pattern = \"yyyy-MM-dd HH:mm:ss\") LocalDateTime date) &#123; System.out.println(date); return date;&#125;自定义转换器Converter实现Converter接口，自定义转换规则，比较灵活。Controller中接受requestBody中的参数（反序列化）和序列化为json时的格式@JsonFormat注解配合@JsonDeserialize或@JsonSerialize使用123456789101112@Datapublic class TestVO &#123; private String msg; //使用JsonFormat注解指定序列化和反序列化的格式 //使用JsonDeserialize和JsonSerialize指定使用的序列化器 //jackson-datatype-jsr310包下是常用的反序列化器和序列化器，spring-boot-starter-json包已经包含该jsr310扩展包 @JsonFormat(pattern = \"yyyy-MM-dd HH:mm:ss\") @JsonDeserialize(using = LocalDateTimeDeserializer.class) @JsonSerialize(using = LocalDateTimeSerializer.class) private LocalDateTime localDateTime; &#125;配置ObjectMapper12345678910111213141516@Bean@Primarypublic ObjectMapper objectMapper() &#123; ObjectMapper objectMapper = new ObjectMapper(); JavaTimeModule javaTimeModule = new JavaTimeModule(); javaTimeModule.addSerializer(LocalDateTime.class, new LocalDateTimeSerializer(DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\"))); javaTimeModule.addSerializer(LocalDate.class, new LocalDateSerializer(DateTimeFormatter.ofPattern(\"yyyy-MM-dd\"))); javaTimeModule.addSerializer(LocalTime.class, new LocalTimeSerializer(DateTimeFormatter.ofPattern(\"HH:mm:ss\"))); javaTimeModule.addDeserializer(LocalDateTime.class, new LocalDateTimeDeserializer(DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\"))); javaTimeModule.addDeserializer(LocalDate.class, new LocalDateDeserializer(DateTimeFormatter.ofPattern(\"yyyy-MM-dd\"))); javaTimeModule.addDeserializer(LocalTime.class, new LocalTimeDeserializer(DateTimeFormatter.ofPattern(\"HH:mm:ss\"))); objectMapper.registerModule(javaTimeModule); return objectMapper;&#125;","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://lolico.me/tags/Spring/"},{"name":"Java","slug":"Java","permalink":"https://lolico.me/tags/Java/"},{"name":"Web","slug":"Web","permalink":"https://lolico.me/tags/Web/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://lolico.me/tags/SpringBoot/"}]},{"title":"再谈SpringDataJPA","slug":"再谈SpringDataJPA","date":"2019-12-27T10:21:08.000Z","updated":"2022-05-02T03:45:10.810Z","comments":true,"path":"2019/12/27/再谈SpringDataJPA/","link":"","permalink":"https://lolico.me/2019/12/27/%E5%86%8D%E8%B0%88SpringDataJPA/","excerpt":"","text":"前言在 关于SpringBoot使用JPA进行更新操作 这一篇文章中曾提到了关于jpa使用save方法更新记录时会出现当有些参数为null时，save操作会用null覆盖数据库中的字段的情况，通常我们的需求是动态的去更新记录，而不是全部覆盖，所以对比起Mybatis的动态sql，Jpa不太灵活的特性就暴露出来，事实上，对于动态更新虽然实现上麻烦了点，但还是能操作一下的。以前的方法对于以前实现动态更新，我们无非是使用@Query注解来写原生sql,就像这样：123456789@Transactional@Modifying@Query(\"update User u set u.email=:#&#123;#user.email&#125; where u.id=:#&#123;#user.id&#125;\")void dynamicUpdateEmailById(@Param(\"user\") User user);@Transactional@Modifying@Query(\"update User u set u.email=?2 where u.id=?1\")void dynamicUpdateEmailById(int id, String email);但往往我们每张表都会有动态更新的需求，按照这样的方法，都写一遍原生sql实在是又麻烦又易错，而且这种方法实际上并没有真正做到动态，而是我们自己把需要更新的部分写死了，当我们需要更新其他字段岂不是又要再写一个方法？总之，很是麻烦。动态sql新姿势假设现在有好几张表：user、rank …，对于所有的有动态更新需求的表都要进行实现的话，那么我们可以这样做：先定义一个BaseRepository123456@NoRepositoryBeanpublic interface BaseRepository&lt;T, ID extends Serializable&gt; extends JpaRepository&lt;T, ID&gt;, JpaSpecificationExecutor&lt;T&gt; &#123; T dynamicUpdate(T entity); &#125;然后定义一个BaseRepositoryImpl作为BaseRepository的默认实现1234567891011121314public class BaseRepositoryImpl&lt;T, ID extends Serializable&gt; extends SimpleJpaRepository&lt;T, ID&gt; implements BaseRepository&lt;T, ID&gt; &#123; private Class&lt;T&gt; entityClass; private EntityManager entityManager; private JpaEntityInformation&lt;T, ?&gt; entityInformation; public BaseRepositoryImpl(JpaEntityInformation&lt;T, ?&gt; entityInformation, EntityManager entityManager) &#123; super(entityInformation, entityManager); this.entityClass = entityInformation.getJavaType(); this.entityManager = entityManager; this.entityInformation = entityInformation; &#125; &#125;然后在配置类上加上注解@EnableJpaRepositories(repositoryBaseClass = BaseRepositoryImpl.class)，看到这里，应该有朋友会感觉有点熟悉。这正是我们为所有Repository自定义公共方法的实现方法，我们在BaseRepository中定义共有方法，然后在BaseRepositoryImpl中提供实现，后续所有继承BaseRepository这个接口的Repository都可以获得这个默认实现，因为我们在注解@EnableJpaRepositories(repositoryBaseClass = BaseRepositoryImpl.class)中指定了Repository的默认实现用BaseRepositoryImpl，而BaseRepositoryImpl继承SimpleJpaRepository这个jpa默认的实现，所以我们相当于扩展JpaRepository，好的，扯远…所以现在我们只要在BaseRepository中定义T dynamicUpdate(T t);这样一个方法,然后在BaseRepositoryImpl中提供实现，那么所有repository都可以获得这个实现，所以，说到最后，怎么实现这样一个方法呢？12345678910111213141516171819202122232425262728293031@Transactional(readOnly = true)public class BaseRepositoryImpl&lt;T, ID extends Serializable&gt; extends SimpleJpaRepository&lt;T, ID&gt; implements BaseRepository&lt;T, ID&gt; &#123; private Class&lt;T&gt; entityClass; private EntityManager entityManager; private JpaEntityInformation&lt;T, ?&gt; entityInformation; public BaseRepositoryImpl(JpaEntityInformation&lt;T, ?&gt; entityInformation, EntityManager entityManager) &#123; super(entityInformation, entityManager); this.entityClass = entityInformation.getJavaType(); this.entityManager = entityManager; this.entityInformation = entityInformation; &#125; @Override @Transactional public T dynamicUpdate(T entity) &#123; BeanWrapper wrapper = new BeanWrapperImpl(entity); Object id = entityInformation.getRequiredId(entity); //获取id的值 T old = entityManager.find(entityClass, id); //先根据id从数据库中查出记录 Set&lt;String&gt; nullProperty = new HashSet&lt;&gt;(); //存放为null的属性名 for (PropertyDescriptor propertyDescriptor : wrapper.getPropertyDescriptors()) &#123; String propertyName = propertyDescriptor.getName(); //属性名 Object propertyValue = wrapper.getPropertyValue(propertyName); //属性值 if (propertyValue == null) &#123; //如果属性值为null就添加到set中 nullProperty.add(propertyName); &#125; &#125; BeanUtils.copyProperties(entity, old, nullProperty.toArray(new String[0])); //将t中属性的值复制到old中，忽略nullProperty.toArray(new String[0])中的属性 return entityManager.merge(old); //更新并返回更新后的结果 &#125;&#125;思路注释里已经写得很清楚了。对于BeanWrapperImpl和BeanUtils这两个类，都是利用反射去获取Bean的各种信息以及进行操作的类。前者是Bean的包装类，后者是Bean工具类,两者有什么区别呢？看类名也能猜出来，前者包装bean后可以获得这个bean的一些信息，比如有那些属性，属性的值是什么，值可不可以修改，能不能读取等等（侧重于对传进去的bean对象进行操作）。后者提供了一些静态方法，用于实例化bean,检查bean的属性类型，复制属性值等（侧重于对类的信息和bean之间属性进行操作）。测试User.java12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576@Entity@Table(name = \"user\")@DynamicUpdatepublic class User &#123; private int id; private String username; private String password; private String email; @Id @Column(name = \"id\") @GeneratedValue(strategy = GenerationType.IDENTITY) public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; @Basic @Column(name = \"uname\") public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; @Basic @Column(name = \"upassword\") public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125; @Basic @Column(name = \"uemail\") public String getEmail() &#123; return email; &#125; public void setEmail(String email) &#123; this.email = email; &#125; @Override public boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; User that = (User) o; return id == that.id &amp;&amp; Objects.equals(username, that.username) &amp;&amp; Objects.equals(password, that.password) &amp;&amp; Objects.equals(email, that.email); &#125; @Override public int hashCode() &#123; return Objects.hash(id, username, password, email); &#125; @Override public String toString() &#123; return \"User&#123;\" + \"id=\" + id + \", username='\" + username + '\\'' + \", password='\" + password + '\\'' + \", email='\" + email + '\\'' + '&#125;'; &#125;&#125;UserRepository.java1234@Repositorypublic interface UserRepository extends CustomUserRepository, BaseRepository&lt;User, Integer&gt; &#123; &#125;测试方法：12345678@Testvoid dynamicUpdate() &#123; User user = new User(); user.setId(3); user.setUsername(\"test3\"); user = repository.dynamicUpdate(user); System.out.println(user);&#125;对数据库表中id为3的记录进行更新，将username设置为test3,原本的记录是3&emsp;&emsp;test&emsp;&emsp;test3&emsp;&emsp;test3@ttt执行方法，输出：结果两条sql,先查询再更新，更新的sql中可以看到只对uname进行set，这是因为我们在User实体类上注解了@DynamicUpdate注意这个注解并不是动态更新记录的意思，这个注解的意思是在进行merge更新时，会对比数据库中的记录，如果不一致就生成对应set的语句，所以可以看到我们测试输出的更新sql语句里只有对uname进行set的sql，因为其他字段的值与数据库记录是一致的，利用这个注解我们可以实现对于数据库中设置默认值比如DateTime，在使用@DynamicInsert后就不会插入null值，而是使用默认的值。讲的有点乱，还没理解的可以去看看这篇文章关于@DynamicUpdate的误解现在看下数据库中id=3的记录是否更新了uname：更新后的记录与输出的一致，很完美！总结对于动态sql，利用这个方法或许性能不太行（因为先查询了一下），但可行性上来说还是可以的，既然想体验Spring Data JPA自动生成实现的功能，自然就很难再保证Mybatis那种灵活的特性。","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://lolico.me/tags/Spring/"},{"name":"Java","slug":"Java","permalink":"https://lolico.me/tags/Java/"},{"name":"JPA","slug":"JPA","permalink":"https://lolico.me/tags/JPA/"}]},{"title":"SpringBoot 拦截器，过滤器，转换器，消息转换器的注册","slug":"SpringBoot-拦截器-过滤器-转换器-消息转换器的注册","date":"2019-12-26T10:16:57.000Z","updated":"2022-05-02T03:45:10.806Z","comments":true,"path":"2019/12/26/SpringBoot-拦截器-过滤器-转换器-消息转换器的注册/","link":"","permalink":"https://lolico.me/2019/12/26/SpringBoot-%E6%8B%A6%E6%88%AA%E5%99%A8-%E8%BF%87%E6%BB%A4%E5%99%A8-%E8%BD%AC%E6%8D%A2%E5%99%A8-%E6%B6%88%E6%81%AF%E8%BD%AC%E6%8D%A2%E5%99%A8%E7%9A%84%E6%B3%A8%E5%86%8C/","excerpt":"","text":"环境：SpringBoot 2.2.2拦截器方式一：写一个配置类，实现WebMvcConfigurer接口并实现addInterceptors方法过滤器方式一：使用@Component或@Bean配合进行注册方式二：当使用嵌入式web服务器时使用@ServletComponentScan配置扫描，同时可以用来注册filter、servlet和linstener转换器方式一：使用@Component或@Bean注册方式二：写一个配置类，实现WebMvcConfigurer接口并实现addFormatters方法消息转换器方式一：使用@Component或@Bean注册方式二：写一个配置类，实现WebMvcConfigurer接口并实现configureMessageConverters方法方式三：写一个配置类，实现WebMvcConfigurer接口并实现extendMessageConverters方法总结得益于SpringBoot的自动配置，通常我们只需要通过注册Bean这样简单的方式就可以向容器中的组件注入配置。","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://lolico.me/tags/Spring/"},{"name":"Java","slug":"Java","permalink":"https://lolico.me/tags/Java/"},{"name":"Web","slug":"Web","permalink":"https://lolico.me/tags/Web/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://lolico.me/tags/SpringBoot/"}]},{"title":"SpringBoot自动配置原理","slug":"SpringBoot自动配置原理","date":"2019-12-19T10:06:00.000Z","updated":"2022-05-02T03:45:10.806Z","comments":true,"path":"2019/12/19/SpringBoot自动配置原理/","link":"","permalink":"https://lolico.me/2019/12/19/SpringBoot%E8%87%AA%E5%8A%A8%E9%85%8D%E7%BD%AE%E5%8E%9F%E7%90%86/","excerpt":"","text":"前言不论在工作中，亦或是求职面试，Spring Boot已经成为我们必知必会的技能项。除了某些老旧的政府项目或金融项目持有观望态度外，如今的各行各业都在飞速的拥抱这个已经不是很新的Spring启动框架。当然，作为Spring Boot的精髓，自动配置原理的工作过程往往只有在“面试”的时候才能用得上，但是如果在工作中你能够深入的理解Spring Boot的自动配置原理，将无往不利。Spring Boot的出现，得益于“约定大于配置”的理念，没有繁琐的配置、难以集成的内容（大多数流行第三方技术都被集成），这是基于Spring 4.x提供的按条件配置Bean的能力。Spring Boot的配置文件初识Spring Boot时我们就知道，Spring Boot有一个全局配置文件：application.properties或application.yml我们的各种属性都可以在这个文件中进行配置，最常配置的比如：server.port、logging.level.* 等等，然而我们实际用到的往往只是很少的一部分，那么这些属性是否有据可依呢？答案当然是肯定的，这些属性都可以在官方文档中查找到：common-application-properties（所以，话又说回来，找资料还得是官方文档，百度出来一大堆，还是稍显业余了一些）除了官方文档为我们提供了大量的属性解释，我们也可以使用IDE的相关提示功能，比如IDEA的自动提示。以上，是Spring Boot的配置文件的大致使用方法，其实都是些题外话。那么问题来了：这些配置是如何在Spring Boot项目中生效的呢？接下来，就需要聚焦本篇博客的主题：自动配置工作原理或者叫实现方式。工作原理剖析Spring Boot关于自动配置的源码在spring-boot-autoconfigure-x.x.x.x.jar中：当然，自动配置原理的相关描述，官方文档貌似是没有提及。不过我们不难猜出，Spring Boot的启动类上有一个@SpringBootApplication注解，这个注解是Spring Boot项目必不可少的注解。那么自动配置原理一定和这个注解有着千丝万缕的联系！@EnableAutoConfiguration@SpringBootApplication是一个复合注解或派生注解，在@SpringBootApplication中有一个注解@EnableAutoConfiguration，翻译成人话就是开启自动配置，其定义如下：而这个注解也是一个派生注解，其中的关键功能由@Import提供，其导入的AutoConfigurationImportSelector#selectImports方法通过SpringFactoriesLoader#loadFactoryNames扫描所有具有META-INF/spring.factories的jar包。spring-boot-autoconfigure-x.x.x.x.jar里就有一个这样的spring.factories文件。这个spring.factories文件也是一组一组的key=value的形式，其中一个key是EnableAutoConfiguration类的全类名，而它的value是一个xxxAutoConfiguration的类名的列表，这些类名以逗号分隔，如下图所示：这个@EnableAutoConfiguration注解通过@SpringBootApplication被间接的标记在了Spring Boot的启动类上。在SpringApplication.run(...)的内部就会执行selectImports()方法，找到所有JavaConfig自动配置类的全限定名对应的class，然后将所有自动配置类加载到Spring容器中。自动配置生效每一个xxxAutoConfiguration自动配置类都是在某些条件之下才会生效的，这些条件的限制在Spring Boot中以注解的形式体现，常见的条件注解有如下几项：@ConditionalOnBean：当容器里有指定的bean的条件下。@ConditionalOnMissingBean：当容器里不存在指定bean的条件下。@ConditionalOnClass：当类路径下有指定类的条件下。@ConditionalOnMissingClass：当类路径下不存在指定类的条件下。@ConditionalOnProperty：指定的属性是否有指定的值，比如@ConditionalOnProperties(prefix=”xxx.xxx”, value=”enable”, matchIfMissing=true)，代表当xxx.xxx为enable时条件的布尔值为true，如果没有设置的情况下也为true。以ServletWebServerFactoryAutoConfiguration配置类为例，解释一下全局配置文件中的属性如何生效，比如：server.port=8081，是如何生效的（当然不配置也会有默认值，这个默认值来自于org.apache.catalina.startup.Tomcat）。在ServletWebServerFactoryAutoConfiguration类上，有一个@EnableConfigurationProperties注解：开启配置属性，而它后面的参数是一个ServerProperties类，这就是约定大于配置的最终落地点。在这个类上，我们看到了一个非常熟悉的注解：@ConfigurationProperties，它的作用就是从配置文件中绑定属性到对应的bean上，而@EnableConfigurationProperties负责导入这个已经绑定了属性的bean到spring容器中（见上面截图）。那么所有其他的和这个类相关的属性都可以在全局配置文件中定义，也就是说，真正“限制”我们可以在全局配置文件中配置哪些属性的类就是这些xxxProperties类，它与配置文件中定义的prefix关键字开头的一组属性是唯一对应的。至此，我们大致可以了解。在全局配置的属性如：server.port等，通过@ConfigurationProperties注解，绑定到对应的xxxProperties配置实体类上封装为一个bean，然后再通过@EnableConfigurationProperties注解导入到Spring容器中。而诸多的xxxAutoConfiguration自动配置类，就是Spring容器的JavaConfig形式，作用就是为Spring 容器导入bean，而所有导入的bean所需要的属性都通过xxxProperties的bean来获得。可能到目前为止还是有所疑惑，但面试的时候，其实远远不需要回答的这么具体，你只需要这样回答：Spring Boot启动的时候会通过@EnableAutoConfiguration注解找到META-INF/spring.factories配置文件中的所有自动配置类，并对其进行加载，而这些自动配置类都是以AutoConfiguration结尾来命名的，它实际上就是一个JavaConfig形式的Spring容器配置类，它能通过以Properties结尾命名的类中取得在全局配置文件中配置的属性如：server.port，而XxxxProperties类是通过@ConfigurationProperties注解与全局配置文件中对应的属性进行绑定的。通过一张图标来理解一下这一繁复的流程：总结综上是对自动配置原理的讲解。当然，在浏览源码的时候一定要记得不要太过拘泥与代码的实现，而是应该抓住重点脉络。一定要记得xxxProperties类的含义是：封装配置文件中相关属性；xxxAutoConfiguration类的含义是：自动配置类，目的是给容器中添加组件。而其他的主方法启动，则是为了加载这些五花八门的xxxAutoConfiguration类。","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://lolico.me/tags/Java/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://lolico.me/tags/SpringBoot/"}]},{"title":"关于使用@Configuration注解的配置类中定义BeanFactoryPostProcessor后注入Environment为null的问题","slug":"关于使用-Configuration注解的配置类中定义BeanFactoryPostProcessor后注入Environment为null的问题","date":"2019-12-17T09:42:22.000Z","updated":"2022-05-02T03:45:10.810Z","comments":true,"path":"2019/12/17/关于使用-Configuration注解的配置类中定义BeanFactoryPostProcessor后注入Environment为null的问题/","link":"","permalink":"https://lolico.me/2019/12/17/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8-Configuration%E6%B3%A8%E8%A7%A3%E7%9A%84%E9%85%8D%E7%BD%AE%E7%B1%BB%E4%B8%AD%E5%AE%9A%E4%B9%89BeanFactoryPostProcessor%E5%90%8E%E6%B3%A8%E5%85%A5Environment%E4%B8%BAnull%E7%9A%84%E9%97%AE%E9%A2%98/","excerpt":"","text":"问题由来异常：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'empDao': Unsatisfied dependency expressed through field 'jdbcTemplate'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'jdbcTemplate' defined in class path resource [me/lolico/App.class]: Unsatisfied dependency expressed through method 'jdbcTemplate' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dataSource' defined in class path resource [me/lolico/App.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [javax.sql.DataSource]: Factory method 'dataSource' threw exception; nested exception is java.lang.NullPointerException at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:643) at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:116) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1422) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:594) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:517) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:323) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:321) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:879) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:878) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:550) at org.springframework.context.support.ClassPathXmlApplicationContext.&lt;init&gt;(ClassPathXmlApplicationContext.java:144) at org.springframework.context.support.ClassPathXmlApplicationContext.&lt;init&gt;(ClassPathXmlApplicationContext.java:85) at me.lolico.AppTest.IOC(AppTest.java:24) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.junit.runner.JUnitCore.run(JUnitCore.java:137) at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68) at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:33) at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:230) at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:58)Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'jdbcTemplate' defined in class path resource [me/lolico/App.class]: Unsatisfied dependency expressed through method 'jdbcTemplate' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dataSource' defined in class path resource [me/lolico/App.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [javax.sql.DataSource]: Factory method 'dataSource' threw exception; nested exception is java.lang.NullPointerException at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:798) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:539) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1338) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1177) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:557) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:517) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:323) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:321) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1287) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1207) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:640) ... 37 moreCaused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dataSource' defined in class path resource [me/lolico/App.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [javax.sql.DataSource]: Factory method 'dataSource' threw exception; nested exception is java.lang.NullPointerException at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:656) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:484) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1338) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1177) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:557) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:517) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:323) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:321) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1287) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1207) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:885) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:789) ... 50 moreCaused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [javax.sql.DataSource]: Factory method 'dataSource' threw exception; nested exception is java.lang.NullPointerException at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185) at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:651) ... 64 moreCaused by: java.lang.NullPointerException at me.lolico.App.dataSource(App.java:30) at me.lolico.App$$EnhancerBySpringCGLIB$$5fe7f88f.CGLIB$dataSource$0(&lt;generated&gt;) at me.lolico.App$$EnhancerBySpringCGLIB$$5fe7f88f$$FastClassBySpringCGLIB$$c81ae23e.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:244) at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:363) at me.lolico.App$$EnhancerBySpringCGLIB$$5fe7f88f.dataSource(&lt;generated&gt;) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154) ... 65 more分析通过错误堆栈信息不难看出异常是在spring容器启动后实例化bean时抛出的。查看堆栈信息可以发现容器启动后：创建EmpDao-&gt;发现其依赖jdbcTemplate创建jdbcTemplate-&gt;发现其依赖dataSource创建dataSource-&gt;抛出异常堆底异常：12345678910111213Caused by: java.lang.NullPointerException at me.lolico.App.dataSource(App.java:30) at me.lolico.App$$EnhancerBySpringCGLIB$$5fe7f88f.CGLIB$dataSource$0(&lt;generated&gt;) at me.lolico.App$$EnhancerBySpringCGLIB$$5fe7f88f$$FastClassBySpringCGLIB$$c81ae23e.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:244) at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:363) at me.lolico.App$$EnhancerBySpringCGLIB$$5fe7f88f.dataSource(&lt;generated&gt;) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154) ... 65 more那么好，现在知道问题是怎么发生的，那怎么解决呢？遂去查看配置类中dataSource定义是不是有问题：123456789101112131415161718192021222324252627282930313233@PropertySource(\"classpath:jdbc.properties\")@ComponentScan(basePackageClasses = App.class)@Configurationpublic class App &#123; @Autowired private Environment env; @Bean public JdbcTemplate jdbcTemplate(DataSource dataSource) &#123; return new JdbcTemplate(dataSource); &#125; @Bean public DataSource dataSource() &#123; DriverManagerDataSource dataSource = new DriverManagerDataSource(); dataSource.setDriverClassName(Objects.requireNonNull(env.getProperty(\"mysql.driver\"))); dataSource.setUrl(env.getProperty(\"mysql.url\")); dataSource.setUsername(env.getProperty(\"mysql.username\")); dataSource.setPassword(env.getProperty(\"mysql.password\")); return dataSource; &#125; @Bean public TransactionManager transactionManager(DataSource dataSource) &#123; return new DataSourceTransactionManager(dataSource); &#125; @Bean public BeanFactoryPostProcessor beanFactoryPostProcessor() &#123; return new TestBeanFactoryPostProcessor(); &#125; &#125;没有问题，那为什么创建的dataSource为null呢？想起之前跑测试case都没错，出错前在配置类中定义了一个BeanFactoryPostProcessor,就是这个东西:1234@Beanpublic BeanFactoryPostProcessor beanFactoryPostProcessor() &#123; return new TestBeanFactoryPostProcessor();&#125;但是异常和定义的这个BeanFactoryPostProcessor扯不上关系啊，而且TestBeanFactoryPostProcessor中也没有逻辑。遂查看框架日志。找到原因所在1234567891011121314151617181920212223242019-12-17 14:20:49,658 [main] [DEBUG] - Refreshing org.springframework.context.support.ClassPathXmlApplicationContext@7e0babb12019-12-17 14:20:49,932 [main] [DEBUG] - Loaded 15 bean definitions from class path resource [applicationContext.xml]2019-12-17 14:20:49,960 [main] [DEBUG] - Creating shared instance of singleton bean &#39;org.springframework.context.annotation.internalConfigurationAnnotationProcessor&#39;2019-12-17 14:20:50,103 [main] [DEBUG] - Identified candidate component class: file [D:\\ws_idea\\springmvc\\target\\classes\\me\\lolico\\dao\\EmpDao.class]2019-12-17 14:20:50,228 [main] [DEBUG] - Creating shared instance of singleton bean &#39;org.springframework.context.event.internalEventListenerProcessor&#39;2019-12-17 14:20:50,230 [main] [DEBUG] - Creating shared instance of singleton bean &#39;beanFactoryPostProcessor&#39;2019-12-17 14:20:50,231 [main] [DEBUG] - Creating shared instance of singleton bean &#39;me.lolico.App#0&#39;2019-12-17 14:20:50,234 [main] [INFO] - @Bean method App.beanFactoryPostProcessor is non-static and returns an object assignable to Spring&#39;s BeanFactoryPostProcessor interface. This will result in a failure to process annotations such as @Autowired, @Resource and @PostConstruct within the method&#39;s declaring @Configuration class. Add the &#39;static&#39; modifier to this method to avoid these container lifecycle issues; see @Bean javadoc for complete details.2019-12-17 14:20:50,248 [main] [DEBUG] - Creating shared instance of singleton bean &#39;org.springframework.context.event.internalEventListenerFactory&#39;2019-12-17 14:20:50,249 [main] [DEBUG] - Creating shared instance of singleton bean &#39;org.springframework.context.annotation.internalAutowiredAnnotationProcessor&#39;2019-12-17 14:20:50,251 [main] [DEBUG] - Creating shared instance of singleton bean &#39;org.springframework.context.annotation.internalCommonAnnotationProcessor&#39;2019-12-17 14:20:50,254 [main] [DEBUG] - Creating shared instance of singleton bean &#39;org.springframework.context.annotation.internalPersistenceAnnotationProcessor&#39;2019-12-17 14:20:50,262 [main] [DEBUG] - Creating shared instance of singleton bean &#39;org.springframework.web.servlet.resource.DefaultServletHttpRequestHandler#0&#39;2019-12-17 14:20:50,268 [main] [DEBUG] - Creating shared instance of singleton bean &#39;org.springframework.web.servlet.handler.SimpleUrlHandlerMapping#0&#39;2019-12-17 14:20:50,330 [main] [DEBUG] - Patterns [&#x2F;**] in &#39;org.springframework.web.servlet.handler.SimpleUrlHandlerMapping#0&#39;2019-12-17 14:20:50,330 [main] [DEBUG] - Creating shared instance of singleton bean &#39;mvcCorsConfigurations&#39;2019-12-17 14:20:50,331 [main] [DEBUG] - Creating shared instance of singleton bean &#39;org.springframework.web.servlet.handler.BeanNameUrlHandlerMapping&#39;2019-12-17 14:20:50,337 [main] [DEBUG] - Creating shared instance of singleton bean &#39;org.springframework.web.servlet.mvc.HttpRequestHandlerAdapter&#39;2019-12-17 14:20:50,338 [main] [DEBUG] - Creating shared instance of singleton bean &#39;org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter&#39;2019-12-17 14:20:50,339 [main] [DEBUG] - Creating shared instance of singleton bean &#39;org.springframework.web.servlet.view.InternalResourceViewResolver#0&#39;2019-12-17 14:20:50,366 [main] [DEBUG] - Creating shared instance of singleton bean &#39;empDao&#39;2019-12-17 14:20:50,378 [main] [DEBUG] - Creating shared instance of singleton bean &#39;jdbcTemplate&#39;2019-12-17 14:20:50,383 [main] [DEBUG] - Creating shared instance of singleton bean &#39;dataSource&#39;2019-12-17 14:20:50,386 [main] [WARN] - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name &#39;empDao&#39;: Unsatisfied dependency expressed through field &#39;jdbcTemplate&#39;; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name &#39;jdbcTemplate&#39; defined in class path resource [me&#x2F;lolico&#x2F;App.class]: Unsatisfied dependency expressed through method &#39;jdbcTemplate&#39; parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name &#39;dataSource&#39; defined in class path resource [me&#x2F;lolico&#x2F;App.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [javax.sql.DataSource]: Factory method &#39;dataSource&#39; threw exception; nested exception is java.lang.NullPointerException注意第六条日志记录及以后几条记录：1232019-12-17 14:20:50,230 [main] [DEBUG] - Creating shared instance of singleton bean &#39;beanFactoryPostProcessor&#39;2019-12-17 14:20:50,231 [main] [DEBUG] - Creating shared instance of singleton bean &#39;me.lolico.App#0&#39;2019-12-17 14:20:50,234 [main] [INFO] - @Bean method App.beanFactoryPostProcessor is non-static and returns an object assignable to Spring&#39;s BeanFactoryPostProcessor interface. This will result in a failure to process annotations such as @Autowired, @Resource and @PostConstruct within the method&#39;s declaring @Configuration class. Add the &#39;static&#39; modifier to this method to avoid these container lifecycle issues; see @Bean javadoc for complete details.Spring容器启动：创建’beanFactoryPostProcessor’Bean，再创建’me.lolico.App#0’Bean。因为beanFactoryPostProcessor定义在App这个配置类中即依赖于’me.lolico.App#0’Bean，那么Spring容器创建’beanFactoryPostProcessor’Bean导致提前实例化’me.lolico.App#0’Bean，而此时Spring容器处于还未实例化所有Bean（只是加载了BeanDefinition）的生命周期，那么在创建’me.lolico.App#0’Bean的时候自然不会去注入Environment属性，只是先实例化出来并未注入属性，参考Spring实例化Bean的三级缓存机制（提前暴露Bean以解决循环依赖的问题)。所以env为null，而后续实例化’dataSource’Bean，使用为null的env去get属性值当然就空指针异常了。事实上，通过断点调试也验证了这个结论:断点调试而且仔细观察日志，Spring也告诉了我们这一点:2019-12-17 14:20:50,234 [main] [INFO] - @Bean method App.beanFactoryPostProcessor is non-static and returns an object assignable to Spring’s BeanFactoryPostProcessor interface. This will result in a failure to process annotations such as @Autowired, @Resource and @PostConstruct within the method’s declaring @Configuration class. Add the ‘static’ modifier to this method to avoid these container lifecycle issues; see @Bean javadoc for complete details.@Bean方法App.beanFactoryPostProcessor是非静态的，并返回可分配给Spring的BeanFactoryPostProcessor接口的对象。这将导致无法在方法的声明@Configuration类中处理诸如@ Autowired，@ Resource和@PostConstruct之类的注释。在此方法中添加“静态”修饰符可避免这些容器生命周期问题；有关完整的详细信息，请参见@Bean javadoc。解决第一想到的是：既然创建’me.lolico.App#0’Bean的时候不会注入env属性，那么改为构造器强制注入,应该就可以了吧：123public App(Environment env) &#123; this.env = env;&#125;事实上是不行的：java.lang.NoSuchMethodException: me.lolico.App$$EnhancerBySpringCGLIB$$e5ab47a1.&lt;init&gt;()spring在使用cglib动态代理生成App实例的时候调用默认的无参构造器。但cglib现在也并不要求代理类一定要有默认无参构造器了，可能是Spring底层实现的原因？所以真正的解决办法App配置类实现EnvironmentAware接口Spring会通过回调接口传入一个Environment对象12345678910public class App implements EnvironmentAware &#123; private Environment env; ...... @Override public void setEnvironment(Environment environment) &#123; this.env = environment; &#125;&#125;将BeanFactoryPostProcessor定义的方法改为静态方法Spring可以通过类名.方法名调用获取BeanFactoryPostProcessor的静态方法。将BeanFactoryPostProcessor定义在其他配置类中或者定义在xml配置文件中原因不解释~小结通过分析这个问题，还能得出一些信息：将BeanFactoryPostProcessor定义在配置类中并且并不以静态方法定义的话，会导致配置类提前实例化（BeanFactoryPostProcessor在Spring生命周期中创建的很早，要早于BeanPostProcessor和Bean参考AbstractApplicationContext#refresh)，从而出现一些生命周期的问题，如果不了解，真的很难发现。可能你这样定义没有问题，那原因之一可能是因为你的这个配置类中没有用到类似Environment这种需要注入进来的属性。参考：^ BeanFactoryPostProcessor and @Bean problems #4711","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://lolico.me/tags/Spring/"},{"name":"Java","slug":"Java","permalink":"https://lolico.me/tags/Java/"}]},{"title":"Spring Data Jpa模糊查询","slug":"SpringDataJPA模糊查询","date":"2019-11-15T09:24:39.000Z","updated":"2022-05-02T03:45:10.806Z","comments":true,"path":"2019/11/15/SpringDataJPA模糊查询/","link":"","permalink":"https://lolico.me/2019/11/15/SpringDataJPA%E6%A8%A1%E7%B3%8A%E6%9F%A5%E8%AF%A2/","excerpt":"","text":"实体类User.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475@Entity@Table(name = \"user\")public class User &#123; private int id; private String username; private String password; private String email; @Id @Column(name = \"id\") @GeneratedValue(strategy = GenerationType.IDENTITY) public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; @Basic @Column(name = \"uname\") public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; @Basic @Column(name = \"upassword\") public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125; @Basic @Column(name = \"uemail\") public String getEmail() &#123; return email; &#125; public void setEmail(String email) &#123; this.email = email; &#125; @Override public boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; User that = (User) o; return id == that.id &amp;&amp; Objects.equals(username, that.username) &amp;&amp; Objects.equals(password, that.password) &amp;&amp; Objects.equals(email, that.email); &#125; @Override public int hashCode() &#123; return Objects.hash(id, username, password, email); &#125; @Override public String toString() &#123; return \"User&#123;\" + \"id=\" + id + \", username='\" + username + '\\'' + \", password='\" + password + '\\'' + \", email='\" + email + '\\'' + '&#125;'; &#125;&#125;不依赖数据库的实现方法自定义查询语句（concat函数）mysql:concat:用于将多个字符串连接成一个字符串，是最重要的mysql函数之一。1234@Query(\"select u from User u \" + \" where (u.username like concat('%',?1,'%') or ?1 is null) \" + \" and u.email=?2 \")List&lt;User&gt; findByUsernameLikeAndEmail(String username, String email);1234@Testvoid findByUsernameLikeAndEmail() &#123; System.out.println(repository.findByUsernameLikeAndEmail(\"test\", \"test3@ttt\"));&#125;输出：[User{id=3, username=’test3’, password=’test3’, email=’test3@ttt’}, User{id=5, username=’test3’, password=’test3’, email=’test3@ttt’}, User{id=6, username=’test3’, password=’test3’, email=’test3@ttt’}, User{id=7, username=’test3’, password=’test3’, email=’test3@ttt’}]自定义查询语句1234@Query(\"select u from User u \" + \" where (u.username like ?1 or ?1 is null) \" + \" and u.email=?2\")List&lt;User&gt; findByUsernameLikeAndEmail(String username, String email);1234@Testvoid findByUsernameLikeAndEmail() &#123; System.out.println(repository.findByUsernameLikeAndEmail(\"%test%\", \"test3@ttt\"));&#125;输出：同方式一注意：效果同方式一，调用传参的不同，相比方式一要自己传入包含模式的匹配字符串：”te_t%”、”test%”等.方式一和方式二调用：repository.findByUsernameLikeAndEmail(null, &quot;test8@ttt&quot;)输出：[User{id=8, username=’null’, password=’8’, email=’test8@ttt’}]u.username like %?1% or ?1 is null和u.username like concat(&#39;%&#39;,?1,&#39;%&#39;) or ?1 is null代表不存在则忽略模糊查询条件，存在则进行模糊查询。jpa自动提供实现的方式1List&lt;User&gt; findByUsernameLikeAndEmail(String username,String email);1234@Testvoid findByUsernameLikeAndEmail() &#123; System.out.println(repository.findByUsernameLikeAndEmail(\"%test%\", \"test3@ttt\"));&#125;输出：同方式一1234@Testvoid findByUsernameLikeAndEmail() &#123; System.out.println(repository.findByUsernameLikeAndEmail(null, \"test8@ttt\"));&#125;由于jpa自动提供实现，没有or ?1 is null逻辑，传参null进行调用抛出异常：异常：org.springframework.dao.InvalidDataAccessApiUsageException: Value must not be null!; nested exception is java.lang.IllegalArgumentException: Value must not be null!利用不同数据库中提供的函数的实现方法mysql:containsMYSQL中可以用CONTAINS函数,在全文索引的的字段中使用：123456@Query(value = \" select * from event e \" + \" where (?1 is null or CONTAINS(e.event_title,'?1')) \" + \" and (to_days(e.register_time)=to_days(?2) or ?2 is null) \" + \" and e.status = '1' \" + \" order by e.register_time desc limit ?3,?4 \",nativeQuery = true) List&lt;Event&gt; findAllList(String eventTitle,Timestamp registerTime,Integer pageNumber,Integer pageSize);还可以用 find_in_set() 方法,例如:select * FROM users WHERE find_in_set(&#39;aa@email.com&#39;, emails);oracle:instrOracle中提供了 instr(strSource,strTarget)函数，比使用 LIKE %关键字% 的模式效率高很多。instr函数也有三种情况：instr条件相当于like什么instr(字段,‘关键字’)&gt;0字段like ‘%关键字%’instr(字段,‘关键字’)=1字段like ‘关键字%’instr(字段,‘关键字’)=0字段not like ‘%关键字%’pgsql:~~用法~ 表示匹配正则表达式，且区分大小写。~* 表示匹配正则表达式，且不区分大小写。可以通过这两个操作符来实现like和ilike一样的效果,^和$就是正则表达式里的用法，如下：匹配以“张”开头的字符串 : select * from table where name ~ ‘^张’;匹配以“小”结尾的字符串 : select * from table where name ~ ‘小$’;!~是~的否定用法，表示不匹配正则表达式，且区分大小写。!~*是~*的否定用法，表示不匹配正则表达式，且不区分大小写。~~等效于like，~~*等效于ilike。!~~等效于not like，!~~*等效于not ilike。","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://lolico.me/tags/Spring/"},{"name":"Java","slug":"Java","permalink":"https://lolico.me/tags/Java/"},{"name":"JPA","slug":"JPA","permalink":"https://lolico.me/tags/JPA/"}]},{"title":"关于SpringBoot使用JPA进行更新操作","slug":"关于SpringBoot使用JPA进行更新操作","date":"2019-11-14T09:08:44.000Z","updated":"2022-05-02T03:45:10.810Z","comments":true,"path":"2019/11/14/关于SpringBoot使用JPA进行更新操作/","link":"","permalink":"https://lolico.me/2019/11/14/%E5%85%B3%E4%BA%8ESpringBoot%E4%BD%BF%E7%94%A8JPA%E8%BF%9B%E8%A1%8C%E6%9B%B4%E6%96%B0%E6%93%8D%E4%BD%9C/","excerpt":"","text":"使用SimpleJpaRepository#save（JpaRepository的默认实现，更新操作本质上是调用EntityManager#merge方法）进行更新操作时会发现：在传入的对象只有部分参数时，更新后数据库中该记录的其他字段为null解决：123456789@Transactional@Modifying@Query(\"update User u set u.email=:#&#123;#user.email&#125; where u.id=:#&#123;#user.id&#125;\")void dynamicUpdateEmailById(@Param(\"user\") User user);@Transactional@Modifying@Query(\"update User u set u.email=?2 where u.id=?1\")void dynamicUpdateEmailById(int id, String email);对于调用SimpJpaReposiory#sava插入新纪录后get不到id(主键)的问题添加@GeneratedValue注解修改主键生成策略为GenerationType.IDENTITY，默认是GenerationType.AUTO异常：org.springframework.dao.DataIntegrityViolationException: could not execute statement; SQL [n/a]; constraint [PRIMARY]; nested exception is org.hibernate.exception.ConstraintViolationException: could not execute statement解决：使用GenerationType.IDENTITY12345678910111213141516@Entity@Table(name = \"user\")public class User &#123; private int id; private String username; private String password; private String email; @Id @Column(name = \"id\") @GeneratedValue(strategy = GenerationType.IDENTITY) public int getId() &#123; return id; &#125; ...&#125;或12345678910111213141516@Entity@Table(name = \"user\")public class User &#123; @Id @Column(name = \"id\") @GeneratedValue(strategy = GenerationType.IDENTITY) private int id; private String username; private String password; private String email; public int getId() &#123; return id; &#125; ...&#125;注意：测试将@GeneratedValue(strategy = GenerationType.IDENTITY)标注在属性（@Id、@Column等还是标注于getter方法)时不生效，原因可能是PPB在解析属性和表字段映射时要么从getter方法进行解析绑定，要么从属性解析绑定，而不是解析属性和对应getter方法进行合并。","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://lolico.me/tags/Spring/"},{"name":"Java","slug":"Java","permalink":"https://lolico.me/tags/Java/"},{"name":"JPA","slug":"JPA","permalink":"https://lolico.me/tags/JPA/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://lolico.me/tags/SpringBoot/"}]},{"title":"EntityManagerFactory和EntityManager","slug":"EntityManagerFactory和EntityManager","date":"2019-11-12T08:53:19.000Z","updated":"2022-05-02T03:45:10.806Z","comments":true,"path":"2019/11/12/EntityManagerFactory和EntityManager/","link":"","permalink":"https://lolico.me/2019/11/12/EntityManagerFactory%E5%92%8CEntityManager/","excerpt":"","text":"常见异常及可能的解决办法javax.persistence.TransactionRequiredException: no transaction is in progress可能的原因：没有开启事务开启事务没有生效@Transactional注解是作用于EntityManager的操作的层级上EntityManagerFactory#createEntityManager生成的EntityManager对于写操作手动管理事务（开启-操作-提交）时，需要注意的是：对于一个操作中的所有子操作要在一个事务中完成java.lang.IllegalStateException: Transaction not successfully startedEntityManagerFactory#createEntityManager每次都会返回一个新的实例，所以通过EntityManagerFactory.createEntityManager().getTransaction()[.begin()|.commit()]开启和提交事务是不行的，例如：12345public void insertOne(User user) &#123; emf.createEntityManager().getTransaction().begin(); emf.createEntityManager().persist(user); emf.createEntityManager().getTransaction().commit();&#125;正确方式：123456public void insertOne(User user) &#123; EntityManager entityManager = emf.createEntityManager(); entityManager.getTransaction().begin(); entityManager.persist(user); entityManager.getTransaction().commit();&#125;org.springframework.dao.InvalidDataAccessApiUsageException: Removing a detached instance;nested exception is java.lang.IllegalArgumentException: Removing a detached instance123456789public void deleteById(int id) &#123; EntityManager entityManager = emf.createEntityManager(); entityManager.getTransaction().begin(); entityManager.remove(getById(id)); entityManager.getTransaction().commit();&#125;public User getById(int id) &#123; return emf.createEntityManager().find(User.class, id);&#125;可能的原因：注意getById(int id)中的内容，EntityManagerFactory#createEntityManager()`每次返回一个新的实例，即在一个事务中操作两个不同的entityManager。通常：在删除一个游离状态的实体时也会报这个异常。对于实体不同状态下的操作见：JPA EntityManager的四个主要方法 ——persist,merge,refresh和remove正确方式：123456public void deleteById(int id) &#123; EntityManager entityManager = emf.createEntityManager(); entityManager.getTransaction().begin(); entityManager.remove(entityManager.find(User.class,id)); entityManager.getTransaction().commit();&#125;java.lang.IllegalArgumentException: attempt to create delete event with null entity删除的实体不存在，检查需要删除的记录是否不存在于数据库的表中。SimpleJpaRepository#saveAndFlush和SimpleJpaRepository#save方法save方法在没有主键时调用EntityManager.persist方法执行插入操作。在有主键时调用EntityManager.merge方法执行更新操作。saveAndFlush方法调用save方法后调用flush方法，将PersistenceContext的信息刷新到数据库中，当触发flush这个动作的时候，所有的实体都将会被insert/update/remove到数据库中，数据库不会触发Commit的操作。源码123456789101112131415161718192021@Transactional@Overridepublic &lt;S extends T&gt; S save(S entity) &#123; if (entityInformation.isNew(entity)) &#123; em.persist(entity); return entity; &#125; else &#123; return em.merge(entity); &#125;&#125;@Transactional@Overridepublic &lt;S extends T&gt; S saveAndFlush(S entity) &#123; S result = save(entity); flush(); return result;&#125;EntityManager#merge和EntityManager#persist方法persist(),是保存，跟save（）方法一样，知识jpa官方说叫persist比较好一些，更接近持久化的含义。而merge（）是合并的意思，就是当你保存的实体，根据主键id划分，如果已存在，那么就是更新操作，如果不存在，就是新增操作。persist会把传进去的实体放到持久化上下文中，此时如果持久化上下文中有了这个实体，就会抛出javax.persistence.EntityExistsException，没有的话事务提交的时候把那个对象加进数据库中，如果数据库中已经存在了那个对象（那一行），就会抛出com.mysql.jdbc.exceptions.jdbc4.MySQLIntegrityConstraintViolationException；而merge会在持久化上下文中生成传进去的实体的受管版本，如果已经有了受管版本，那也不会抛出异常，然后把那个受管的实体返回出来，事务提交的时候如果数据库中不存在那个对象（那一行），就把把那个受管的加进去，存在的话就替换掉原来的数据。merge是如果持久化上下文中有了受管版本，那就更新，没有就复制一份，返回受管的。再次总结persist（①，②-③，④-⑤）： （这里说的抛出的异常都是指对象（或者数据库中的行）重复的异常） ①如果persist的是一个受管实体（即已经在上下文中），就不会抛出异常。②如果persist的是一个游离实体（即上下文中没有它），而上下文中又没有它的受管版本，数据库中也没有，也不会抛出异常，而会把这个实体写进数据库中。③如果persist的是一个游离实体（即上下文中没有），而上下文中又没有它的受管版本，数据库却有这个实体，那么EntityManager在persist它的时候不会抛出异常，但是事务提交的时候就会抛出异常：Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLIntegrityConstraintViolationException: Duplicate entry ‘7’ for key 1；④如果persist的是一个游离实体（即上下文中没有），而上下文中却有它的受管版本，数据库中又没有这个实体，那么还是不会抛出异常，而是把它的受管版本加进去（不是那个游离的，是那个受管的！）（即，这种情况persist和没persist是一样的！）。 ⑤如果persist的是一个游离实体（即上下文中没有），而上下文中却有它的受管版本，数据库中也有了这个实体，那么EntityManager在persist它的时候就会抛出异常：javax.persistence.EntityExistsException 而merge就不会抛出什么对象重复的异常的了。事实上，经过测试，EntityManager#merge方法在没主键时会执行插入操作（可用于插入记录操作）。但是无法通过EntityManager#merge插入自定义主键的记录，而EntityManager#persist在有无主键时都会进行插入操作，对于主键的值会根据表主键的生成策略进行生成。即：persist是直接保存，merge是根据id是否存在来判断是保存还是修改（id存在，则修改； id不存在，则添加）","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://lolico.me/tags/Spring/"},{"name":"Java","slug":"Java","permalink":"https://lolico.me/tags/Java/"},{"name":"JPA","slug":"JPA","permalink":"https://lolico.me/tags/JPA/"},{"name":"Hibernate","slug":"Hibernate","permalink":"https://lolico.me/tags/Hibernate/"}]},{"title":"深入理解@ModelAttribute、@SessionAttribute和@SessionAttributes注解","slug":"深入理解SpringMVC属性注解","date":"2019-10-19T04:45:57.000Z","updated":"2022-05-02T03:45:10.810Z","comments":true,"path":"2019/10/19/深入理解SpringMVC属性注解/","link":"","permalink":"https://lolico.me/2019/10/19/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3SpringMVC%E5%B1%9E%E6%80%A7%E6%B3%A8%E8%A7%A3/","excerpt":"","text":"@ModelAttribute如果希望将方法入参对象添加到模型中，则仅需要在相应入参前使用@ModelAttribute注解。来看一个具体的实例：12345@GetMapping(\"/h\")public User user(@ModelAttribute(\"user\") User user) &#123; user.setNickName(\"lolico li\"); return user;&#125;SpringMVC将请求消息绑定到User对象，然后以user为键将User对象放到模型中，在准备对视图进行渲染前，SpringMVC还会进一步将模型中的数据转储到视图上下文中并暴露给视图对象。对于JSP来说，SpringMVC将模型数据转储到ServletRequest的属性列表中（通过ServletRequest#setAttribute(String name, Object o)方法，作用域为请求域)，这也是为什么@ModelAttribute注解的属性只能在一次相同的请求中可见的原因。除了可以在方法入参上使用@ModelAttribute注解外 ，还可以在方法定义上使用。SpringMVC在调用目标方法前，会先逐个调用在方法层级上标注了该注解的方法，并将这些方法的返回值添加到模型中。下面一个具体的实例：123456789101112@ModelAttribute(\"user\")public User initUserModal() &#123; // 1 User user = new User(); user.setNickName(\"init user\"); return user;&#125;@GetMapping(\"/h\")public User handle(@ModelAttribute(\"user\") User user) &#123; // 2 user.setNickName(\"lolico li\"); return user;&#125;在访问UserController中的任何一个请求处理方法前，都会先执行initUserModal方法，并将其返回值以user为键添加到模型中。由于handle方法使用入参级的@ModelAttribute注解，且属性名和①处方法上的@ModelAttribute的属性名相同。这时SpringMVC会从模型中取出①处获得的模型属性，赋给②处的user对象，然后再根据请求消息对usr进行属性填充覆盖，得到一个整合版本的user对象。注意：处理方法的入参最多只能使用一个SpringMVC注解。如handle方法的user入参使用了@ModelAttribute，就不能再使用@RequestParam或@CookieValue,@RequestHeader等注解。如果使用了两个。将抛出异常。@SessionAttribute可以用于获取HttpSession中的属性，在入参方法上标注@SessionAttribute注解，SpringMVC会将会话中对应的属性绑定到入参，下面是一个具体的实例：12345@PostMapping(\"/login\")public User login(@SessionAttribute(\"user\") User user) &#123; // do something return user;&#125;但是很可惜，当向/login发送请求时，SpringMVC会抛出异常：ServletRequestBindingException: Missing session attribute ‘user’ of type User不同于@ModelAttribute，如果在HttpSession中没有对应的属性，则会抛出异常。那这样看来的话，这个注解是只能用于获取HttpSession中的属性吗？当然不是这样的，类似@ModelAttribute注解，@SessionAttribute还会在方法执行完毕后，将标注该注解的入参对象再放回到HttpSession中，利用这一特性我们可以在方法中对某个会话属性进行“更新”。那该如何向会话域中添加属性呢？使用Servlet原生API中的HttpSession作为入参时，SpringMVC会将请求会话绑定到入参，然后我们可以操作这个对象去设置会话属性。使用SpringMVC提供的原生Servlet API的代理类WebRequest作为入参，使用WebRequest#setAttribute(String name, Object value, int scope)方法可同时支持向请求域或是会话域中添加属性。@SessionAttributes如果希望在多个请求之间共享某个模型属性数据，则可以在控制器类上标注一个@SessionAttributes，SpringMVC会将模型中对应的属性暂存到HttpSession中。为什么这么说呢？后面会慢慢分析，先来看一个@SessionAttributes使用实例：UserController.java12345678910111213141516171819202122@Controller@RequestMapping(\"/user\")@SessionAttributes(\"user\") // 1 会将2处的模型属性透明的保存到HttpSession中public class UserController &#123; @GetMapping(\"/h1\") // 2 public String handle1(@ModelAttribute(\"user\") User user) &#123; user.setNickName(\"lolico li\"); return \"redirect:/user/h2\"; &#125; @ResponseBody @GetMapping(\"/h2\") public ResponseEntity&lt;Object&gt; handle2(ModelMap modelMap, SessionStatus sessionStatus) &#123; User user = (User) modelMap.get(\"user\"); if (user != null) &#123; user.setNickName(\"griouges\"); sessionStatus.setComplete(); &#125; return ResponseEntity.ok().build(); &#125;&#125;在①处标注的@SessionAttributes(&quot;user&quot;)会自动将本处理器的任何处理方法中属性名为user的模型属性透明地存储到HttpSession中。在②处，handler1方法的user入参会添加到隐含模型中，于是这个模型属性在handle1方法执行时，SpringMVC会将其透明的保存到HttpSession中。handle1返回的逻辑视图名为redirect:/user/h2，重定向发送另一个请w求。而这个请求由handle2方法负责处理。两个处理方法位于不同的请求上下文中，之所以handle2可以获取名为user的模型属性，就是因为@SessionAttributes(&quot;user&quot;)透明的将handle1的user模型属性存储到HttpSession中，而handler2的隐含模型又自动从HttpSession中获取到这个模型属性。（PS：一般这种情况我们使用forward转发，这里重定向是为了演示@SessionAttributes注解在不同请求上下文中共享模型属性的作用）handle2方法还包含一个SessionStatus对象，当调用SessionStatus#setComplete方法，SpringMVC会清除控制器类的所有会话属性；否则这个会话属性会一直保存在HttpSession中，这也是为什么说@SessionAttributes是将模型属性暂存到HttpSession中的原因。我们也可以通过HttpSession#removeAttribute(String name)方法手动删除会话属性，但是需要提供属性名，硬编码是不提倡且不方便的。讲了这么多，但是很可惜，当向/h1发送请求时，SpringMVC抛出异常：HttpSessionRequiredException: Session attribute ‘user’ required - not found in session这个异常很奇怪，因为Spring仅宣传@SessionAttributes的作用是将处理方法对应的模型属性透明的保存到HttpSession中，并没有要求HttpSession中必须事先拥有对应的模型属性。通过研究SpringMVC的源码，才找到了问题的答案。原来SpringMVC对@ModelAttribute、@SessionAttributes的处理遵循一个流程，当流程条件不满足时就会报错。处理流程简单说明如下：SpringMVC在调用处理方法前，在请求的线程中自动创建一个隐含的模型对象。调用所有标注了@ModelAttribute的方法，并将方法返回值添加到隐含对象。查看Session中是否存在@SessionAttributes(&quot;xxx&quot;)所指定的xxx属性，如果有，则将其添加到隐含模型中。如果模型中已有xxx属性，则覆盖已有的。对标注了@ModelAttribute(&quot;xxx&quot;)处理方法的入参按以下流程处理。如果隐含模型拥有名为xxx的属性，则将其赋给该入参，再用请求消息填充该入参对象直接返回，否则转到4.2。如果xxx是会话属性，即在处理类上标注了@SessionAttributes(&quot;xxx&quot;)，则尝试从会话中获取该属性，并将其赋给该入参，然后再用请求消息填充该入参对象。如果在会话中找不到对应的属性，则抛出HttpSessionRequiredException异常。否则转到4.3。如果隐含模型中不存在xxx属性，且xxx也不是会话属性，则创建入参的对象实例，然后再用请求消息填充该入参。分析上面的代码，由于在处理器类上标注了@SessionAttributes(&quot;user&quot;)，所以user为会话属性，在对handle1进行处理时会先在隐含模型中查找对应属性，如果没有，则继续在会话中查找这个属性。由于会话中也不存在，因此抛出HttpSessionRequiredException异常，也就是说走到了上面的流程的4.2中。解决这个异常的方法很简单，添加一个标注了@ModelAttribute(&quot;user&quot;)的方法，使得在访问处理方法前先向隐含模型中添加user属性，这样4.1步就会执行，而4.2中也就能在隐含模型中找到对应属性，不会报错。总结@ModelAttribute注解在方法入参上时就算模型中没有也不会抛出异常（参考上述流程的第1步），在方法执行完毕后透明的将其放入模型中，作用域为请求域，类似于ServletRequest#setAttribute；注解在方法上时，处理方法执行前会先执行这个方法，并将返回值放入模型中。@SessionAttribute只能注解在方法参数，用于访问Session中的属性，方法执行完毕后会再将其放入HttpSession中，要求HttpSession中必须事先拥有对应属性，否则抛出ServletRequestBindingException：Missing session attribute异常，可设置require=false，作用域为会话域，类似于HttpSession#setAttribute@SessionAttributes可以将指定的模型属性暂存到HttpSession中，还有一个作用是将Session中的属性填充至模型属性中（参考上述流程的第2步），使得方法入参级的@ModelAttribute可以访问到。注意区分@SessionAttribute和@SessionAttributes的不同","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://lolico.me/tags/Spring/"},{"name":"Web","slug":"Web","permalink":"https://lolico.me/tags/Web/"}]},{"title":"解析日期字符串格式并转换","slug":"解析日期字符串格式并转换","date":"2019-07-21T10:01:21.000Z","updated":"2022-05-02T03:45:10.810Z","comments":true,"path":"2019/07/21/解析日期字符串格式并转换/","link":"","permalink":"https://lolico.me/2019/07/21/%E8%A7%A3%E6%9E%90%E6%97%A5%E6%9C%9F%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%A0%BC%E5%BC%8F%E5%B9%B6%E8%BD%AC%E6%8D%A2/","excerpt":"","text":"利用正则表达式匹配日期字符串格式并转换1234567891011121314151617181920212223242526272829303132public class DateConverter &#123; public static Date parseDate(String dateStr, String format) throws ParseException &#123; return new Date(new SimpleDateFormat(format).parse(dateStr).getTime()); &#125; public static String formatDate(Date date, String format) &#123; return new SimpleDateFormat(format).format(date); &#125; public Date convert(String source) &#123; if (source == null) return null; source = source.trim(); if (\"\".equals(source)) return null; try &#123; if (source.matches(\"^\\\\d&#123;4&#125;-\\\\d&#123;1,2&#125;-\\\\d&#123;1,2&#125;$\"))//yyyy-MM-dd return parseDate(source, \"yyyy-MM-dd\"); else if (source.matches(\"^\\\\d&#123;4&#125;/\\\\d&#123;1,2&#125;/\\\\d&#123;1,2&#125;$\"))//yyyy/MM/dd return parseDate(source, \"yyyy/MM/dd\"); else if (source.matches(\"^\\\\d&#123;4&#125;-\\\\d&#123;1,2&#125;-\\\\d&#123;1,2&#125; \\\\d&#123;1,2&#125;:\\\\d&#123;1,2&#125;:\\\\d&#123;1,2&#125;$\"))//yyyy-MM-dd HH:mm:ss return parseDate(source, \"yyyy-MM-dd HH:mm:ss\"); else if (source.matches(\"^\\\\d&#123;4&#125;/\\\\d&#123;1,2&#125;/\\\\d&#123;1,2&#125; \\\\d&#123;1,2&#125;:\\\\d&#123;1,2&#125;:\\\\d&#123;1,2&#125;$\"))//yyyy/MM/dd HH:mm:ss return parseDate(source, \"yyyy/MM/dd HH:mm:ss\"); else throw new IllegalArgumentException(\"Invalid date value '\" + source + \"'\"); &#125; catch (ParseException e) &#123; e.printStackTrace(); &#125; return null; &#125;&#125;","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://lolico.me/tags/Java/"}]},{"title":"Iterator和Iterable接口","slug":"Iterator和Iterable接口","date":"2018-11-14T08:30:32.000Z","updated":"2022-05-02T03:45:10.806Z","comments":true,"path":"2018/11/14/Iterator和Iterable接口/","link":"","permalink":"https://lolico.me/2018/11/14/Iterator%E5%92%8CIterable%E6%8E%A5%E5%8F%A3/","excerpt":"","text":"通常情况下,我们使用集合框架时会希望能够遍历一个集合中的元素。例如，显示集合中的每个元素。一般的，我们都是采用for循环或增强for（for-each），这两个方法也可以用在集合框架。但是在集合框架中还有一种方法是采用迭代器遍历集合框架，它是一个对象，实现了Iterator接口或ListIterator接口。迭代器（Iterator），使你能够通过循环来得到或删除集合的元素。ListIterator，继承了Iterator以允许双向遍历列表和修改元素。两个问题什么是foreach循环？for-each是增强型的for循环，是Java5的新特性之一。foreach语法格式如下：123for(元素类型t 元素变量x : 遍历对象obj)&#123; 引用了x的java语句&#125;什么时候可以使用foreach进行遍历？可以被foreach遍历的对象分两种：数组java对于数组的foreach处理相对来说简单。在编译期将foreach还原成简单的for循环。实现了Iterable接口的对象实现了Iterable接口的对象，可以被foreach。并且java会通过迭代器的形式来遍历他。Iterable接口：故名思议，实现了这个接口的集合对象支持迭代，是可迭代的。Iterator接口：迭代器，它就是提供迭代机制的对象，具体如何迭代，都是Iterator接口规范的。Iterable和IteratorIterable我们看看Iterable接口的用途是什么：123456789101112&#x2F;** * Implementing this interface allows an object to be the target of * the &quot;for-each loop&quot; statement. See * &lt;strong&gt; * &lt;a href&#x3D;&quot;&#123;@docRoot&#125;&#x2F;..&#x2F;technotes&#x2F;guides&#x2F;language&#x2F;foreach.html&quot;&gt;For-each Loop&lt;&#x2F;a&gt; * &lt;&#x2F;strong&gt; * * @param &lt;T&gt; the type of elements returned by the iterator * * @since 1.5 * @jls 14.14.2 The enhanced for statement *&#x2F;实现这个接口，允许一个对象成为for-each的目标再来看看接口中定义了哪些需要实现的方法Iterable.java12345678public interface Iterable&lt;T&gt; &#123; /** * Returns an iterator over elements of type &#123;@code T&#125;. * * @return an Iterator. */ Iterator&lt;T&gt; iterator();&#125;上面我们说过了，实现了Iterable接口的对象，可以被foreach。并且java会通过迭代器的形式来遍历他。Iterable接口中的Iterator&lt;T&gt; iterator()方法返回的就是一个迭代器（Iterator)Iterator包含2个需要实现的方法：hasNext()、next() 和一个默认方法remove()。我们以ArrayList为例：12List&lt;Object&gt; list=new ArrayList&lt;&gt;();for(Object obj:list);编译后查看class文件:12345List&lt;Object&gt; list &#x3D; new ArrayList();Object var3;for(Iterator var2 &#x3D; list.iterator(); var2.hasNext(); var3 &#x3D; var2.next()) &#123;&#125;可以看到是使用了迭代器来遍历集合,首先获取集合的迭代器后调用hasNext()方法判断是否迭代到终点,next()方法不仅要返回集合元素（下一个）,还要将迭代器的游标后移。定义一个实现了Iterable接口的类IterableTester.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class IterableTester&lt;E&gt; implements Iterable&lt;E&gt; &#123; private Object[] elements = &#123;&#125;; //存放泛型对象的数组,取出时需要进行强制类型转换 private int size = 0; IterableTester(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; elements = new Object[initialCapacity]; &#125; &#125; public boolean add(E element) &#123; if (size &lt; elements.length) &#123; elements[size] = element; size++; return true; &#125; else &#123; return false; &#125; &#125; public E get(int index) &#123; //rangeCheck(index); return (E) elements[index]; //存放在Object类型的数组中，所以在取出的时候，需要进行强制类型转换。 &#125; @Override public Iterator&lt;E&gt; iterator() &#123; return new itr(); //返回一个迭代器 &#125; //内部类,实现Iterator接口 private class itr implements Iterator&lt;E&gt; &#123; int cursor = 0; @Override public boolean hasNext() &#123; //如果游标不等于元素个数,则还有下一个 return cursor != size; &#125; @Override public E next() &#123; if (cursor &gt;= size || cursor &gt;= elements.length) throw new RuntimeException(); return (E) elements[cursor++]; &#125; &#125;&#125;执行for-each的时候，会先调用iterator()方法返回一个迭代器。然后调用迭代器的hasNext()和next()方法来进行遍历。测试样例11234567IterableTester&lt;String&gt; its = new IterableTester&lt;&gt;(5);its.add(new String(\"i \"));its.add(new String(\"am \"));its.add(new String(\"a \"));its.add(new String(\"coder\"));for (String s : its) System.out.print(s);输出i am coder需要注意的地方迭代出来的元素都是原集合元素的拷贝Java集合中保存的元素实质是对象的引用(可以理解为C中的指针)，而非对象本身。迭代出的元素也就都是引用的拷贝，结果还是引用。那么，如果集合中保存的元素是可变类型的，我们就可以通过迭代出的元素修改原集合中的对象。而对于不可变类型，如String或者基本类型的包装类型Integer等则不会反应到原集合中。测试样例212345678910111213141516171819202122232425262728public class Main &#123; public static void main(String[] args) &#123; IterableTester&lt;Person&gt; itp = new IterableTester&lt;&gt;(5); ArrayList&lt;String&gt; als = new ArrayList&lt;&gt;(); Person p = new Person(\"Tom\"); itp.add(p); als.add(new String(\"Tom\")); for (Person p_ : itp) p_.setName(\"Jack\"); //修改了原集合中的元素(Person对象) for (String s_ : als) s_ = \"Jack\"; //实际上是S_=new String(\"Jack\"),并没有对原集合中的元素进行修改 System.out.println(itp.get(0).getName()); System.out.println(als.get(0)); &#125;&#125;class Person &#123; private String name; Person(String name) &#123; this.name = name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getName() &#123; return name; &#125;&#125;输出12JackTom值得思考的问题既然说:迭代出来的元素都是原集合元素的拷贝,如果集合中保存的元素是可变类型的，我们就可以通过迭代出的元素修改原集合中的对象。那么我们可不可以在将迭代元素修改时却不影响原集合元素呢?答案是肯定的,大概有两个实现的方法(这里只说一下大概的思路):将集合定义成不可变类,具体可看我的这篇博文：在实现Iterator#next方法时,返回集合元素的一个克隆,具体可看我的这篇博文：","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://lolico.me/tags/Java/"}]},{"title":"response.getWriter()和内置对象out的区别","slug":"response-getWriter-和内置对象out的区别","date":"2018-11-03T08:25:16.000Z","updated":"2022-05-02T03:45:10.806Z","comments":true,"path":"2018/11/03/response-getWriter-和内置对象out的区别/","link":"","permalink":"https://lolico.me/2018/11/03/response-getWriter-%E5%92%8C%E5%86%85%E7%BD%AE%E5%AF%B9%E8%B1%A1out%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"","text":"首先我们需要知道的是:response对象和out对象都是jsp内置的隐式对象。out是JSP九大内置对象之一，是JspWriter的一个对象，JspWriter继承了java.io.Writer类。response.getWriter()返回的是PrintWriter的一个对象，PrintWriter同样继承了java.io.Writer类。两者的主要区别两者的类型不一样：内置对象out的类型是JspWriter，response.getWrite()返回的类型是PrintWriter。out和response.getWriter()的类不一样，一个是JspWriter，另一个是PrintWriter,但这两个类都继承自java.io.Writer，不同的是JspWriter是抽象类。获取方式不同：JspWriter是JSP的内置对象，可以直接使用，对象名out是保留字，也只能通过out来调用其相关方法。此外还可以通过内置对象pageContext调用方法getOut()获得；PrintWriter则是在用的时候需要通过内置对象response调用getWriter()获得。JspWriter的print()方法会抛出IOException，而PrintWriter则不会。out为jsp的内置对象，刷新jsp页面，自动初始化获得out对象，所以使用out对象是需要刷新页面的，而response.getWriter()响应信息通过out对象输出到网页上，当响应结束时它自动被关闭，与jsp页面无关，无需刷新页面。out的print()方法和println()方法在缓冲区溢出并且没有自动刷新时候会产生IOException，而response.getWrite()方法的print和println中都是抑制ioexception异常的，不会有IOException。out.println(“”)并不能使页面布局换行，只能令html代码换行，要实现页面布局换行可以out.println(“&lt;/br&gt;”)执行原理不同:示例：1234&lt;%=\"aaaa\"%&gt;bbbb&lt;%out.write(\"cccc\");%&gt;&lt;%response.getWriter().write(\"dddd\");%&gt;注意：response.getWriter().print()实际上调用的还是write方法，PrintWriter中print(String)源码:123456public void print(String s) &#123; if (s == null) &#123; s = \"null\"; &#125; write(s);&#125;运行上面的示例会在页面输出:dddd aaaa bbbb cccc顺序为什么是这样的呢?示例中的前三个方式，在jsp被翻译为servlet时，都会被翻译为out.write()方法，当我们向页面输出内容时，tomcat服务器会默认先刷新response缓冲区中的内容到网页中。而out对象本身也有个out缓冲区，前3个方法执行后要输出的内容先被存到out缓冲区内，然后再转移到response缓冲区中被tomcat服务器提取，因为JspWriter相当于一个带缓存功能的printWriter，它不是直接将数据输出到页面，而是将数据刷新到response的缓冲区后再输出。所以response.getWriter().print(String)直接输出数据，out.print(String)只能在其后输出。当然我们也可以让1、2、3的内容直接存到response缓冲区中。这是因为，out缓冲区可以通过指令buffer来设置它的缓存区大小，一般默认的是8kb，当我们设置为buffer=“0kb”时，就让out缓冲区存储空间为0，这样1、2、3方法输出的内容就会直接存到response缓冲区中。","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://lolico.me/tags/Java/"},{"name":"JSP","slug":"JSP","permalink":"https://lolico.me/tags/JSP/"},{"name":"Web","slug":"Web","permalink":"https://lolico.me/tags/Web/"}]},{"title":"Jsp中include指令与include动作","slug":"Jsp中include指令与include动作","date":"2018-10-18T08:19:05.000Z","updated":"2022-05-02T03:45:10.806Z","comments":true,"path":"2018/10/18/Jsp中include指令与include动作/","link":"","permalink":"https://lolico.me/2018/10/18/Jsp%E4%B8%ADinclude%E6%8C%87%E4%BB%A4%E4%B8%8Einclude%E5%8A%A8%E4%BD%9C/","excerpt":"","text":"前言＜%@ include file=&quot; &quot;%＞为指令元素＜jsp:include page=&quot; &quot; flush=&quot;true&quot;/＞为动作元素include指令通过file属性指定被包含的文件，并且file属性不支持任何表达式；&lt;jsp:include&gt;标识通过page属性指定被包含的文件，而page属性支持JSP表达式使用include指令，被包含的文件被原封不动的插入到包含页面中使用该指令的位置，然后JSP编译器再对这个合成的文件进行编译，所以在一个JSP页面中使用include指令来包含另一个JSP页面，最终编译后的文件只有一个。（静态包含）使用&lt;jsp:include&gt;动作包含文件时，当该动作标识执行后，JSP程序会将请求转发到（注意不是重定向）被包含页面，并将执行结果输出到浏览器中，然后返回页面继续执行后面的代码，因为服务器执行的是多个文件，所以JSP编译器会分别对这些文件进行编译。（动态包含）在应用include指令包含文件时，由于被包含的文件最终会生成一个文件，所以在被包含文件、包含的文件中不能有重名的变量或方法；而在应用&lt;jsp:include&gt;动作标识包含文件时，由于每个文件是单独编译的，所以在被包含文件和包含文件中重名的变量和方法是不相冲突的。示例12345678910111213&lt;%@ page language=\"java\" contentType=\"text/html;charset=UTF-8\" %&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset=\"utf-8\"&gt; &lt;title&gt;JSPinclude动作实例&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;%@ include file=\"Static.txt\" %&gt;&lt;jsp:include page=\"Dyamic.jsp\" flush=\"true\"/&gt;&lt;/body&gt;&lt;/html&gt;Static.txt123456&lt;%@ page language&#x3D;&quot;java&quot; contentType&#x3D;&quot;text&#x2F;html;charset&#x3D;UTF-8&quot; %&gt;&lt;form action&#x3D;&quot;JSPIncludeActiveDemo.jsp&quot; method&#x3D;&quot;post&quot;&gt; 用户名： &lt;input type&#x3D;&quot;text&quot; name&#x3D;&quot;name&quot;&gt;&lt;br&#x2F;&gt; 密码： &lt;input type&#x3D;&quot;password&quot; name&#x3D;&quot;password&quot;&gt;&lt;br&#x2F;&gt; &lt;input type&#x3D;&quot;submit&quot; value&#x3D;&quot;登录&quot;&gt;&lt;&#x2F;form&gt;Dyamic.jsp123456&lt;%@ page language=\"java\" contentType=\"text/html;charset=UTF-8\" %&gt;&lt;br/&gt;用户名：&lt;%=request.getParameter(\"name\") %&gt;&lt;br/&gt;密码：&lt;%=request.getParameter(\"password\") %&gt;&lt;br/&gt;示例","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://lolico.me/tags/Java/"},{"name":"JSP","slug":"JSP","permalink":"https://lolico.me/tags/JSP/"}]},{"title":"高精度计算","slug":"高精度计算","date":"2018-09-04T08:05:35.000Z","updated":"2022-05-02T03:45:10.810Z","comments":true,"path":"2018/09/04/高精度计算/","link":"","permalink":"https://lolico.me/2018/09/04/%E9%AB%98%E7%B2%BE%E5%BA%A6%E8%AE%A1%E7%AE%97/","excerpt":"","text":"前言&emsp;&emsp;由于计算机运算是有模运算,数据范围的表示有一定限制,如整型int(C++中int与long相同)表达范围是(-2^312^31-1),unsigned long(无符号整数)是(02^32-1),都约为几十亿.如果采用实数型,则能保存最大的double只能提供15~16位的有效数字,即只能精确表达数百万亿的数.因此,在计算位数超过十几位的数时,不能采用现有类型,只能自己编程计算.&emsp;&emsp;高精度计算通用方法:高精度计算时一般用一个数组来存储一个数,数组的一个元素对应于数的一位(当然,在以后的学习中为了加快计算速度,也可用数组的一个元素表示数的多位数字,暂时不讲),表示时,由于数计算时可能要进位,因此为了方便,将数由低位到高位依次存在数组下标对应由低到高位置上,另外,我们申请数组大小时,一般考虑了最大的情况,在很多情况下,表示有富余,即高位有很多0,可能造成无效的运算和判断,因此,我们一般将数组的第0个下标对应位置来存储该数的位数.如数:3485(三千四百八十五)，表达在数组a[5]上情况是:下标&emsp;&emsp;0&emsp;&emsp;1&emsp;&emsp;2&emsp;&emsp;3&emsp;&emsp;4内容&emsp;&emsp;4&emsp;&emsp;5&emsp;&emsp;8&emsp;&emsp;4&emsp;&emsp;3说明：&nbsp;位数&nbsp; 个位&nbsp; 十位&nbsp; 百位&nbsp; 千位具体在计算加减乘除时方法就是小学时采用的列竖式方法.高精度数的存储采用字符串读入将数先存在字符串中,再逐位倒叙存入数组中1234567891011121314151617#include &lt;cstring&gt;#include &lt;iostream&gt;using namespace std;int main() &#123; int num1[200], num2[200]; //最高199位 string input; memset(num1, 0, sizeof(num1)); //数组清零 memset(num2, 0, sizeof(num2)); cin &gt;&gt; input; num1[0] = input.length(); //位数 for (int i = 1; i &lt;= num1[0]; ++i) num1[i] = input[num1[0] - i] - '0'; //将字符转为数字并倒序存储进数组 cin &gt;&gt; input; num2[0] = input.length(); for (int i = 1; i &lt;= num2[0]; ++i) num2[i] = input[num2[0] - i] - '0';&#125;采用直接读入利用取余数的方式存入数组中12345678910111213#include &lt;iostream&gt;using namespace std;int main() &#123; int num[200], key; cin &gt;&gt; key; memset(num, 0, sizeof(num)); //数组清零 int i = 0; //第i位 while(key)&#123; num[++i] = key % 10; //取第i位数 key /= 10; &#125; num[0] = i; //位数位i位&#125;操作高精度数以下程序只写实现功能的函数,并且假定高精度数的数据结构满足上述约定.比较两个高精度数1234567891011//比较a和b的大小关系,a&gt;b return 1,a&lt;b return -1,a=b return 0int compare(int a[], int b[]) &#123; int k = a[0] &gt; b[0] ? a[0] : b[0]; //更大的位数 for (int i = k; i &gt; 0; --i) &#123; //逐位比较 if (a[i] &gt; b[i]) return 1; if (a[i] &lt; b[i]) return -1; &#125; return 0; //各位都相等&#125;高精度数加法1234567891011void doplus(int a[], int b[]) &#123; //结果放在a中，即计算a=a+b int k = a[0] &gt; b[0] ? a[0] : b[0]; for (int i = 1; i &lt;= k; ++i) &#123; a[i + 1] += (a[i] + b[i]) / 10; //先进位 a[i] = (a[i] + b[i]) % 10; &#125; if (a[k + 1] &gt; 0) a[0] = k + 1; else a[0] = k;&#125;高精度数减法12345678910111213141516171819202122232425262728293031int dominus(int a[], int b[]) &#123; //结果放于a中，返回符号位，1正数，0相等，-1负数 if (compare(a, b) == 0) &#123; // a=a-b=0 return 0 a[1] = 0, a[0] = 1; // memset(a,0,sizeof(a)); return 0; &#125; if (compare(a, b) == 1) &#123; // a=a-b return 1 for (int i = 1; i &lt;= b[0]; ++i) &#123; if (a[i] &lt; b[i]) &#123; a[i + 1]--; a[i] = a[i] + 10 - b[i]; &#125; else &#123; a[i] -= b[i]; &#125; &#125; while (a[a[0]] == 0) a[0]--; return 1; &#125; for (int i = 1; i &lt;= b[0]; ++i) &#123; // a=b-a return -1 if (b[i] &lt; a[i]) &#123; b[i + 1]--; a[i] = b[i] + 10 - a[i]; &#125; else &#123; a[i] = b[i] - a[i]; &#125; &#125; a[0] = b[0]; while (a[a[0]] == 0) a[0]--; return -1;&#125;高精度乘法要求尽可能用更少的存储单元,逐位相乘,注意进位和总位数.1234567891011121314int *multiply(int a[], int b[]) &#123; //结果存在res数组中并返回res int res[a[0] + b[0]]; res[0] = a[0] + b[0]; //最坏情况下的位数 memset(res, 0, sizeof(res)); for (int i = 0; i &lt; a[0]; ++i) for (int j = 0; j &lt; b[0]; ++j) &#123; res[i + j] += a[i] * b[j]; res[i + j + 1] += res[i + j] / 10; res[i + j] = res[i + j] % 10; &#125; while (!res[res[0]]) //位数的修正 res[0]--; return res;&#125;高精度除法模拟手算除法,把除法试商转化为连减.123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121#include &lt;stdio.h&gt;#include &lt;string.h&gt;#define N 500int bj(int a[], int b[], int k1, int k2) /*比较大小函数*/&#123; int i, t, flag; /*flag作标志位*/ if (k1 &lt; k2) flag = 0; /*被除数小于除数返回0*/ else if (k1 &gt; k2) flag = 1; /*被除数大于除数返回1*/ else &#123; /*被除数和除数位数相等则逐位进行比较*/ i = k1; t = 0; while (t == 0 &amp;&amp; i &gt; 0) &#123; if (a[i] &gt; b[i]) &#123; t = 1; flag = 1; &#125; else if (a[i] == b[i]) i--; else &#123; t = 1; flag = 0; &#125; &#125; if (i == 0 &amp;&amp; t == 0) flag = 2; /*被除数等于除数返回2*/ &#125; return flag;&#125;int jf(int a[], int b[], int k1, int k2) /*减法运算*/&#123; int i, k, d[N]; for (i = 0; i &lt; k2; i++) d[i] = b[i]; /*把除数赋给数组d*/ for (i = k2; i &lt; N; i++) d[i] = 0; /*d数组无数据的高位置0*/ k = k1 - k2 - 1; /*计算减法起始位置*/ if (k &lt; 0) k = 0; if (k &gt; 0) &#123; for (i = k2 - 1; i &gt;= 0; i--) d[i + k] = d[i]; /*移动减数位数与被减数对齐*/ for (i = 0; i &lt; k; i++) d[i] = 0; /*移动后的其余位置0*/ &#125; for (i = 0; i &lt; k1; i++) &#123; if (a[i] &gt;= d[i]) a[i] -= d[i]; else &#123; a[i + 1] = a[i + 1] - 1; a[i] = 10 + a[i] - d[i]; &#125; &#125; return k;&#125;int main() &#123; int a[N] = &#123; 0 &#125;, b[N] = &#123; 0 &#125;, c[N] = &#123; 0 &#125;, d[N] = &#123; 0 &#125;; int i, ka, kb, m, t, t1, t2, k, x, kd, kk; char a1[N], b1[N]; printf(\"Input 被除数:\"); scanf(\"%s\", a1); ka = strlen(a1); for (i = 0; i &lt; ka; i++) a[i] = a1[ka - i - 1] - '0'; printf(\"Input 除数:\"); scanf(\"%s\", b1); kb = strlen(b1); for (i = 0; i &lt; kb; i++) b[i] = b1[kb - i - 1] - '0'; kd = ka; /*保存被除数位数 */ t2 = bj(a, b, ka, kb); m = 0; do &#123; while (a[ka - 1] == 0) ka--; t = bj(a, b, ka, kb); if (t &gt;= 1) &#123; k = jf(a, b, ka, kb); c[k]++; if (k &gt; m) m = k; t1 = 0; for (i = k; i &lt;= m; i++) &#123; x = c[i] + t1; c[i] = x % 10; t1 = x / 10; &#125; if (t1 &gt; 0) &#123; m++; c[m] = t1; &#125; &#125; &#125; while (t == 1); if (t2 == 0) &#123; printf(\"商=0\"); printf(\"\\n余数=\"); for (i = kd - 1; i &gt;= 0; i--) printf(\"%d\", a[i]); exit(1); &#125; if (t2 == 2) &#123; printf(\"商 = 1\"); printf(\"\\n余数 = 0\"); exit(1); &#125; kk = kd; while (!c[kd - 1]) kd--; printf(\"商 = \"); for (i = kd - 1; i &gt;= 0; i--) printf(\"%d\", c[i]); while (!a[kk]) kk--; printf(\"\\n余数 = \"); if (kk &lt; 0) &#123; printf(\"0\"); exit(1); &#125; for (i = kk; i &gt;= 0; i--) printf(\"%d\", a[i]);&#125;案例N！，要求精确到P位(0〈P〈1000)问题1. N！，要求精确到P位(0〈P〈1000)算法：结果用数组a保存，开始时a[0]=1，依次乘以数组中各位，注意进位和数组长度的变化源程序如下：123456789101112131415161718192021222324#include &lt;stdio.h&gt;#define M 1000int main() &#123; int a[M], i, n, j, flag = 1; printf(\"n=\"); scanf(\"%d\", &amp;n); printf(\"n!=\"); a[0] = 1; for (i = 1; i &lt; M; i++) a[i] = 0; for (j = 2; j &lt;= n; j++) &#123; for (i = 0; i &lt; flag; i++) a[i] *= j; for (i = 0; i &lt; flag; i++) if (a[i] &gt;= 10) &#123; a[i + 1] += a[i] / 10; a[i] = a[i] % 10; if (i == flag - 1) flag++; &#125; &#125; for (j = flag - 1; j &gt;= 0; j--) printf(\"%d\", a[j]);&#125;麦森数问题2. 麦森数【问题描述】形如2P-1的素数称为麦森数，这时P一定也是个素数。但反过来不一定，即如果P是个素数，2P-1不一定也是素数。到1998年底，人们已找到了37个麦森数。最大的一个是P=3021377，它有909526位。麦森数有许多重要应用，它与完全数密切相关任务：从文件中输入P（1000&lt;P&lt;3100000），计算2P-1的位数和最后500位数字（用十进制高精度数表示）【输入格式】文件中只包含一个整数P（1000&lt;P&lt;3100000）【输出格式】第一行：十进制高精度数2P-1的位数。第2-11行：十进制高精度数2P-1的最后500位数字。（每行输出50位，共输出10行，不足500位时高位补0）不必验证2P-1与P是否为素数。【输入样例】1279【输出样例】38600000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000010407932194664399081925240327364085538615262247266704805319112350403608059673360298012239441732324184842421613954281007791383566248323464908139906605677320762924129509389220345773183349661583550472959420547689811211693677147548478866962501384438260291732348885311160828538416585028255604666224831890918801847068222203140521026698435488732958028878050869736186900714720710555703168729087算法：2的幂可以转化成左移运算，为了提高运算速度，可每次左移10位，即每次乘210。对于个位单独考虑，每次左移一位源程序如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;math.h&gt;#include &lt;stdio.h&gt;#define MAX 100000int main() &#123; int p; int i, j; scanf(\"%d\", &amp;p); printf(\"%d\\n\", (int)(p * log10(2.0)) + 1); long store[110] = &#123; 0 &#125;; store[0] = 1; int left = p % 10; p /= 10; for (i = 1; i &lt;= p; i++) &#123; for (j = 0; j &lt;= 100; j++) store[j] &lt;&lt;= 10; for (j = 0; j &lt;= 100; j++) &#123; if (store[j] &gt;= MAX) &#123; store[j + 1] += store[j] / MAX; store[j] %= MAX; &#125; &#125; &#125; for (i = 1; i &lt;= left; i++) &#123; for (j = 0; j &lt;= 100; j++) store[j] &lt;&lt;= 1; for (j = 0; j &lt;= 100; j++) &#123; if (store[j] &gt;= MAX) &#123; store[j + 1] += store[j] / MAX; store[j] %= MAX; &#125; &#125; &#125; store[0] -= 1; for (i = 1; i &lt; 100; i++) &#123; if (store[i - 1] &lt; 0) &#123; store[i] -= 1; store[i - 1] += MAX; &#125; else break; &#125; for (i = 99; i &gt;= 0; i--) &#123; printf(\"%05d\", store[i]); if ((100 - i) % 10 == 0) printf(\"\\n\"); &#125;&#125;","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Cpp","slug":"Cpp","permalink":"https://lolico.me/tags/Cpp/"}]},{"title":"计算两个日期之间的天数","slug":"计算两个日期之间的天数","date":"2018-08-21T08:13:12.000Z","updated":"2022-05-02T03:45:10.810Z","comments":true,"path":"2018/08/21/计算两个日期之间的天数/","link":"","permalink":"https://lolico.me/2018/08/21/%E8%AE%A1%E7%AE%97%E4%B8%A4%E4%B8%AA%E6%97%A5%E6%9C%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%A4%A9%E6%95%B0/","excerpt":"","text":"前言给定两个日期(年月日)要求计算出 这两个日期之间的天数。在生活中我们也总会遇到这样的问题，仔细一想，虽然计算的方法不难，但是真正算起来还是要花费一点时间的，而且在这个过程中很容易因为不细心而得出错误的结果。当我们每次遇到这个问题时，总不能每次都心算或是手算吧？所以呢，写出一个简单的计算两日期之间天数的程序还是有点用的。分析虽说这个过程并不复杂，但是我们还是要分析一下：日期是否符合生活规律（即不能出现月为13或是日期出现40的情况）给定日期时不一定是小的在前大的在后计算两日期之间天数的算法至于日期是否符合生活规律写个判断就可以了，这个很简单，在这里就不赘述，程序中默认给定的日期是正确的，给定日期的先后顺序也我们可以写一个判断并进行位置交换，至于大的在前还是小的在前按你自己的习惯都行，下面的分析以小的在前大的在后为基准并且已经解决日期规范问题。最最最关键的当然还是计算天数的方法：写计算天数的算法时我们需要考虑：年份是同年还是不同年，并且我们还要考虑到是否为闰年的情况。同年的情况下还有是否同月的情况，若是同月，将日相减便得到结果，这也是最简单的一种情况。考虑到还有是否闰年，年份是否同年的情况，若是我们这样分那就会有很多种组合，程序也会显得很杂乱。那么我们怎么才能让计算的过程相对更简单呢？在这里，我就分两种情况：同年不同年1):同年的情况下为了不再区分是否同月,我们计算出:(大的日期到年初的天数-小的日期到年初的天数)2):不同年的情况下,计算出:(小的日期到年末的天数+大的日期到年初的天数+年份差之间的天数)对于不同年,我们计算小的日期到年末的天数我们还可以计算当前年的总天数-小的日期到年初的天数,所以最后就变成了(大的日期到年初的天数-小的日期到年初的天数+年份差之间的天数)注意此处的年份差之间的天数与2)中的不同,相差1.为了再简单点,我们再将这两种情况视为一种情况:即不管什么情况,计算出(大的日期到年初的天数-小的日期到年初的天数+年份差之间的天数),因为同年份时的年份差之间的天数为零。实现先放上完整代码:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#include &lt;iostream&gt;using namespace std;const int leepMonth[13] = &#123; 0, 31, 29, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31 &#125;;const int noLeepMonth[13] = &#123; 0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31 &#125;;const int year[2] = &#123; 365, 366 &#125;;typedef struct Date &#123; int year; int month; int day; int isLeep;&#125; Date;void isLeep(Date &amp;date) &#123; if ((date.year % 4 == 0 &amp;&amp; date.year % 100 != 0) || date.year % 400 == 0) date.isLeep = 1; date.isLeep = 0;&#125;void swap(Date &amp;min, Date &amp;max) &#123; Date temp; if (min.year &gt; max.year || (min.year == max.year &amp;&amp; min.month &gt; max.month) || (min.year == max.year &amp;&amp; min.month == max.month &amp;&amp; min.day &gt; max.day)) &#123; temp = min; min = max; max = temp; &#125;&#125;int diff(Date &amp;min, Date &amp;max) &#123; isLeep(min); isLeep(max); swap(min, max); //保证小的日期在前大的在后 int minday = 0, maxday = 0, diff = 0; for (int m = 1; m &lt; min.month; m++) &#123; //计算小的日期到年初的天数,最后还要加上日期中的天数 if (min.isLeep) minday += leepMonth[m]; else minday += noLeepMonth[m]; &#125; for (int m = 1; m &lt; max.month; m++) &#123; //计算大的日期到年初的天数,最后还要加上日期中的天数 if (max.isLeep) maxday += leepMonth[m]; else maxday += noLeepMonth[m]; &#125; minday += min.day; //加上天数 maxday += max.day; for (Date y = min; y.year &lt; max.year; y.year++) &#123; //计算年份差之间的天数 isLeep(y); diff += year[y.isLeep]; &#125; diff = diff + maxday - minday; //得出结果 return diff;&#125;int main() &#123; Date startDate, endDate; cout &lt;&lt; \"please input startday(yyyy MM dd):\"; cin &gt;&gt; startDate.year &gt;&gt; startDate.month &gt;&gt; startDate.day; cout &lt;&lt; \"please input endday(yyyy MM dd):\"; cin &gt;&gt; endDate.year &gt;&gt; endDate.month &gt;&gt; endDate.day; //日期先后不影响,swap()确保小的在前 cout &lt;&lt; \"daydiff: \" &lt;&lt; diff(startDate, endDate) &lt;&lt; endl;&#125;为了程序的可读性,这里定义了一个结构体Date,为了计算年份差之间的天数更方便,结构体中还定义了一个isLeep成员,结合数组year[2]={355,356}可以更简单的计算出年份差之间的天数,这部分的完整代码挖出来以便更好理解:1234for (Date y = min; y.year &lt; max.year; y.year++) &#123; isLeep(y); diff += year[y.isLeep];&#125;isLeep()函数判断当前年是否为闰年,并对结构体成员isLeep初始化.为闰年时year[y.isLeep]即year[1]=366,不是闰年时year[y.isLeep]即year[0]=365","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Cpp","slug":"Cpp","permalink":"https://lolico.me/tags/Cpp/"}]},{"title":"将字符串藏在二进制编码中","slug":"将字符串藏在二进制编码中","date":"2018-08-10T07:47:56.000Z","updated":"2022-05-02T03:45:10.810Z","comments":true,"path":"2018/08/10/将字符串藏在二进制编码中/","link":"","permalink":"https://lolico.me/2018/08/10/%E5%B0%86%E5%AD%97%E7%AC%A6%E4%B8%B2%E8%97%8F%E5%9C%A8%E4%BA%8C%E8%BF%9B%E5%88%B6%E7%BC%96%E7%A0%81%E4%B8%AD/","excerpt":"","text":"前言先放两张图将字符串以二进制的形式编码,也就是图片中那一大串二进制代码.看起来好像很厉害的样子,其实实现起来十分的简单.在不懂的朋友面前或许我们还可以用这个方式装个逼 (逃实现原理简单说下实现的方法：字符串以二进制形式编码:将字符串以二进制编码其实就是利用字符的ASCII码,并将每个字符的ASCII码转换为二进制的形式便将字符串”藏在了二进制编码中”.将二进制字符串还原:也就是将图片中的二进制字符串”破解”,其实也很简单,就是将二进制字符串分割,再转换为十进制的ASCII码,最后再转为字符类型即可.说白了,就是将上面的步骤反过来.代码12345678910111213141516171819202122232425262728293031323334353637383940414243public class BinaryString &#123; private String binaryCode=\"\"; public BinaryString(String str) &#123; char[] chars = str.toCharArray(); for (char ch : chars) &#123; String s=Integer.toBinaryString((int)ch);//将字符的ASCII码转换为二进制 while(s.length()&lt;8)//不够8位则在前面补0 s=\"0\"+s; binaryCode+=s+\" \"; &#125; &#125; public String getBinaryCode()&#123; //得到二进制编码的字符串 return binaryCode; &#125; public static String toDecimalString(String binaryCode)&#123; //将二进制编码的字符串还原 String decimalString=\"\"; String[] strings=binaryCode.split(\" \");//分割二进制字符串,得到每个字符的二进制字符串 for(String str:strings)&#123; char ch= (char) Integer.parseInt(str,2);//转换为十进制ASCII并强制类型转换为char decimalString+=ch; &#125; return decimalString; &#125; public static void main(String[] args) &#123; String Code=\"01010011 01101111 01101101 01100101 \" + \"01110100 01101001 01101101 01100101 \" + \"01110011 00100000 01001001 00100000 \" + \"01100110 01100001 01101001 01101100 \" + \"00100000 01101111 01110010 01100100 \" + \"01100101 01110010 01110011 00100000 \" + \"01101111 01101110 00100000 01110000 \" + \"01110101 01110010 01110000 01101111 \" + \"01110011 01100101 00100000 01110100 \" + \"01101111 00100000 01100001 01101110 \" + \"01101110 01101111 01111001 00100000 \" + \"01101101 01111001 00100000 01110100 \" + \"01100101 01100001 01101101 00100001\"; System.out.println(toDecimalString(Code)); System.out.println(new BinaryString(\"Thrall and Jaina sitting in a tree, K-I-S-S-I-N-G\").getBinaryCode()); &#125;&#125;输出12Sometimes I fail orders on purpose to annoy my team!01010100 01101000 01110010 01100001 01101100 01101100 00100000 01100001 01101110 01100100 00100000 01001010 01100001 01101001 01101110 01100001 00100000 01110011 01101001 01110100 01110100 01101001 01101110 01100111 00100000 01101001 01101110 00100000 01100001 00100000 01110100 01110010 01100101 01100101 00101100 00100000 01001011 00101101 01001001 00101101 01010011 00101101 01010011 00101101 01001001 00101101 01001110 00101101 01000111","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://lolico.me/tags/Java/"}]},{"title":"Chevereto-在服务器上搭建自己的图床","slug":"Chevereto-在服务器上搭建自己的图床","date":"2018-08-09T07:43:03.000Z","updated":"2022-05-02T03:45:10.806Z","comments":true,"path":"2018/08/09/Chevereto-在服务器上搭建自己的图床/","link":"","permalink":"https://lolico.me/2018/08/09/Chevereto-%E5%9C%A8%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%9B%BE%E5%BA%8A/","excerpt":"","text":"介绍官网:chevereto.comgithub项目:Chevereto-FreeChevereto 是一款采用 PHP 语言开发的网络相册脚本程序，支持多语言，提供中文语言包的下载的开源在线图片存储分享服务系统，支持本地上传和在线获取两种图像上传方式，并集成了 TinyURL 网址缩短服务。Chevereto 这套程序可以像 Discuz 或 WordPress 一样随意架设在任何空间上。而它的功能除了一般图片空间单纯的从电脑上传图片外，也支援利用网址也可以上传，最屌的是还有 TinyURL 的缩短网址的功能可以使用，因此这套 Chevereto 可以说是比市面上一些免费图床好太多了。安装目前Chevereto有免费版和付费版两种,且当前最新版本已经支持PHP7,但是PHP7已经不支持mysql扩展,所以建议不要使用PHP7,使用PHP5.5,PHP5.6即可下载源码后解压并放在网站根目录,官网和github下载很慢,这里提供一个: chevereto-3.10.13.zip打开你的网站,若网站提示你Chevereto can’t create the app/settings.php file. You must manually create this file.在app/目录下创建一个setting.php文件即可.刷新网页,开始安装,安装界面是英文的,英语不差到离谱应该还是能够看懂的,填入对应数据库信息,登陆后台账号密码等就可以开始安装了.安装可能还会提示你某些文件夹权限不够或者setting.php文件无法写入,可以修改对应文件夹权限,或是自己在setting.php中写入安装程序提示你的代码即可继续安装.上述步骤完成后,我们的图床便搭建好了,现在就可以登录后台对一些基础功能进行设置和修改.演示站点img.griouges.cn","categories":[{"name":"不正常的文章","slug":"不正常的文章","permalink":"https://lolico.me/categories/%E4%B8%8D%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[]},{"title":"字符串与任意类型数据拼接","slug":"字符串与任意类型数据拼接","date":"2018-07-01T07:47:56.000Z","updated":"2022-05-02T03:45:10.810Z","comments":true,"path":"2018/07/01/字符串与任意类型数据拼接/","link":"","permalink":"https://lolico.me/2018/07/01/%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%B8%8E%E4%BB%BB%E6%84%8F%E7%B1%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%8B%BC%E6%8E%A5/","excerpt":"","text":"前言c++中的string类提供了许多函数给我们使用,也重载了一些基本的运算符,例如string类中的append()函数和重载的’+’运算符可以让我们将字符串与字符串或字符进行拼接,但是却没有直接提供将字符串与其他基本类型数据拼接的函数或运算符,当我们需要将字符串与其他基本类型拼接时该怎么办呢?实现c++中将字符串与其他基本类型数据拼接十分的灵活,灵活之处在于有很多种方式可以实现拼接,下面我就介绍几种将字符串与其他基本类型拼接的方法.讲的一些方法中游的部分是没有涉及到c++中的string而是c中的字符串(字符数组),若是只想看string的可以跳过一些方法.sprintf函数函数原型:int sprintf (char *__stream, const char *__format, ...);123456789101112131415#include&lt;iostream&gt;#include&lt;cstring&gt;using namespace std;int main()&#123; char *s = \"aaa\"; int a = 1; double b = 1.11; char *buf = new char(); sprintf(buf, \"%s%d%.2f\", s, a, b); cout &lt;&lt; buf &lt;&lt; endl; system(\"pause\");&#125;//输出://aaa11.11//请按任意键继续. . .此方法局限性较大,用这种方式拼接类似于c中的字符操作函数char *strcat(char *dest,char *src)只不过用sprintf可以将字符串与其他基本类型的数据进行拼接,美中不足的是需要注意拼接时有浮点型的数据要控制小数点的位数,并且与strcat()一样的,拼接的字符串和拼接后的字符串是c风格的字符串.c风格字符串和c++string字符串的不同和转换可以看下这篇文章:C++ string对象和C风格字符串的差别与转换接口itoa函数函数原型:char *_itoa(int value, char *string, int radix);1234567891011121314#include&lt;iostream&gt;#include&lt;cstring&gt;using namespace std;int main() &#123; char* s = \"a\"; int a = 1; char *buf=new char(); _itoa(a, buf, 10); cout &lt;&lt; s+buf &lt;&lt; endl; system(\"pause\");&#125;//输出://a1//请按任意键继续. . .此方法局限性相比sprintf()更大,因为只能将string字符串与整型数据拼接并且使用的是非标准C语言和C++语言扩展函数,注意函数原型中的radix参数是转换时的基数,具体的可以见:itoa-百度百科to_string函数函数原型:123456789string to_string (int val);string to_string (long val);string to_string (long long val);string to_string (unsigned val);string to_string (unsigned long val);string to_string (unsigned long long val);string to_string (float val);string to_string (double val);string to_string (long double val);12345678910111213#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;int main() &#123; string s = \"a\"; int a = 1; double b = 1.11; cout &lt;&lt; s+to_string(a)+to_string(b) &lt;&lt; endl; system(\"pause\");&#125;//输出://a11.110000//请按任意键继续. . .此方法适用于string字符串与其他基础类型拼接,需要注意的是to_string()函数是c++11中引入的标准库函数,使用该函数拼接唯一不足的一点就是拼接的是浮点型数据时小数点后会跟6位,不足6位0来补,有时候可能达不到我们想要的结果.重载运算符1234567891011121314151617181920212223242526#include &lt;iostream&gt;#include &lt;sstream&gt;#include &lt;string&gt;using namespace std;template &lt;typename T&gt;string operator&amp;(const T &amp;t, const string &amp;s) &#123; ostringstream oss; oss &lt;&lt; t; return oss.str() + s;&#125;template &lt;typename T&gt;string operator&amp;(const string &amp;s, const T &amp;t) &#123; ostringstream oss; oss &lt;&lt; t; return s + oss.str();&#125;int main() &#123; string s = \"a\"; int a = 1; double b = 1.11; cout &lt;&lt; (s &amp; a &amp; b) &lt;&lt; endl; system(\"pause\");&#125;//输出//a11.11//请按任意键继续. . .重载&amp;运算符使得string字符串可以与其他任意基本类型进行拼接,对于浮点型数据也不会在小数点后跟上0,可以说是十分完美的一种方法了.后记对于string字符串拼接,除了上面讲的一些方法还有很多方法,例如利用string类中substr()函数还可以实现将字符串的某一片段与其他字符串或基本类型数据拼接,总之,按不同的需求来拼接,思路不同,方法更是有很多种.","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Cpp","slug":"Cpp","permalink":"https://lolico.me/tags/Cpp/"}]},{"title":"C语言结构体定义的几种方法","slug":"C语言结构体定义的几种方法","date":"2018-07-01T07:26:14.000Z","updated":"2022-05-02T03:45:10.806Z","comments":true,"path":"2018/07/01/C语言结构体定义的几种方法/","link":"","permalink":"https://lolico.me/2018/07/01/C%E8%AF%AD%E8%A8%80%E7%BB%93%E6%9E%84%E4%BD%93%E5%AE%9A%E4%B9%89%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E6%B3%95/","excerpt":"","text":"什么是结构体？在C语言中，结构体(struct)指的是一种数据结构，是C语言中聚合数据类型(aggregate data type)的一类。结构体可以被声明为变量、指针或数组等，用以实现较复杂的数据结构。结构体同时也是一些元素的集合，这些元素称为结构体的成员(member)，且这些成员可以为不同的类型，成员一般用名字访问。结构体的定义C语言结构体类型的定义模板大概为：123struct 类型名&#123; 成员表列&#125; 变量;在成员表列中可以是几种基本数据类型，也可以是结构体类型。struct 类型名{} 变量;后的分号不能漏下面给出定义结构体类型的几种方法先定义结构体类型，再定义结构体变量12345678struct student&#123; char no[20]; //学号 char name[20]; //姓名 char sex[5]; //性别 int age; //年龄&#125;; struct student stu1,stu2;//此时stu1,stu2为student结构体变量定义结构体类型的同时定义结构体变量123456struct student&#123; char no[20]; //学号 char name[20]; //姓名 char sex[5]; //性别 int age; //年龄&#125; stu1,stu2;此时还可以继续定义student结构体变量如：struct student stu3;直接定义结构体变量123456struct&#123; char no[20]; //学号 char name[20]; //姓名 char sex[5]; //性别 int age; //年龄&#125; stu1,stu2;一般不会使用第三种定义方法，因为直接定义结构体变量stu1,stu2后就不能再继续定义该类型的变量。注意在C语言中使用struct定义结构体类型后定义结构体变量时struct不能省略，在C++中允许省略struct。12345678910//在c中:struct student&#123; ...&#125;;struct student stu1; //struct不可省略//在c++中：struct student&#123; ...&#125;;student stu1; //struct可省略在C中定义结构体类型后每次定义变量时都要使用struct，如果嫌麻烦，我们可以这样：1234typedef struct student&#123; ...&#125;STUDENT;STUDENT stu1;使用typedef给struct student取一个”别名”STUDENT在某些情况下还可以使用#define来实现更简化的结构体定义与变量的定义，但可能会牺牲部分可读性。12345#define STUDENT struct studentSTUDENT&#123; ...&#125;;STUDENT stu1;typedef和#define用法不同，甚至可以结合起来灵活使用，使用时一定要注意两者的不同之处。","categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"C","slug":"C","permalink":"https://lolico.me/tags/C/"}]},{"title":"利用亚马逊aws一年EC2实例搭建酸酸乳科学上网","slug":"利用亚马逊aws一年EC2实例搭建酸酸乳科学上网","date":"2018-07-01T07:21:36.000Z","updated":"2022-05-02T03:45:10.810Z","comments":true,"path":"2018/07/01/利用亚马逊aws一年EC2实例搭建酸酸乳科学上网/","link":"","permalink":"https://lolico.me/2018/07/01/%E5%88%A9%E7%94%A8%E4%BA%9A%E9%A9%AC%E9%80%8Aaws%E4%B8%80%E5%B9%B4EC2%E5%AE%9E%E4%BE%8B%E6%90%AD%E5%BB%BA%E9%85%B8%E9%85%B8%E4%B9%B3%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/","excerpt":"","text":"搭建前的主机准备工作注册aws账号首先在aws官网网注册一个账号，并用信用卡进行验证。注册账号的方法就不详说，至于用信用卡进行认证，可以从淘宝上买一个visa信用卡进行验证，完成这些步骤后我们就可以免费使用aws一年EC2实例，搭建ss/ssr进行科学上网。创建EC2实例并启动搭建ss/ssr之前，我们需要先启动一个实例。选择创建实例的地区，注意：在成功验证信用卡后aws会发送一封邮件到注册的邮箱，在邮件中会告诉我们可用地区的EC2实例，博主之前也是没注意到这封邮件，导致在不允许的地区创建实例时不能启动点击服务选择EC2aws创建实例点击启动实例aws启动实例选择实例的操作系统，这里我选择的是第一个Linux系统选择EC2系统2345步都可默认，点击下一步，进入配置安全组界面默认点击下一步在配置安全组页面我们需要添加一个入站规则，选择所有流量，来源中填写0.0.0.0，最后点击审核和启动添加入站规则选择登入实例的密钥对，没有的话点击创建密钥对，并下载这个密钥对，(密钥十分重要，这是登入aws实例的唯一钥匙)创建密钥对——到这里，实例的创建就完成了，接下来就是连接我们刚才创建的实例并搭建ss/ssr使用Xshell登入实例在这里我们选择使用Xshell 5连接实例点击查看实例，我们可以看见我们刚才创建的实例的ip，记下这个ip打开Xshell实例ip点击工具中的用户密钥管理者，并导入上文说的十分重要的那个密钥导入密钥导入密钥后点击Xshell右上角文件中的新建在主机项中填入刚才记下的ip填入ip再点击右边用户身份验证，选择图中的方法，并选择登入的密钥，在用户名项中填入ec2-user，并确认(Linux系统的填ec2-user，Ubuntu系统填Ubuntu，否则可能会连接失败)选择登入方法和密钥连接刚才新建的会话，第一次连接会有个提示，选择接受并保存，如图所示则连接成功连接成功——到这一步，我们就成功连接上了实例，现在就可以开始搭建ss/ssr了搭建ss/ssr输入sudo su获取root权限安装脚本ss1wget -N --no-check-certificate https://raw.githubusercontent.com/ToyoDAdoubi/doubi/master/ss-go.sh &amp;&amp; chmod +x ss-go.sh &amp;&amp; sudo bash ss-go.shssr1wget -N --no-check-certificate https://raw.githubusercontent.com/ToyoDAdoubi/doubi/master/ssr.sh &amp;&amp; chmod +x ssr.sh &amp;&amp; sudo bash ssr.sh安装完成后是这样的安装完成安装完成之后输入1回车，进行安装配置ShadowsocksR①选择端口，博主这里设置的是8080，（据说配合混淆参数可以实现免流，但现在好像是不可以了）选择端口②设置密码③设置加密方法④设置协议，选择插件兼容原版填入y进行配置⑤设置混淆插件，同样填入y选择兼容原版（③④⑤博主都是直接默认回车）⑥⑦⑧配置端口和速度直接默认回车，当然也可以按自己的想法来设置之后填入y开始安装，安装过程稍慢，需要等一等进行安装安装成功！安装成功安装成功后就可以复制配置信息中的ss/ssr链接或二维码进行连接开始我们的FQ之旅补充：BBR加速SS/SSRssr.sh脚本内置bbr加速四合一脚本1wget -N --no-check-certificate https://raw.githubusercontent.com/chiakge/Linux-NetSpeed/master/tcp.sh &amp;&amp; chmod +x tcp.sh &amp;&amp; sudo bash tcp.sh","categories":[{"name":"不正常的文章","slug":"不正常的文章","permalink":"https://lolico.me/categories/%E4%B8%8D%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[]}],"categories":[{"name":"正常的文章","slug":"正常的文章","permalink":"https://lolico.me/categories/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"},{"name":"碎碎念","slug":"碎碎念","permalink":"https://lolico.me/categories/%E7%A2%8E%E7%A2%8E%E5%BF%B5/"},{"name":"不正常的文章","slug":"不正常的文章","permalink":"https://lolico.me/categories/%E4%B8%8D%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"MessageQueue","slug":"MessageQueue","permalink":"https://lolico.me/tags/MessageQueue/"},{"name":"Netty","slug":"Netty","permalink":"https://lolico.me/tags/Netty/"},{"name":"Spring","slug":"Spring","permalink":"https://lolico.me/tags/Spring/"},{"name":"AOP","slug":"AOP","permalink":"https://lolico.me/tags/AOP/"},{"name":"Web","slug":"Web","permalink":"https://lolico.me/tags/Web/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://lolico.me/tags/SpringBoot/"},{"name":"Redis","slug":"Redis","permalink":"https://lolico.me/tags/Redis/"},{"name":"Asp.Net Core","slug":"Asp-Net-Core","permalink":"https://lolico.me/tags/Asp-Net-Core/"},{"name":"NLog","slug":"NLog","permalink":"https://lolico.me/tags/NLog/"},{"name":"WPF","slug":"WPF","permalink":"https://lolico.me/tags/WPF/"},{"name":"Nginx","slug":"Nginx","permalink":"https://lolico.me/tags/Nginx/"},{"name":"WSL","slug":"WSL","permalink":"https://lolico.me/tags/WSL/"},{"name":"IDEA","slug":"IDEA","permalink":"https://lolico.me/tags/IDEA/"},{"name":"WebStorm","slug":"WebStorm","permalink":"https://lolico.me/tags/WebStorm/"},{"name":"PyCharm","slug":"PyCharm","permalink":"https://lolico.me/tags/PyCharm/"},{"name":"Security","slug":"Security","permalink":"https://lolico.me/tags/Security/"},{"name":"CORS","slug":"CORS","permalink":"https://lolico.me/tags/CORS/"},{"name":"Vue.js","slug":"Vue-js","permalink":"https://lolico.me/tags/Vue-js/"},{"name":"git","slug":"git","permalink":"https://lolico.me/tags/git/"},{"name":"Python","slug":"Python","permalink":"https://lolico.me/tags/Python/"},{"name":"pip","slug":"pip","permalink":"https://lolico.me/tags/pip/"},{"name":"dlib","slug":"dlib","permalink":"https://lolico.me/tags/dlib/"},{"name":"JetBrains Quest","slug":"JetBrains-Quest","permalink":"https://lolico.me/tags/JetBrains-Quest/"},{"name":"Java","slug":"Java","permalink":"https://lolico.me/tags/Java/"},{"name":"Shiro","slug":"Shiro","permalink":"https://lolico.me/tags/Shiro/"},{"name":"Password","slug":"Password","permalink":"https://lolico.me/tags/Password/"},{"name":"Salt","slug":"Salt","permalink":"https://lolico.me/tags/Salt/"},{"name":"JPA","slug":"JPA","permalink":"https://lolico.me/tags/JPA/"},{"name":"Hibernate","slug":"Hibernate","permalink":"https://lolico.me/tags/Hibernate/"},{"name":"JSP","slug":"JSP","permalink":"https://lolico.me/tags/JSP/"},{"name":"Cpp","slug":"Cpp","permalink":"https://lolico.me/tags/Cpp/"},{"name":"C","slug":"C","permalink":"https://lolico.me/tags/C/"}]}